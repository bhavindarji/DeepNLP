{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.keras.datasets import imdb\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorboard import summary as summary_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 200)\n",
      "x_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "sentence_size = 200\n",
    "embedding_size = 50\n",
    "# model_dir = tempfile.mkdtemp()\n",
    "model_dir = './checkpoint/cnn_classifier'\n",
    "\n",
    "# we assign the first indices in the vocabulary to special tokens that we use\n",
    "# for padding, as start token, and for indicating unknown words\n",
    "pad_id = 0\n",
    "start_id = 1\n",
    "oov_id = 2\n",
    "index_offset = 2\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train_variable, y_train), (x_test_variable, y_test) = imdb.load_data(\n",
    "    num_words=vocab_size, start_char=start_id, oov_char=oov_id,\n",
    "    index_from=index_offset)\n",
    "print(len(y_train), \"train sequences\")\n",
    "print(len(y_test), \"test sequences\")\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_train = sequence.pad_sequences(x_train_variable, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "x_test = sequence.pad_sequences(x_test_variable, \n",
    "                                maxlen=sentence_size,\n",
    "                                truncating='post',\n",
    "                                padding='post', \n",
    "                                value=pad_id)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <PAD>\n",
      "1 <START>\n",
      "2 <OOV>\n",
      "3 the\n",
      "4 and\n",
      "5 a\n",
      "6 of\n",
      "7 to\n",
      "8 is\n",
      "9 br\n",
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <OOV> is an amazing actor and now the same being director <OOV> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <OOV> and would recommend it to everyone to watch and the fly <OOV> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <OOV> to the two little <OOV> that played the <OOV> of norman and paul they were just brilliant children are often left out of the <OOV> list i think because the stars that play them all grown up are such a big <OOV> for the whole film but these children are amazing and should be <OOV> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <OOV> with us all\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "word_inverted_index = {v + index_offset: k for k, v in word_index.items()}\n",
    "\n",
    "# The first indexes in the map are reserved to represent things other than tokens\n",
    "word_inverted_index[pad_id] = '<PAD>'\n",
    "word_inverted_index[start_id] = '<START>'\n",
    "word_inverted_index[oov_id] = '<OOV>'\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(i, word_inverted_index[i])\n",
    "  \n",
    "def index_to_text(indexes):\n",
    "    return ' '.join([word_inverted_index[i] for i in indexes])\n",
    "\n",
    "print(index_to_text(x_train_variable[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input function\n",
    "\n",
    "x_len_train = np.array([min(len(x), sentence_size) for x in x_train_variable])\n",
    "x_len_test = np.array([min(len(x), sentence_size) for x in x_test_variable])\n",
    "\n",
    "def parser(x, length, y):\n",
    "    features = {\"x\": x, \"len\": length}\n",
    "    return features, y\n",
    "\n",
    "#len을 활용하여 기존 전처리 이후의 길이를 보존\n",
    "#from_tensor_slices를 활용하면 numpy 데이터 구조에서 쉽게 변환\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, x_len_train, y_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(x_train_variable))\n",
    "    dataset = dataset.batch(100)\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_test, x_len_test, y_test))\n",
    "    dataset = dataset.batch(100)\n",
    "    dataset = dataset.map(parser)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classification\n",
    "\n",
    "CNN을 활용하여 text를 분류해보자, n-gram의 효과로 활용\n",
    "\n",
    "https://www.semanticscholar.org/paper/Learning-to-Rank-Short-Text-Pairs-with-Deep-Neural-Severyn-Moschitti/452f7411af7d471dd3ba84c2b06b2aaffc38cdb9\n",
    "\n",
    "Embedding Layer -> Dropout -> Conv1D -> GlobalMax1D -> Hidden Dense Layer -> Dropout -> Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers = {}\n",
    "\n",
    "def train_and_evaluate(classifier):\n",
    "    # 예측 테스트를 위해 모델을 학습시키고 저장한다.\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=train_input_fn, steps=25000)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n",
    "    \n",
    "    # name scopes의 재사용을 위해 graph를 reset한다.\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool),\n",
    "                             num_thresholds=21)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n",
    "        writer.add_summary(sess.run(pr), global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './checkpoint/cnn_classifier/cnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1214e2ba8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#head: pre-made estimator로 평가를 할 때, 일정한 함수를 사용하게 세팅\n",
    "head = tf.contrib.estimator.binary_classification_head()\n",
    "\n",
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    #embedding layer를 선언한다.\n",
    "    input_layer = tf.contrib.layers.embed_sequence(\n",
    "                    features['x'],\n",
    "                    vocab_size,\n",
    "                    embedding_size,\n",
    "                    initializer=params['embedding_initializer']\n",
    "                    )\n",
    "\n",
    "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer,\n",
    "                                   rate=0.2,\n",
    "                                   training=training)\n",
    "\n",
    "    conv = tf.layers.conv1d(\n",
    "            inputs=dropout_emb,\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu)\n",
    "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
    "    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)  \n",
    "    dropout_hidden = tf.layers.dropout(inputs=hidden, rate=0.2, training=training)\n",
    "    logits = tf.layers.dense(inputs=dropout_hidden, units=1)\n",
    "    \n",
    "    #prediction 진행 시, None\n",
    "    if labels is not None:\n",
    "        labels = tf.reshape(labels, [-1, 1])\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer() #여러가지 Optimizer 활용가능\n",
    "    \n",
    "    def _train_op_fn(loss):\n",
    "#         tf.summary('loss', loss)\n",
    "        return optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "\n",
    "    \n",
    "    return head.create_estimator_spec(\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "        mode=mode,\n",
    "        logits=logits,\n",
    "        train_op_fn=_train_op_fn)\n",
    "\n",
    "params = {'embedding_initializer': tf.random_uniform_initializer(-1.0, 1.0)}\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                        model_dir=os.path.join(model_dir, 'cnn'),\n",
    "                                        params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./checkpoint/cnn_classifier/cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 90.836975, step = 1\n",
      "INFO:tensorflow:global_step/sec: 12.7869\n",
      "INFO:tensorflow:loss = 69.78476, step = 101 (7.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.386\n",
      "INFO:tensorflow:loss = 66.52496, step = 201 (7.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2463\n",
      "INFO:tensorflow:loss = 56.74327, step = 301 (7.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8295\n",
      "INFO:tensorflow:loss = 60.572372, step = 401 (7.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.884\n",
      "INFO:tensorflow:loss = 47.06904, step = 501 (7.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7084\n",
      "INFO:tensorflow:loss = 43.126133, step = 601 (8.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.808\n",
      "INFO:tensorflow:loss = 57.06847, step = 701 (7.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.134\n",
      "INFO:tensorflow:loss = 42.21399, step = 801 (7.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6357\n",
      "INFO:tensorflow:loss = 42.85147, step = 901 (7.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1127\n",
      "INFO:tensorflow:loss = 43.338566, step = 1001 (8.999 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-8f97c09843e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-7942fbcfa4d5>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# 예측 테스트를 위해 모델을 학습시키고 저장한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_classifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_evaluate(cnn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-1\n",
      "I really liked the movie!\n",
      "\t./checkpoint/cnn_classifier/cnn 0.4765971899032593\n",
      "Hated every second of it...\n",
      "\t./checkpoint/cnn_classifier/cnn 0.530629575252533\n"
     ]
    }
   ],
   "source": [
    "def text_to_index(sentence):\n",
    "    # Remove punctuation characters except for the apostrophe\n",
    "    translator = str.maketrans('', '', string.punctuation.replace(\"'\", ''))\n",
    "    tokens = sentence.translate(translator).lower().split()\n",
    "    return np.array([1] + [word_index[t] if t in word_index else oov_id for t in tokens])\n",
    "\n",
    "def print_predictions(sentences):\n",
    "    indexes = [text_to_index(sentence) for sentence in sentences]\n",
    "    x = sequence.pad_sequences(indexes, \n",
    "                               maxlen=sentence_size, \n",
    "                               truncating='post',\n",
    "                               padding='post',\n",
    "                               value=pad_id)\n",
    "    length = np.array([min(len(x), sentence_size) for x in indexes])\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": x, \"len\": length}, shuffle=False)\n",
    "    predictions = {}\n",
    "    for path, classifier in all_classifiers.items():\n",
    "        predictions[path] = [p['logistic'][0] for p in classifier.predict(input_fn=predict_input_fn)]\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        print(sentence)\n",
    "        for path in all_classifiers:\n",
    "            print(\"\\t{} {}\".format(path, predictions[path][idx]))\n",
    "            \n",
    "print_predictions([\n",
    "    'I really liked the movie!',\n",
    "    'Hated every second of it...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-1\n",
      "I like this movie\n",
      "\t./checkpoint/cnn_classifier/cnn 0.4677623212337494\n"
     ]
    }
   ],
   "source": [
    "print_predictions(['I like this movie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 linear model을 활용하여 분류 (Bag-of-Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/6x/lq2g1bqs673f7knw38tdmphm0000gn/T/tmp9vo4rmrt/bow_sparse', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119e291d0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#위의 데이터셋을 가지고 간단한 모델 구현해보기\n",
    "\n",
    "#categorical_columns_with_identity: pre-processed text 입력에 어울림\n",
    "column = tf.feature_column.categorical_column_with_identity('x', vocab_size)\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "            feature_columns=[column],\n",
    "            model_dir=os.path.join(model_dir, 'bow_sparse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers = {}\n",
    "\n",
    "def train_and_evaluate(classifier):\n",
    "    # 예측 테스트를 위해 모델을 학습시키고 저장한다.\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=train_input_fn, steps=25000)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n",
    "    \n",
    "    # name scopes의 재사용을 위해 graph를 reset한다.\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool),\n",
    "                             num_thresholds=21)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n",
    "        writer.add_summary(sess.run(pr), global_step=0)\n",
    "        writer.close()\n",
    "        \n",
    "# Un-comment code to download experiment data from Colaboratory\n",
    "#     from google.colab import files\n",
    "#     model_name = os.path.basename(os.path.normpath(classifier.model_dir))\n",
    "#     ! zip -r {model_name + '.zip'} {classifier.model_dir}\n",
    "#     files.download(model_name + '.zip')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#simple 모델은 내부를 들여보기 쉬운 장점이 있음\n",
    "#최신의 checkpoint를 활용하여 가장 큰 weights를 가진 요소를 확인\n",
    "#positive와 negative 값 확인해보면 단어들이 대체적으로 긍정 및 부정\n",
    "\n",
    "weights = classifier.get_variable_value('linear/linear_model/x/weights').flatten()\n",
    "sorted_indexes = np.argsort(weights)\n",
    "extremes = np.concatenate((sorted_indexes[-8:], sorted_indexes[:8]))\n",
    "extreme_weights = sorted([(weights[i], word_inverted_index[i]) for i in extremes])\n",
    "\n",
    "y_pos = np.arange(len(extreme_weights))\n",
    "plt.bar(y_pos, [pair[0] for pair in extreme_weights], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, [pair[1] for pair in extreme_weights], rotation=45, ha='right')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Most significant tokens') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    " - dense low-dimensional representation of sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_column = tf.feature_column.embedding_column(column, dimension=embedding_size)\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[100],\n",
    "    feature_columns=[word_embedding_column], \n",
    "    model_dir=os.path.join(model_dir, 'bow_embeddings'))\n",
    "train_and_evaluate(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir, 'metadata.tsv'), 'w', encoding=\"utf-8\") as f:\n",
    "    f.write('label\\n')\n",
    "    for index in range(0, vocab_size):\n",
    "        f.write(word_inverted_index[index] + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
