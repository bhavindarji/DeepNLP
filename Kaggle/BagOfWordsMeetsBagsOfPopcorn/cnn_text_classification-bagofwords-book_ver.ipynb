{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카글 텍스트 분류 - 합성곱 신경망 활용 접근방법\n",
    "\n",
    "\n",
    "- 이번 장은 앞서 00장에서 간략하게 설명하였던 합성곱 신경망을 활용하여 텍스트 분류 문제를 풀어보고자 한다. 합성곱 신경망은 주로 이미지에서 특징을 추출하여 이미지 판단을 하는 역할로 큰 성능을 이루었는데, 텍스트에서도 좋은 효과를 낼 수 있다는 점을 Yoon Kim (2014) 박사가 \"Convolution Neural Network for Sentence Classificaion\" (http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf) 활용하여 입증하였다.\n",
    "\n",
    "<img src=\"./Fig/fig1-cnn_text_classification.png\"> \n",
    "\n",
    "**Fig1. Yoon Kim's Text Classification**\n",
    "\n",
    "- RNN이 단어의 입력의 순서를 중요하게 반영한다면, CNN은 문장의 지역 정보를 보존하면서 각 문장 성분의 등장 정보들을 학습에 반영하는 구조로 풀어가고 있습니다. 학습을 하면서 각 필터 사이즈를 조절하면서 언어의 특징 값을 추출하게 되는데, 기존의 N-gram (2 그램, 3 그램) 방식과 유사하다고 볼 수 있습니다.\n",
    "\n",
    "- 예를 들어 \"나는 배가 고프다\" 라는 문장을 2그램을 사용한다면, \"나 는 / 는 배 / 배 가 / 가 고프 / 고프 다/\" 로 각각 문장의 단어 성분을 쪼개어 활용 하는 접근방법을, 단어를 각 백터값을 투영하여 컨볼루션 필터값에 적용하는 원리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 설명\n",
    "\n",
    " - 이전 내용에서 기본적인 Kaggle 연동 및 데이터 분석 및 전처리를 진행하여, 여기에서는 관련된 주제 위주로 설명을 하겠습니다. Full Code는 http://Kaggle/BagOfWordsMeetsBagsOfPopcorn/cnn_text_classification-bagofwords-book_ver.ipynb 를 참조하시기 바랍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "FILE_DIR_PATH = './data/'\n",
    "INPUT_TRAIN_DATA_FILE_NAME = 'input.npy'\n",
    "LABEL_TRAIN_DATA_FILE_NAME = 'label.npy'\n",
    "DATA_CONFIGS_FILE_NAME = 'data_configs.json'\n",
    "\n",
    "input_data = np.load(open(FILE_DIR_PATH + INPUT_TRAIN_DATA_FILE_NAME, 'rb'))\n",
    "label_data = np.load(open(FILE_DIR_PATH + LABEL_TRAIN_DATA_FILE_NAME, 'rb'))\n",
    "prepro_configs = None\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "\n",
    "input_train, input_eval, label_train, label_eval = train_test_split(input_data, label_data, test_size=TEST_SPLIT, random_state=RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "vocab_size = 74065\n",
    "embedding_size = 128\n",
    "\n",
    "def mapping_fn(X, Y):\n",
    "    input, label = {'text': X}, Y\n",
    "    return input, label\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(input_train))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    dataset = dataset.repeat(count=NUM_EPOCHS)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_eval, label_eval))\n",
    "    dataset = dataset.shuffle(buffer_size=len(input_eval))\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_len_train = np.array([min(len(x), sentence_size) for x in x_train_variable])\n",
    "# x_len_test = np.array([min(len(x), sentence_size) for x in x_test_variable])\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    #embedding layer를 선언합니다.\n",
    "    input_layer = tf.contrib.layers.embed_sequence(\n",
    "                    features['text'],\n",
    "                    vocab_size,\n",
    "                    embedding_size,\n",
    "                    initializer=params['embedding_initializer']\n",
    "                    )\n",
    "    # 현재 모델이 학습모드인지 여부를 확인하는 변수입니다.\n",
    "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    # embedding layer에 대한 output에 대해 dropout을 취합니다.\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer,\n",
    "                                   rate=0.2,\n",
    "                                   training=training)\n",
    "    \n",
    "    conv = tf.layers.conv1d(\n",
    "            inputs=dropout_emb,\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
    "    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)\n",
    "    dropout_hidden = tf.layers.dropout(inputs=hidden, rate=0.2, training=training)\n",
    "#     logits = tf.layers.dense(inputs=dropout_hidden, units=1, name='result')\n",
    "    logits = tf.layers.dense(inputs=dropout_hidden, units=1)\n",
    "    \n",
    "    #prediction 진행 시, None\n",
    "    if labels is not None:\n",
    "        labels = tf.reshape(labels, [-1, 1])\n",
    "\n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "        train_op = tf.train.AdamOptimizer(0.001).minimize(loss, global_step)\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss = loss)\n",
    "    \n",
    "    elif EVAL:\n",
    "        loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "        pred = tf.nn.sigmoid(logits)\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(pred))\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops={'acc': accuracy})\n",
    "        \n",
    "    elif PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\n",
    "                'prob': tf.nn.sigmoid(logits),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/sinseongjin/DeepNLP/Kaggle/BagOfWordsMeetsBagsOfPopcorn/checkpoint/cnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x116e5ab00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {'embedding_initializer': tf.random_uniform_initializer(-1.0, 1.0)}\n",
    "\n",
    "model_dir = os.path.join(os.getcwd(), \"checkpoint/cnn_model\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "config_tf = tf.estimator.RunConfig()\n",
    "config_tf._save_checkpoints_steps = 100\n",
    "config_tf._save_checkpoints_secs = None\n",
    "config_tf._keep_checkpoint_max =  2\n",
    "config_tf._log_step_count_steps = 100\n",
    "\n",
    "est = tf.estimator.Estimator(model_fn, model_dir=model_dir, config=config_tf, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "Experiment started at 14:49:16\n",
      ".......................................\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sinseongjin/DeepNLP/Kaggle/BagOfWordsMeetsBagsOfPopcorn/checkpoint/cnn_model/model.ckpt-16171\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 16172 into /Users/sinseongjin/DeepNLP/Kaggle/BagOfWordsMeetsBagsOfPopcorn/checkpoint/cnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.016009422, step = 16172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-acab1b21d4bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".......................................\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    565\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1044\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf18/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)\n",
    "time_start = datetime.utcnow()\n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "est.train(train_input_fn)\n",
    "\n",
    "time_end = datetime.utcnow()\n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-15-14:54:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sinseongjin/DeepNLP/Kaggle/BagOfWordsMeetsBagsOfPopcorn/checkpoint/cnn_model/model.ckpt-16172\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-15-14:55:00\n",
      "INFO:tensorflow:Saving dict for global step 16172: acc = 0.8092, global_step = 16172, loss = 0.8769784\n"
     ]
    }
   ],
   "source": [
    "valid = est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sinseongjin/DeepNLP/Kaggle/BagOfWordsMeetsBagsOfPopcorn/checkpoint/cnn_model/model.ckpt-16172\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "0 0.00014485823\n",
      "1 0.99961406\n",
      "2 0.99998176\n",
      "3 1.0\n",
      "4 0.9999354\n",
      "5 0.0069756764\n",
      "6 0.0009121039\n",
      "7 1.748002e-08\n",
      "8 0.9996364\n",
      "9 0.088859916\n",
      "10 0.2813358\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 0.99997973\n",
      "14 0.027485149\n",
      "15 2.725245e-10\n",
      "16 0.9896344\n",
      "17 0.999869\n",
      "18 1.0\n",
      "19 0.99999976\n",
      "20 0.86113757\n",
      "21 0.00082698034\n",
      "22 2.302443e-08\n",
      "23 0.0057249623\n",
      "24 0.08718701\n",
      "25 8.3448003e-07\n",
      "26 0.00042200493\n",
      "27 0.99976295\n",
      "28 0.9980082\n",
      "29 0.99990594\n",
      "30 8.1340895e-06\n",
      "31 2.945175e-05\n",
      "32 0.7740441\n",
      "33 0.01203145\n",
      "34 0.08418838\n",
      "35 0.034193046\n",
      "36 0.013115659\n",
      "37 6.8747075e-05\n",
      "38 0.0024390218\n",
      "39 0.00090134406\n",
      "40 1.0\n",
      "41 0.043168157\n",
      "42 0.99999523\n",
      "43 1.003838e-10\n",
      "44 8.242397e-06\n",
      "45 0.99999833\n",
      "46 0.00024189864\n",
      "47 0.9999939\n",
      "48 0.04685736\n",
      "49 0.03707358\n",
      "50 0.42006865\n",
      "51 1.9059033e-05\n",
      "52 0.9977704\n",
      "53 0.31496993\n",
      "54 0.15673038\n",
      "55 0.000355451\n",
      "56 0.99999726\n",
      "57 0.99999976\n",
      "58 0.9997718\n",
      "59 0.005758731\n",
      "60 0.3706826\n",
      "61 0.9789099\n",
      "62 0.03730304\n",
      "63 0.00019409931\n",
      "64 0.8011107\n",
      "65 0.999941\n",
      "66 0.59876853\n",
      "67 0.99862623\n",
      "68 0.9965456\n",
      "69 0.9999881\n",
      "70 1.0\n",
      "71 0.29681852\n",
      "72 0.99739754\n",
      "73 0.3170819\n",
      "74 0.9998104\n",
      "75 0.942631\n",
      "76 0.99666935\n",
      "77 1.0\n",
      "78 0.89319247\n",
      "79 0.00017498242\n",
      "80 0.00097712\n",
      "81 5.2518203e-07\n",
      "82 0.9502707\n",
      "83 0.866401\n",
      "84 8.730188e-05\n",
      "85 0.7191345\n",
      "86 0.9908897\n",
      "87 0.999987\n",
      "88 0.9998511\n",
      "89 0.9916918\n",
      "90 0.013207748\n",
      "91 0.9999919\n",
      "92 0.004262422\n",
      "93 0.9999999\n",
      "94 8.5074664e-10\n",
      "95 1.2356272e-05\n",
      "96 3.9351576e-06\n",
      "97 0.9997526\n",
      "98 0.9972614\n",
      "99 1.0\n",
      "100 0.007685262\n",
      "101 0.99982566\n",
      "102 0.00095848716\n",
      "103 9.5240637e-07\n",
      "104 0.99991846\n",
      "105 0.17008796\n",
      "106 4.4913944e-05\n",
      "107 0.97883576\n",
      "108 3.9165582e-07\n",
      "109 1.4527135e-05\n",
      "110 0.00043127348\n",
      "111 0.99988484\n",
      "112 2.9658684e-05\n",
      "113 0.9999504\n",
      "114 0.99960464\n",
      "115 0.49931833\n",
      "116 1.4816355e-07\n",
      "117 3.3443546e-05\n",
      "118 0.10756457\n",
      "119 2.245716e-06\n",
      "120 4.4424616e-12\n",
      "121 2.7983465e-06\n",
      "122 0.99999976\n",
      "123 0.07372554\n",
      "124 0.97876155\n",
      "125 9.059386e-09\n",
      "126 6.5125136e-07\n",
      "127 1.0671033e-06\n",
      "128 4.7878607e-06\n",
      "129 0.95862204\n",
      "130 0.00044403292\n",
      "131 1.801377e-06\n",
      "132 0.851807\n",
      "133 0.3915616\n",
      "134 0.28207383\n",
      "135 0.99189174\n",
      "136 0.99842334\n",
      "137 4.3215196e-06\n",
      "138 0.0042574164\n",
      "139 0.94508046\n",
      "140 0.0007444304\n",
      "141 0.9999995\n",
      "142 2.9130988e-06\n",
      "143 8.818273e-06\n",
      "144 0.96579695\n",
      "145 0.9999578\n",
      "146 2.0928644e-06\n",
      "147 0.99706453\n",
      "148 0.99999094\n",
      "149 1.0223599e-08\n",
      "150 1.0\n",
      "151 1.0\n",
      "152 1.3857198e-07\n",
      "153 0.2406272\n",
      "154 0.12392245\n",
      "155 0.000715591\n",
      "156 0.0004045127\n",
      "157 0.5075636\n",
      "158 0.21299918\n",
      "159 0.016831644\n",
      "160 0.0083372565\n",
      "161 0.99999917\n",
      "162 0.99999976\n",
      "163 0.9997416\n",
      "164 0.98610187\n",
      "165 0.99899215\n",
      "166 0.13805015\n",
      "167 0.92287844\n",
      "168 0.1413256\n",
      "169 0.9998946\n",
      "170 1.0736148e-06\n",
      "171 0.9999726\n",
      "172 0.99994814\n",
      "173 0.022073949\n",
      "174 2.8172055e-05\n",
      "175 1.1285085e-06\n",
      "176 7.577414e-05\n",
      "177 0.9999993\n",
      "178 0.99999833\n",
      "179 5.9240796e-05\n",
      "180 0.9969599\n",
      "181 8.262081e-07\n",
      "182 1.1424038e-08\n",
      "183 1.1907089e-08\n",
      "184 0.9999994\n",
      "185 5.583796e-09\n",
      "186 0.38377348\n",
      "187 0.058463763\n",
      "188 0.0003806157\n",
      "189 6.0066786e-06\n",
      "190 0.13960002\n",
      "191 0.99941266\n",
      "192 0.7549506\n",
      "193 0.4165513\n",
      "194 0.9999995\n",
      "195 0.0034933197\n",
      "196 0.9999994\n",
      "197 0.9999994\n",
      "198 1.0518125e-06\n",
      "199 0.9999963\n",
      "200 1.1998235e-05\n",
      "201 6.8785106e-05\n",
      "202 8.951834e-11\n",
      "203 0.18269332\n",
      "204 0.9648882\n",
      "205 0.9985165\n",
      "206 0.047876015\n",
      "207 0.0023753266\n",
      "208 1.5018166e-07\n",
      "209 0.9999999\n",
      "210 0.9731363\n",
      "211 0.9993655\n",
      "212 0.010719121\n",
      "213 3.836734e-06\n",
      "214 1.0\n",
      "215 0.99966645\n",
      "216 0.999869\n",
      "217 0.0015559745\n",
      "218 0.98860186\n",
      "219 0.0023099838\n",
      "220 0.090093665\n",
      "221 0.99886715\n",
      "222 0.9997229\n",
      "223 0.95567226\n",
      "224 0.0016461303\n",
      "225 0.00015640503\n",
      "226 9.97025e-06\n",
      "227 0.9988865\n",
      "228 0.8941169\n",
      "229 2.3212715e-08\n",
      "230 0.00014008002\n",
      "231 7.933399e-07\n",
      "232 0.21534894\n",
      "233 0.044843644\n",
      "234 8.444474e-05\n",
      "235 0.0014824147\n",
      "236 8.667405e-06\n",
      "237 0.00022286703\n",
      "238 0.58645016\n",
      "239 0.9999919\n",
      "240 0.00019353878\n",
      "241 0.009070827\n",
      "242 0.00038174947\n",
      "243 1.0\n",
      "244 0.99992824\n",
      "245 0.99999404\n",
      "246 1.02898824e-07\n",
      "247 0.9770469\n",
      "248 2.1735068e-06\n",
      "249 0.9999856\n",
      "250 0.4536796\n",
      "251 8.4758285e-06\n",
      "252 0.9815191\n",
      "253 0.9995546\n",
      "254 0.9607743\n",
      "255 0.9999974\n",
      "256 1.9139766e-06\n",
      "257 0.3235071\n",
      "258 0.99919754\n",
      "259 0.9999192\n",
      "260 1.0\n",
      "261 1.0\n",
      "262 0.9949427\n",
      "263 0.99994314\n",
      "264 0.00034226733\n",
      "265 0.9999888\n",
      "266 0.99807346\n",
      "267 0.22360608\n",
      "268 0.9937791\n",
      "269 0.9917052\n",
      "270 0.9998536\n",
      "271 0.35873\n",
      "272 1.0\n",
      "273 0.9969921\n",
      "274 0.043021113\n",
      "275 2.6710946e-08\n",
      "276 0.94019175\n",
      "277 0.99297214\n",
      "278 9.481343e-09\n",
      "279 6.296247e-05\n",
      "280 3.6666388e-06\n",
      "281 0.99933225\n",
      "282 3.6952764e-07\n",
      "283 1.0\n",
      "284 0.9999323\n",
      "285 0.00043367426\n",
      "286 0.60275006\n",
      "287 0.4031219\n",
      "288 8.383972e-06\n",
      "289 6.666262e-06\n",
      "290 0.0018120274\n",
      "291 2.2366923e-08\n",
      "292 1.0\n",
      "293 0.9999999\n",
      "294 0.010899608\n",
      "295 0.90852565\n",
      "296 0.99998224\n",
      "297 0.00025257294\n",
      "298 0.99998355\n",
      "299 0.083571896\n",
      "300 0.99999857\n",
      "301 0.006216978\n",
      "302 1.0\n",
      "303 0.8559849\n",
      "304 2.8345337e-05\n",
      "305 0.99976677\n",
      "306 0.5247902\n",
      "307 0.9941757\n",
      "308 0.9967264\n",
      "309 9.1597036e-10\n",
      "310 0.9665189\n",
      "311 0.99592066\n",
      "312 4.864325e-07\n",
      "313 0.9999999\n",
      "314 0.9999989\n",
      "315 0.99992895\n",
      "316 4.395115e-11\n",
      "317 1.3304549e-06\n",
      "318 0.99997246\n",
      "319 1.0\n",
      "320 0.808018\n",
      "321 0.99979407\n",
      "322 0.00025348025\n",
      "323 1.3945059e-08\n",
      "324 1.0\n",
      "325 0.9999547\n",
      "326 8.979276e-08\n",
      "327 0.06689167\n",
      "328 0.9999815\n",
      "329 0.9970657\n",
      "330 0.4301127\n",
      "331 4.7351025e-09\n",
      "332 0.9999976\n",
      "333 0.8974994\n",
      "334 0.9999999\n",
      "335 0.014782456\n",
      "336 0.0013730178\n",
      "337 3.2804102e-09\n",
      "338 4.337985e-07\n",
      "339 3.738697e-05\n",
      "340 0.62121767\n",
      "341 0.46586844\n",
      "342 0.99471337\n",
      "343 2.3227736e-07\n",
      "344 0.97952616\n",
      "345 0.99951935\n",
      "346 0.9999025\n",
      "347 0.00074498396\n",
      "348 0.9999887\n",
      "349 0.0014875443\n",
      "350 0.9996437\n",
      "351 1.0\n",
      "352 0.38555107\n",
      "353 6.0489965e-05\n",
      "354 0.71020734\n",
      "355 0.9999999\n",
      "356 0.2807592\n",
      "357 0.9999987\n",
      "358 0.9725073\n",
      "359 0.99976605\n",
      "360 3.2926106e-05\n",
      "361 0.9999906\n",
      "362 0.9999976\n",
      "363 0.9960898\n",
      "364 0.9915473\n",
      "365 3.4828412e-05\n",
      "366 1.4056958e-07\n",
      "367 0.0001386758\n",
      "368 0.02795909\n",
      "369 0.9998857\n",
      "370 0.0016874501\n",
      "371 0.99991035\n",
      "372 1.9402592e-06\n",
      "373 0.2466729\n",
      "374 2.1496e-07\n",
      "375 0.99998295\n",
      "376 6.01608e-06\n",
      "377 1.0\n",
      "378 0.99992394\n",
      "379 0.0013363506\n",
      "380 0.99754035\n",
      "381 0.42052796\n",
      "382 0.99999774\n",
      "383 0.00073977135\n",
      "384 0.9998778\n",
      "385 0.010337828\n",
      "386 0.99992466\n",
      "387 0.9888792\n",
      "388 0.00079975085\n",
      "389 1.7478449e-12\n",
      "390 1.0\n",
      "391 0.9999957\n",
      "392 0.1044966\n",
      "393 0.0024970556\n",
      "394 0.003472142\n",
      "395 1.0\n",
      "396 0.8344962\n",
      "397 0.003726861\n",
      "398 0.9999695\n",
      "399 0.99995685\n",
      "400 0.1048913\n",
      "401 0.9978119\n",
      "402 0.4812253\n",
      "403 2.5644695e-06\n",
      "404 4.0530867e-05\n",
      "405 0.9999753\n",
      "406 0.99997044\n",
      "407 1.0\n",
      "408 0.96129674\n",
      "409 0.0013522112\n",
      "410 0.99866486\n",
      "411 0.9999999\n",
      "412 0.06447256\n",
      "413 0.96217144\n",
      "414 0.0093099205\n",
      "415 8.398859e-05\n",
      "416 0.99999964\n",
      "417 0.9999814\n",
      "418 0.99995875\n",
      "419 0.9999558\n",
      "420 0.9999982\n",
      "421 0.041295655\n",
      "422 0.04718556\n",
      "423 0.75629807\n",
      "424 1.3092858e-07\n",
      "425 0.9998072\n",
      "426 0.99395156\n",
      "427 0.9999951\n",
      "428 0.99820983\n",
      "429 8.41628e-06\n",
      "430 0.999998\n",
      "431 1.7826482e-08\n",
      "432 0.06653224\n",
      "433 0.9988444\n",
      "434 0.9998056\n",
      "435 1.0\n",
      "436 6.523601e-09\n",
      "437 5.7619654e-06\n",
      "438 1.7060337e-07\n",
      "439 0.99999845\n",
      "440 0.01008902\n",
      "441 0.015181776\n",
      "442 0.04377281\n",
      "443 0.024740575\n",
      "444 0.9998909\n",
      "445 1.0\n",
      "446 0.9999685\n",
      "447 0.9780759\n",
      "448 3.661205e-05\n",
      "449 0.92473644\n",
      "450 0.0001700445\n",
      "451 1.0\n",
      "452 0.99991584\n",
      "453 0.9999747\n",
      "454 0.9928606\n",
      "455 0.9999609\n",
      "456 1.0\n",
      "457 2.4282806e-06\n",
      "458 6.326081e-06\n",
      "459 0.13075127\n",
      "460 0.9783595\n",
      "461 0.99685425\n",
      "462 0.9994752\n",
      "463 0.9999057\n",
      "464 0.9999968\n",
      "465 0.93403286\n",
      "466 0.038073633\n",
      "467 0.00027183126\n",
      "468 4.2784217e-05\n",
      "469 0.99429566\n",
      "470 8.126663e-07\n",
      "471 0.9951267\n",
      "472 2.606038e-10\n",
      "473 0.9967361\n",
      "474 0.99999535\n",
      "475 2.7220588e-06\n",
      "476 0.51992065\n",
      "477 0.112213604\n",
      "478 0.94329244\n",
      "479 1.0\n",
      "480 5.9112085e-06\n",
      "481 0.9734795\n",
      "482 4.967553e-05\n",
      "483 0.9612856\n",
      "484 1.0964118e-05\n",
      "485 6.108146e-12\n",
      "486 0.9555744\n",
      "487 0.9999995\n",
      "488 0.0062052286\n",
      "489 1.3625644e-06\n",
      "490 0.0035626849\n",
      "491 0.99303997\n",
      "492 0.85251147\n",
      "493 0.9986093\n",
      "494 0.78341275\n",
      "495 0.99999917\n",
      "496 0.5854157\n",
      "497 0.9999999\n",
      "498 2.9881794e-06\n",
      "499 5.8963646e-11\n",
      "500 0.9942562\n",
      "501 2.6220985e-07\n",
      "502 0.051066015\n",
      "503 0.0013098238\n",
      "504 0.99997497\n",
      "505 0.16067903\n",
      "506 0.99999976\n",
      "507 0.9999912\n",
      "508 0.99625266\n",
      "509 1.0\n",
      "510 0.061583992\n",
      "511 0.0022303497\n",
      "512 0.0043098256\n",
      "513 0.9999999\n",
      "514 0.6408148\n",
      "515 1.0\n",
      "516 5.6662768e-05\n",
      "517 0.876406\n",
      "518 0.9813964\n",
      "519 0.99983716\n",
      "520 1.0\n",
      "521 1.2140771e-07\n",
      "522 1.0\n",
      "523 0.99656576\n",
      "524 2.013023e-09\n",
      "525 1.3883179e-06\n",
      "526 0.998844\n",
      "527 1.0\n",
      "528 1.0\n",
      "529 0.65363514\n",
      "530 0.025485124\n",
      "531 0.00037187187\n",
      "532 0.99045944\n",
      "533 0.9999937\n",
      "534 0.9756865\n",
      "535 0.0087617235\n",
      "536 0.99956125\n",
      "537 1.9667825e-06\n",
      "538 0.9999994\n",
      "539 0.95676047\n",
      "540 0.9917726\n",
      "541 1.2421854e-07\n",
      "542 0.9921027\n",
      "543 0.00043005112\n",
      "544 0.9999989\n",
      "545 1.9158768e-05\n",
      "546 0.99998236\n",
      "547 0.009111949\n",
      "548 0.84749925\n",
      "549 0.9987871\n",
      "550 0.99975175\n",
      "551 0.9725409\n",
      "552 3.4557746e-09\n",
      "553 0.0005868801\n",
      "554 8.0567615e-11\n",
      "555 0.9996669\n",
      "556 0.9999473\n",
      "557 9.320689e-05\n",
      "558 0.2879036\n",
      "559 0.33027163\n",
      "560 0.60529023\n",
      "561 0.008924588\n",
      "562 1.0\n",
      "563 0.99991155\n",
      "564 0.0007112107\n",
      "565 0.99998844\n",
      "566 0.9999994\n",
      "567 0.999859\n",
      "568 0.6569753\n",
      "569 9.0399686e-07\n",
      "570 0.99999905\n",
      "571 0.9998087\n",
      "572 1.0\n",
      "573 0.99998665\n",
      "574 5.4894874e-05\n",
      "575 3.2733208e-10\n",
      "576 0.00909783\n",
      "577 0.99999964\n",
      "578 1.6440237e-05\n",
      "579 0.99999154\n",
      "580 0.0014483884\n",
      "581 1.7668069e-07\n",
      "582 0.004662429\n",
      "583 0.5644058\n",
      "584 0.2559821\n",
      "585 0.011199213\n",
      "586 0.9999999\n",
      "587 0.12111146\n",
      "588 0.15598379\n",
      "589 0.9985549\n",
      "590 0.9992481\n",
      "591 1.8864735e-06\n",
      "592 0.9779082\n",
      "593 0.99987304\n",
      "594 0.9999708\n",
      "595 0.019347746\n",
      "596 0.00050207606\n",
      "597 0.040069077\n",
      "598 0.3209693\n",
      "599 0.5018661\n",
      "600 2.4640494e-06\n",
      "601 8.759816e-07\n",
      "602 0.9896515\n",
      "603 0.1366845\n",
      "604 0.99972266\n",
      "605 0.99970394\n",
      "606 0.9802782\n",
      "607 1.0\n",
      "608 0.9860095\n",
      "609 2.1222904e-05\n",
      "610 0.99164397\n",
      "611 0.37784413\n",
      "612 0.00035165527\n",
      "613 0.9773022\n",
      "614 0.99923\n",
      "615 0.98954076\n",
      "616 0.9693526\n",
      "617 0.0013040873\n",
      "618 1.7791118e-12\n",
      "619 0.99895966\n",
      "620 1.4945999e-06\n",
      "621 1.6056147e-08\n",
      "622 0.9999851\n",
      "623 0.731596\n",
      "624 0.915417\n",
      "625 0.9999958\n",
      "626 0.00018325524\n",
      "627 0.9999931\n",
      "628 7.2839546e-05\n",
      "629 0.3926099\n",
      "630 0.030776538\n",
      "631 7.625736e-07\n",
      "632 0.99787915\n",
      "633 9.754379e-06\n",
      "634 0.99999964\n",
      "635 0.98039126\n",
      "636 5.484181e-07\n",
      "637 0.9990778\n",
      "638 0.9984066\n",
      "639 0.032954987\n",
      "640 0.95823604\n",
      "641 0.9999913\n",
      "642 0.013255027\n",
      "643 0.011294052\n",
      "644 0.9999945\n",
      "645 0.9999999\n",
      "646 2.85166e-11\n",
      "647 2.7269612e-05\n",
      "648 0.8405791\n",
      "649 1.0\n",
      "650 0.95121044\n",
      "651 0.9857625\n",
      "652 0.96341187\n",
      "653 0.97800046\n",
      "654 0.9999975\n",
      "655 0.99996746\n",
      "656 0.6311306\n",
      "657 0.9961869\n",
      "658 1.0\n",
      "659 0.9590372\n",
      "660 1.216707e-07\n",
      "661 0.00016469129\n",
      "662 4.9079592e-08\n",
      "663 0.99999833\n",
      "664 2.3815861e-05\n",
      "665 0.67699885\n",
      "666 0.9999999\n",
      "667 9.3683263e-07\n",
      "668 0.9996736\n",
      "669 0.0002417255\n",
      "670 0.9999982\n",
      "671 4.959012e-07\n",
      "672 4.3764628e-10\n",
      "673 0.9607422\n",
      "674 1.5717314e-05\n",
      "675 0.94940484\n",
      "676 0.026505437\n",
      "677 0.99999774\n",
      "678 1.6555989e-05\n",
      "679 0.99161047\n",
      "680 0.99112344\n",
      "681 0.99998534\n",
      "682 0.9293411\n",
      "683 0.9885395\n",
      "684 0.06478723\n",
      "685 0.00036968655\n",
      "686 0.0048923907\n",
      "687 0.9999956\n",
      "688 0.99999666\n",
      "689 0.0003668925\n",
      "690 0.012443623\n",
      "691 0.9974638\n",
      "692 0.99976426\n",
      "693 0.06156877\n",
      "694 0.99999785\n",
      "695 0.84165996\n",
      "696 3.0157803e-08\n",
      "697 0.99954885\n",
      "698 0.9894978\n",
      "699 0.98169553\n",
      "700 0.99383414\n",
      "701 0.99095386\n",
      "702 0.06130775\n",
      "703 0.5803258\n",
      "704 0.99999845\n",
      "705 0.04700882\n",
      "706 0.0019895306\n",
      "707 3.647068e-09\n",
      "708 0.0013259818\n",
      "709 1.0068715e-10\n",
      "710 0.9994814\n",
      "711 0.00023101454\n",
      "712 0.9785048\n",
      "713 0.003463677\n",
      "714 0.9982134\n",
      "715 0.09505601\n",
      "716 0.9995646\n",
      "717 0.009898765\n",
      "718 0.79300976\n",
      "719 0.0006717783\n",
      "720 0.999933\n",
      "721 0.9913351\n",
      "722 0.9999715\n",
      "723 0.24257848\n",
      "724 0.00016681477\n",
      "725 0.998599\n",
      "726 0.00043895555\n",
      "727 3.795554e-05\n",
      "728 0.9999976\n",
      "729 0.9999846\n",
      "730 0.9935231\n",
      "731 0.856388\n",
      "732 0.993721\n",
      "733 0.03579868\n",
      "734 0.999997\n",
      "735 0.9998411\n",
      "736 0.9992513\n",
      "737 5.8347073e-08\n",
      "738 3.7830617e-08\n",
      "739 0.99989426\n",
      "740 1.0\n",
      "741 0.18264972\n",
      "742 1.2865273e-07\n",
      "743 1.6184093e-05\n",
      "744 0.15508579\n",
      "745 9.8238794e-05\n",
      "746 0.99999917\n",
      "747 0.001877588\n",
      "748 0.14501438\n",
      "749 1.8735587e-05\n",
      "750 0.07603944\n",
      "751 1.0474836e-07\n",
      "752 0.006125864\n",
      "753 0.99923575\n",
      "754 1.7813094e-06\n",
      "755 0.97571534\n",
      "756 0.7712617\n",
      "757 0.27122003\n",
      "758 0.9999999\n",
      "759 0.00015539685\n",
      "760 0.9999969\n",
      "761 0.0005530572\n",
      "762 3.5839428e-06\n",
      "763 0.0017284885\n",
      "764 0.23746307\n",
      "765 0.98126113\n",
      "766 0.99999785\n",
      "767 0.014573283\n",
      "768 0.9999423\n",
      "769 0.0004800574\n",
      "770 2.3257958e-06\n",
      "771 0.020317338\n",
      "772 0.4645397\n",
      "773 0.9998554\n",
      "774 8.280564e-07\n",
      "775 0.88664997\n",
      "776 0.5956819\n",
      "777 0.00045130416\n",
      "778 0.99999666\n",
      "779 0.025736779\n",
      "780 0.9999937\n",
      "781 0.999964\n",
      "782 0.06220748\n",
      "783 0.012251461\n",
      "784 0.9999713\n",
      "785 3.4044064e-08\n",
      "786 0.97296786\n",
      "787 0.99992263\n",
      "788 0.97602683\n",
      "789 0.60093087\n",
      "790 0.99986005\n",
      "791 0.0010120248\n",
      "792 0.5536326\n",
      "793 1.7723247e-08\n",
      "794 0.9961462\n",
      "795 0.682696\n",
      "796 0.98868024\n",
      "797 8.038354e-08\n",
      "798 0.99999547\n",
      "799 0.055476286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 0.8936643\n",
      "801 0.114695355\n",
      "802 1.0\n",
      "803 0.08978769\n",
      "804 2.11075e-08\n",
      "805 0.8836031\n",
      "806 1.0\n",
      "807 1.0868394e-05\n",
      "808 6.357288e-06\n",
      "809 0.03429558\n",
      "810 0.9999776\n",
      "811 0.0019665218\n",
      "812 0.99999356\n",
      "813 0.9225975\n",
      "814 0.9999999\n",
      "815 0.00043167474\n",
      "816 0.9975363\n",
      "817 1.2446603e-07\n",
      "818 0.000143673\n",
      "819 0.9999944\n",
      "820 0.99999774\n",
      "821 0.99998844\n",
      "822 2.4386485e-05\n",
      "823 0.15883419\n",
      "824 0.999998\n",
      "825 0.117097996\n",
      "826 4.5861702e-07\n",
      "827 0.9996737\n",
      "828 0.9999987\n",
      "829 0.0026772781\n",
      "830 0.9999776\n",
      "831 0.99999785\n",
      "832 0.9999223\n",
      "833 0.55274326\n",
      "834 0.9999999\n",
      "835 0.7787279\n",
      "836 2.8262712e-05\n",
      "837 8.5973056e-08\n",
      "838 0.9974727\n",
      "839 0.03581512\n",
      "840 0.5151117\n",
      "841 0.99999833\n",
      "842 0.002386049\n",
      "843 0.9972934\n",
      "844 0.91206545\n",
      "845 0.9904102\n",
      "846 8.7762416e-08\n",
      "847 0.9952201\n",
      "848 0.01903663\n",
      "849 0.0020699077\n",
      "850 0.0516829\n",
      "851 0.5522244\n",
      "852 0.999967\n",
      "853 0.99997616\n",
      "854 0.61056715\n",
      "855 0.00020253322\n",
      "856 0.03688654\n",
      "857 6.315466e-06\n",
      "858 0.7935731\n",
      "859 0.86596876\n",
      "860 0.9997527\n",
      "861 0.9623243\n",
      "862 0.8726427\n",
      "863 0.98686326\n",
      "864 1.0\n",
      "865 3.3730994e-06\n",
      "866 0.11904335\n",
      "867 7.10066e-05\n",
      "868 0.3927123\n",
      "869 0.00014107936\n",
      "870 0.9999999\n",
      "871 0.005591619\n",
      "872 2.3937199e-07\n",
      "873 0.00027183126\n",
      "874 0.011739465\n",
      "875 0.99734145\n",
      "876 0.9999999\n",
      "877 0.7505982\n",
      "878 0.9997569\n",
      "879 0.86486167\n",
      "880 0.9989826\n",
      "881 0.08638561\n",
      "882 0.0025665918\n",
      "883 0.0014677689\n",
      "884 0.99927753\n",
      "885 0.9823056\n",
      "886 2.8910054e-06\n",
      "887 1.361408e-07\n",
      "888 0.9998709\n",
      "889 0.9969331\n",
      "890 0.45599738\n",
      "891 3.6605407e-08\n",
      "892 0.67494965\n",
      "893 0.00020064878\n",
      "894 8.232711e-06\n",
      "895 0.8354556\n",
      "896 0.0009661645\n",
      "897 0.8668677\n",
      "898 5.0062436e-06\n",
      "899 0.0074013676\n",
      "900 1.1525705e-05\n",
      "901 0.009389813\n",
      "902 4.516128e-07\n",
      "903 0.9999734\n",
      "904 0.9995875\n",
      "905 0.49474493\n",
      "906 0.5530195\n",
      "907 0.00021505066\n",
      "908 0.997696\n",
      "909 1.2645275e-09\n",
      "910 0.9998605\n",
      "911 1.0\n",
      "912 0.9999217\n",
      "913 0.65659666\n",
      "914 0.9999969\n",
      "915 0.02376505\n",
      "916 0.9999411\n",
      "917 0.99962807\n",
      "918 0.15389213\n",
      "919 7.251955e-05\n",
      "920 0.99158055\n",
      "921 0.0040525515\n",
      "922 0.0016226728\n",
      "923 0.71013135\n",
      "924 0.9330041\n",
      "925 0.01346787\n",
      "926 0.99998355\n",
      "927 0.12787704\n",
      "928 0.004918215\n",
      "929 1.4632548e-06\n",
      "930 3.7208792e-06\n",
      "931 7.733887e-09\n",
      "932 0.035398275\n",
      "933 0.9999136\n",
      "934 0.99999845\n",
      "935 0.9999901\n",
      "936 0.0049573053\n",
      "937 2.1316669e-06\n",
      "938 0.99197817\n",
      "939 2.1121986e-07\n",
      "940 0.9293484\n",
      "941 0.9999999\n",
      "942 8.187572e-06\n",
      "943 0.9999863\n",
      "944 0.11925054\n",
      "945 1.8648385e-05\n",
      "946 0.9999999\n",
      "947 0.993032\n",
      "948 0.00089946314\n",
      "949 0.9997563\n",
      "950 0.0076116375\n",
      "951 3.0211777e-05\n",
      "952 0.049890615\n",
      "953 0.99998796\n",
      "954 0.99999976\n",
      "955 0.12188812\n",
      "956 0.9937111\n",
      "957 0.05440756\n",
      "958 1.5695107e-06\n",
      "959 1.0\n",
      "960 0.7671146\n",
      "961 2.0008487e-05\n",
      "962 0.8697958\n",
      "963 0.2283191\n",
      "964 1.0\n",
      "965 0.9887244\n",
      "966 5.0744206e-05\n",
      "967 8.4485735e-10\n",
      "968 0.9676012\n",
      "969 0.0031936606\n",
      "970 0.0044920254\n",
      "971 0.036875114\n",
      "972 2.8657024e-07\n",
      "973 0.9999727\n",
      "974 0.9999989\n",
      "975 0.00016586298\n",
      "976 1.0\n",
      "977 0.036079723\n",
      "978 0.11815311\n",
      "979 6.856186e-05\n",
      "980 0.9923028\n",
      "981 0.85976344\n",
      "982 0.9999914\n",
      "983 0.9980404\n",
      "984 5.9132896e-07\n",
      "985 0.96461153\n",
      "986 0.99997556\n",
      "987 0.97552806\n",
      "988 0.99989974\n",
      "989 0.99999297\n",
      "990 0.9982248\n",
      "991 4.921444e-07\n",
      "992 0.0012487926\n",
      "993 2.2632364e-06\n",
      "994 0.99436873\n",
      "995 0.6342662\n",
      "996 0.64272845\n",
      "997 0.9744169\n",
      "998 0.0053235525\n",
      "999 0.99940336\n",
      "1000 0.9246186\n",
      "1001 0.99985933\n",
      "1002 0.99987066\n",
      "1003 0.0017464992\n",
      "1004 0.9976292\n",
      "1005 0.9999999\n",
      "1006 0.0014225601\n",
      "1007 0.039537486\n",
      "1008 0.31380957\n",
      "1009 0.8437378\n",
      "1010 0.0063095675\n",
      "1011 0.99991524\n",
      "1012 0.008042701\n",
      "1013 0.0076202657\n",
      "1014 0.011476579\n",
      "1015 1.0\n",
      "1016 0.00071623136\n",
      "1017 0.99994946\n",
      "1018 0.0002780527\n",
      "1019 0.008150685\n",
      "1020 0.23700666\n",
      "1021 0.9998776\n",
      "1022 0.95132536\n",
      "1023 6.860177e-08\n",
      "1024 0.4126621\n",
      "1025 0.9750304\n",
      "1026 0.020712795\n",
      "1027 0.55341476\n",
      "1028 0.017272303\n",
      "1029 0.99994195\n",
      "1030 0.943469\n",
      "1031 2.7449887e-06\n",
      "1032 0.00075224054\n",
      "1033 0.9999975\n",
      "1034 0.98361444\n",
      "1035 0.8397447\n",
      "1036 1.1427257e-09\n",
      "1037 5.4422037e-07\n",
      "1038 0.002250802\n",
      "1039 0.0073833447\n",
      "1040 9.667366e-05\n",
      "1041 0.9987551\n",
      "1042 1.0\n",
      "1043 0.99995756\n",
      "1044 0.8625414\n",
      "1045 0.99955267\n",
      "1046 0.8782958\n",
      "1047 0.00014883833\n",
      "1048 0.47381604\n",
      "1049 0.99709487\n",
      "1050 4.5880946e-10\n",
      "1051 0.00823081\n",
      "1052 0.0050571472\n",
      "1053 0.9999256\n",
      "1054 0.9997789\n",
      "1055 0.5250946\n",
      "1056 0.99999833\n",
      "1057 0.7108993\n",
      "1058 0.30679068\n",
      "1059 0.17049687\n",
      "1060 0.017874954\n",
      "1061 0.99995863\n",
      "1062 7.599516e-06\n",
      "1063 2.346599e-05\n",
      "1064 6.346094e-06\n",
      "1065 1.0\n",
      "1066 7.8734304e-11\n",
      "1067 0.009034024\n",
      "1068 0.00042531514\n",
      "1069 0.9999989\n",
      "1070 0.68605036\n",
      "1071 0.98891747\n",
      "1072 0.9879475\n",
      "1073 7.494037e-06\n",
      "1074 0.9999906\n",
      "1075 0.36770767\n",
      "1076 0.99996674\n",
      "1077 0.9998584\n",
      "1078 0.99970573\n",
      "1079 0.90827924\n",
      "1080 0.99999535\n",
      "1081 0.053127453\n",
      "1082 0.98798007\n",
      "1083 0.14257935\n",
      "1084 0.53921616\n",
      "1085 0.7510759\n",
      "1086 0.99536127\n",
      "1087 0.0019762593\n",
      "1088 0.87719434\n",
      "1089 0.11975574\n",
      "1090 0.42277882\n",
      "1091 0.23389597\n",
      "1092 3.540324e-07\n",
      "1093 7.5624973e-07\n",
      "1094 0.9999999\n",
      "1095 0.9999999\n",
      "1096 0.90097016\n",
      "1097 0.9999876\n",
      "1098 0.9253768\n",
      "1099 0.06952914\n",
      "1100 0.99499476\n",
      "1101 0.062376186\n",
      "1102 0.4333893\n",
      "1103 0.99946827\n",
      "1104 0.81868595\n",
      "1105 0.32489473\n",
      "1106 2.4514005e-05\n",
      "1107 0.00096132\n",
      "1108 0.9998518\n",
      "1109 0.9999999\n",
      "1110 0.006270491\n",
      "1111 0.9999938\n",
      "1112 0.010338789\n",
      "1113 1.0\n",
      "1114 3.2276654e-05\n",
      "1115 0.9996264\n",
      "1116 0.4413965\n",
      "1117 0.9986098\n",
      "1118 0.99997973\n",
      "1119 0.99996674\n",
      "1120 3.131898e-05\n",
      "1121 0.9790181\n",
      "1122 8.152539e-05\n",
      "1123 0.9653828\n",
      "1124 0.011781329\n",
      "1125 5.2225805e-06\n",
      "1126 0.0008744027\n",
      "1127 0.02453275\n",
      "1128 9.908583e-08\n",
      "1129 0.99999857\n",
      "1130 2.071267e-05\n",
      "1131 0.001153903\n",
      "1132 0.75894153\n",
      "1133 0.99993944\n",
      "1134 0.97105473\n",
      "1135 0.18214972\n",
      "1136 0.3873085\n",
      "1137 2.3019923e-06\n",
      "1138 0.007891873\n",
      "1139 0.99967897\n",
      "1140 0.9999794\n",
      "1141 2.520572e-12\n",
      "1142 0.0002892957\n",
      "1143 0.9999602\n",
      "1144 3.8341847e-07\n",
      "1145 4.0263234e-07\n",
      "1146 0.48661986\n",
      "1147 1.0\n",
      "1148 4.801084e-06\n",
      "1149 0.94284403\n",
      "1150 0.9412133\n",
      "1151 0.99999595\n",
      "1152 0.98972684\n",
      "1153 0.99914396\n",
      "1154 0.99997175\n",
      "1155 0.99995005\n",
      "1156 4.0075116e-05\n",
      "1157 0.03667226\n",
      "1158 1.0\n",
      "1159 0.2809884\n",
      "1160 0.999767\n",
      "1161 0.98078555\n",
      "1162 0.25136116\n",
      "1163 0.99882334\n",
      "1164 6.1043656e-06\n",
      "1165 2.4589635e-08\n",
      "1166 0.9999993\n",
      "1167 0.9998572\n",
      "1168 0.99208987\n",
      "1169 0.9966732\n",
      "1170 0.8431844\n",
      "1171 0.0024150386\n",
      "1172 0.0065711965\n",
      "1173 0.069849245\n",
      "1174 0.99999976\n",
      "1175 4.306074e-07\n",
      "1176 0.99975115\n",
      "1177 2.496497e-06\n",
      "1178 0.9999994\n",
      "1179 0.0024083515\n",
      "1180 0.00023211735\n",
      "1181 0.99999416\n",
      "1182 1.0\n",
      "1183 0.7843064\n",
      "1184 0.0993648\n",
      "1185 2.0332564e-05\n",
      "1186 0.7301596\n",
      "1187 1.0\n",
      "1188 0.9999999\n",
      "1189 0.0002635208\n",
      "1190 0.87919587\n",
      "1191 0.050227433\n",
      "1192 0.0073965276\n",
      "1193 2.5118285e-07\n",
      "1194 0.999481\n",
      "1195 0.091227874\n",
      "1196 0.66041654\n",
      "1197 0.08828631\n",
      "1198 0.005021898\n",
      "1199 4.6127966e-06\n",
      "1200 0.9999957\n",
      "1201 0.985307\n",
      "1202 0.0011392588\n",
      "1203 0.9988181\n",
      "1204 0.008443387\n",
      "1205 0.9999039\n",
      "1206 0.9979\n",
      "1207 8.356114e-06\n",
      "1208 0.018022027\n",
      "1209 0.0024613054\n",
      "1210 0.73161787\n",
      "1211 0.017677007\n",
      "1212 0.9986777\n",
      "1213 0.999689\n",
      "1214 0.9999975\n",
      "1215 0.9999758\n",
      "1216 0.006974788\n",
      "1217 1.2329008e-07\n",
      "1218 0.92109114\n",
      "1219 0.9997265\n",
      "1220 0.18955368\n",
      "1221 0.9808008\n",
      "1222 0.32658562\n",
      "1223 4.191511e-08\n",
      "1224 0.9930593\n",
      "1225 0.7787095\n",
      "1226 0.9998919\n",
      "1227 0.9608601\n",
      "1228 1.5758002e-05\n",
      "1229 1.2368205e-06\n",
      "1230 2.4159912e-05\n",
      "1231 0.08110158\n",
      "1232 0.9999989\n",
      "1233 0.026475588\n",
      "1234 0.9899075\n",
      "1235 0.00028790566\n",
      "1236 0.9999995\n",
      "1237 0.99838805\n",
      "1238 0.99669844\n",
      "1239 1.0\n",
      "1240 0.99860734\n",
      "1241 0.00023212995\n",
      "1242 0.99616206\n",
      "1243 0.00013599328\n",
      "1244 0.99995506\n",
      "1245 0.9999995\n",
      "1246 0.12599623\n",
      "1247 0.37772176\n",
      "1248 1.0\n",
      "1249 0.00021553514\n",
      "1250 0.99949574\n",
      "1251 0.0005519484\n",
      "1252 3.285655e-06\n",
      "1253 0.99999857\n",
      "1254 0.0030335824\n",
      "1255 0.9998672\n",
      "1256 0.9999049\n",
      "1257 5.204387e-11\n",
      "1258 0.08790367\n",
      "1259 0.4364472\n",
      "1260 0.93928534\n",
      "1261 0.0009238313\n",
      "1262 7.4191115e-07\n",
      "1263 0.026031697\n",
      "1264 0.9976609\n",
      "1265 1.9586721e-05\n",
      "1266 0.99999535\n",
      "1267 5.994353e-07\n",
      "1268 0.99987006\n",
      "1269 0.10934633\n",
      "1270 2.8758043e-06\n",
      "1271 0.9913647\n",
      "1272 0.28538707\n",
      "1273 2.4434453e-06\n",
      "1274 6.750754e-05\n",
      "1275 0.9999343\n",
      "1276 0.998114\n",
      "1277 0.09611856\n",
      "1278 0.97290075\n",
      "1279 0.08086529\n",
      "1280 6.916419e-09\n",
      "1281 0.962159\n",
      "1282 4.378264e-11\n",
      "1283 4.0810933e-06\n",
      "1284 0.9999968\n",
      "1285 0.9999999\n",
      "1286 1.0\n",
      "1287 1.585452e-05\n",
      "1288 1.0\n",
      "1289 2.9780638e-05\n",
      "1290 0.026645245\n",
      "1291 0.00010331805\n",
      "1292 0.9999865\n",
      "1293 0.024266003\n",
      "1294 3.1426447e-05\n",
      "1295 0.0013422986\n",
      "1296 3.6575897e-05\n",
      "1297 0.0049383133\n",
      "1298 0.9737933\n",
      "1299 0.3702596\n",
      "1300 0.17323276\n",
      "1301 0.941815\n",
      "1302 3.979705e-09\n",
      "1303 0.024009952\n",
      "1304 0.83418244\n",
      "1305 0.9998332\n",
      "1306 0.76734257\n",
      "1307 0.9061046\n",
      "1308 0.9934906\n",
      "1309 0.9994055\n",
      "1310 0.505197\n",
      "1311 0.99981385\n",
      "1312 0.0059475475\n",
      "1313 0.0002724612\n",
      "1314 0.9999994\n",
      "1315 1.0\n",
      "1316 3.554645e-05\n",
      "1317 1.0\n",
      "1318 0.09681694\n",
      "1319 0.010791808\n",
      "1320 0.99999845\n",
      "1321 0.34630957\n",
      "1322 0.0007003753\n",
      "1323 0.8780448\n",
      "1324 0.2763139\n",
      "1325 0.832161\n",
      "1326 0.99767536\n",
      "1327 0.99998784\n",
      "1328 0.9997675\n",
      "1329 0.012336158\n",
      "1330 0.00017550946\n",
      "1331 0.011778941\n",
      "1332 0.9947919\n",
      "1333 0.9999796\n",
      "1334 0.62520236\n",
      "1335 0.00030868014\n",
      "1336 1.1661643e-05\n",
      "1337 0.9444108\n",
      "1338 0.9943001\n",
      "1339 0.9989549\n",
      "1340 0.99890065\n",
      "1341 1.5808788e-05\n",
      "1342 0.10146178\n",
      "1343 0.0001992101\n",
      "1344 0.9999796\n",
      "1345 0.8587537\n",
      "1346 0.044227373\n",
      "1347 9.061798e-06\n",
      "1348 0.025204603\n",
      "1349 0.0021661855\n",
      "1350 0.9888319\n",
      "1351 0.9999999\n",
      "1352 3.6371337e-06\n",
      "1353 0.9708846\n",
      "1354 0.98977166\n",
      "1355 0.99998736\n",
      "1356 0.9879946\n",
      "1357 0.99999785\n",
      "1358 0.43198317\n",
      "1359 0.16775341\n",
      "1360 0.9988674\n",
      "1361 0.99999976\n",
      "1362 1.3109876e-07\n",
      "1363 0.9999888\n",
      "1364 1.0\n",
      "1365 2.672038e-06\n",
      "1366 0.00017028025\n",
      "1367 0.99766785\n",
      "1368 3.1298302e-07\n",
      "1369 0.9996031\n",
      "1370 7.6249444e-07\n",
      "1371 0.45609784\n",
      "1372 1.4692547e-07\n",
      "1373 0.99989355\n",
      "1374 0.9976332\n",
      "1375 0.9999449\n",
      "1376 0.000103724065\n",
      "1377 0.99999976\n",
      "1378 0.23701903\n",
      "1379 0.9823706\n",
      "1380 1.0\n",
      "1381 0.99877316\n",
      "1382 0.42467493\n",
      "1383 1.1705538e-06\n",
      "1384 0.91055703\n",
      "1385 0.00010405167\n",
      "1386 1.0\n",
      "1387 3.860573e-05\n",
      "1388 0.99139786\n",
      "1389 0.0001991784\n",
      "1390 0.7713808\n",
      "1391 0.0013229154\n",
      "1392 0.99991274\n",
      "1393 0.99999976\n",
      "1394 0.99999464\n",
      "1395 0.75937176\n",
      "1396 0.79023844\n",
      "1397 0.8269712\n",
      "1398 0.036195036\n",
      "1399 0.73053557\n",
      "1400 0.22116546\n",
      "1401 0.07356329\n",
      "1402 0.9694905\n",
      "1403 0.9269012\n",
      "1404 0.4084038\n",
      "1405 0.025856026\n",
      "1406 0.09504939\n",
      "1407 0.99788696\n",
      "1408 0.99455947\n",
      "1409 0.9999894\n",
      "1410 0.76523244\n",
      "1411 3.1601354e-05\n",
      "1412 0.99998367\n",
      "1413 1.073365e-06\n",
      "1414 0.19948795\n",
      "1415 1.9854756e-06\n",
      "1416 0.3543091\n",
      "1417 0.6319693\n",
      "1418 0.9538678\n",
      "1419 0.00253131\n",
      "1420 0.009491064\n",
      "1421 0.9990207\n",
      "1422 0.9999999\n",
      "1423 0.99999213\n",
      "1424 7.1677746e-06\n",
      "1425 0.9999999\n",
      "1426 0.004907063\n",
      "1427 0.04355172\n",
      "1428 0.001315973\n",
      "1429 0.98697555\n",
      "1430 0.4684941\n",
      "1431 1.1772431e-08\n",
      "1432 0.9999223\n",
      "1433 0.00013425246\n",
      "1434 0.00079979276\n",
      "1435 0.7764353\n",
      "1436 0.016319012\n",
      "1437 0.45784107\n",
      "1438 9.074718e-06\n",
      "1439 0.2721192\n",
      "1440 0.00063882663\n",
      "1441 0.115148894\n",
      "1442 0.9965514\n",
      "1443 0.9996394\n",
      "1444 9.630895e-08\n",
      "1445 0.012400078\n",
      "1446 0.04076799\n",
      "1447 0.99980825\n",
      "1448 0.8449886\n",
      "1449 0.00012426765\n",
      "1450 0.99999976\n",
      "1451 0.9999831\n",
      "1452 0.9603571\n",
      "1453 1.9468112e-08\n",
      "1454 0.43022782\n",
      "1455 0.1217457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1456 0.9999759\n",
      "1457 0.99958986\n",
      "1458 0.99994195\n",
      "1459 7.3719384e-06\n",
      "1460 0.012702265\n",
      "1461 0.9999931\n",
      "1462 7.1320943e-07\n",
      "1463 0.99998605\n",
      "1464 0.8405737\n",
      "1465 1.0\n",
      "1466 0.0015331024\n",
      "1467 0.9999999\n",
      "1468 1.0\n",
      "1469 0.46906844\n",
      "1470 1.549154e-05\n",
      "1471 0.00094060187\n",
      "1472 6.855494e-06\n",
      "1473 0.26999706\n",
      "1474 0.0003698977\n",
      "1475 1.844305e-05\n",
      "1476 0.00364532\n",
      "1477 0.000858199\n",
      "1478 0.0002025419\n",
      "1479 9.147051e-09\n",
      "1480 0.7315719\n",
      "1481 1.0\n",
      "1482 0.22107677\n",
      "1483 7.173574e-06\n",
      "1484 0.9999962\n",
      "1485 0.998911\n",
      "1486 0.084323846\n",
      "1487 0.99998057\n",
      "1488 0.9421767\n",
      "1489 0.02284655\n",
      "1490 0.9990062\n",
      "1491 0.0007996453\n",
      "1492 0.00011393971\n",
      "1493 0.9947743\n",
      "1494 0.99595\n",
      "1495 0.99969614\n",
      "1496 8.042454e-06\n",
      "1497 0.99916565\n",
      "1498 3.116998e-07\n",
      "1499 6.6732264e-06\n",
      "1500 1.12237375e-08\n",
      "1501 0.026085733\n",
      "1502 0.99862623\n",
      "1503 2.7250555e-05\n",
      "1504 2.994853e-05\n",
      "1505 1.0\n",
      "1506 0.0071424446\n",
      "1507 0.9661863\n",
      "1508 9.5587486e-05\n",
      "1509 0.99999964\n",
      "1510 0.99999475\n",
      "1511 0.9934853\n",
      "1512 1.6633914e-05\n",
      "1513 1.1355613e-05\n",
      "1514 0.00061678287\n",
      "1515 0.017853737\n",
      "1516 0.99057543\n",
      "1517 0.08558926\n",
      "1518 0.99995756\n",
      "1519 0.9999993\n",
      "1520 7.2070984e-06\n",
      "1521 0.0007620539\n",
      "1522 1.0\n",
      "1523 0.99796534\n",
      "1524 1.0\n",
      "1525 0.999985\n",
      "1526 0.06836028\n",
      "1527 0.9999896\n",
      "1528 0.7785292\n",
      "1529 8.548119e-07\n",
      "1530 0.010138247\n",
      "1531 0.9998442\n",
      "1532 1.0\n",
      "1533 1.0138931e-08\n",
      "1534 0.1586598\n",
      "1535 3.6251593e-09\n",
      "1536 0.995628\n",
      "1537 0.99904114\n",
      "1538 1.0\n",
      "1539 0.99999976\n",
      "1540 0.9739621\n",
      "1541 1.7521096e-06\n",
      "1542 0.99995434\n",
      "1543 0.99999976\n",
      "1544 0.91083527\n",
      "1545 0.9972493\n",
      "1546 0.86635303\n",
      "1547 2.546682e-08\n",
      "1548 0.0012413149\n",
      "1549 1.348745e-05\n",
      "1550 0.99960107\n",
      "1551 0.00029976864\n",
      "1552 0.9999919\n",
      "1553 0.9999703\n",
      "1554 0.63788235\n",
      "1555 1.0\n",
      "1556 0.0015174854\n",
      "1557 0.9999993\n",
      "1558 0.6290182\n",
      "1559 7.618409e-07\n",
      "1560 0.99942833\n",
      "1561 2.7272134e-05\n",
      "1562 1.0775444e-06\n",
      "1563 2.5913601e-05\n",
      "1564 8.776743e-06\n",
      "1565 5.26574e-05\n",
      "1566 0.0010407041\n",
      "1567 0.013487448\n",
      "1568 0.022209527\n",
      "1569 1.7565982e-05\n",
      "1570 0.7458352\n",
      "1571 0.43569434\n",
      "1572 0.9486712\n",
      "1573 0.120283306\n",
      "1574 0.985995\n",
      "1575 0.99977356\n",
      "1576 0.9805252\n",
      "1577 0.9997826\n",
      "1578 0.99045944\n",
      "1579 0.99999785\n",
      "1580 0.9991598\n",
      "1581 5.220712e-11\n",
      "1582 0.03343548\n",
      "1583 2.8859404e-05\n",
      "1584 0.38547754\n",
      "1585 0.99971336\n",
      "1586 9.390543e-05\n",
      "1587 0.99999976\n",
      "1588 0.99999094\n",
      "1589 0.08816309\n",
      "1590 0.9057582\n",
      "1591 9.1628027e-07\n",
      "1592 0.9923422\n",
      "1593 0.00011043981\n",
      "1594 0.9959487\n",
      "1595 0.9999887\n",
      "1596 0.99989355\n",
      "1597 0.9608706\n",
      "1598 0.0023715983\n",
      "1599 0.99793315\n",
      "1600 0.98941797\n",
      "1601 0.015880505\n",
      "1602 1.0\n",
      "1603 0.8442783\n",
      "1604 0.09376784\n",
      "1605 1.0\n",
      "1606 0.99998367\n",
      "1607 0.018158576\n",
      "1608 0.98217255\n",
      "1609 0.41168755\n",
      "1610 7.998269e-08\n",
      "1611 0.0004810833\n",
      "1612 0.001195171\n",
      "1613 2.0890834e-06\n",
      "1614 0.3932172\n",
      "1615 1.2828441e-05\n",
      "1616 0.9999999\n",
      "1617 0.010632969\n",
      "1618 0.8790644\n",
      "1619 0.02173957\n",
      "1620 0.99999785\n",
      "1621 0.99999905\n",
      "1622 1.0741862e-06\n",
      "1623 0.99554116\n",
      "1624 0.998293\n",
      "1625 3.7385256e-05\n",
      "1626 0.000117314456\n",
      "1627 0.0013810904\n",
      "1628 0.99997056\n",
      "1629 0.0030121384\n",
      "1630 3.3604418e-05\n",
      "1631 0.9722333\n",
      "1632 0.013403507\n",
      "1633 2.0874004e-05\n",
      "1634 0.9819002\n",
      "1635 0.9999999\n",
      "1636 0.9998803\n",
      "1637 3.8704036e-12\n",
      "1638 0.99948186\n",
      "1639 2.263204e-06\n",
      "1640 7.9955625e-10\n",
      "1641 0.4875465\n",
      "1642 0.9880264\n",
      "1643 0.9999285\n",
      "1644 0.9999857\n",
      "1645 1.0\n",
      "1646 0.9158143\n",
      "1647 0.99998116\n",
      "1648 0.8817104\n",
      "1649 2.162409e-08\n",
      "1650 0.99998057\n",
      "1651 0.007147982\n",
      "1652 0.0023412327\n",
      "1653 0.0025581806\n",
      "1654 0.99986553\n",
      "1655 0.99998236\n",
      "1656 0.012560967\n",
      "1657 0.013456559\n",
      "1658 5.541146e-05\n",
      "1659 0.0046399785\n",
      "1660 0.047644816\n",
      "1661 0.5167484\n",
      "1662 0.01840737\n",
      "1663 1.6779847e-11\n",
      "1664 0.007263819\n",
      "1665 0.9999614\n",
      "1666 0.9551021\n",
      "1667 0.99999976\n",
      "1668 0.0012733563\n",
      "1669 2.2432365e-09\n",
      "1670 1.1761566e-06\n",
      "1671 0.7523138\n",
      "1672 0.99396354\n",
      "1673 0.0133013455\n",
      "1674 0.99998426\n",
      "1675 1.2791706e-05\n",
      "1676 0.0009102534\n",
      "1677 0.99998415\n",
      "1678 0.0015980745\n",
      "1679 0.0864041\n",
      "1680 0.37008294\n",
      "1681 2.2994412e-08\n",
      "1682 0.9999999\n",
      "1683 1.0\n",
      "1684 0.0018800828\n",
      "1685 0.99055636\n",
      "1686 0.9999907\n",
      "1687 5.17729e-06\n",
      "1688 0.00023932195\n",
      "1689 0.9795074\n",
      "1690 0.9998405\n",
      "1691 4.2076335e-05\n",
      "1692 0.9690899\n",
      "1693 1.0\n",
      "1694 0.4457412\n",
      "1695 0.0004722\n",
      "1696 0.008573071\n",
      "1697 0.93316257\n",
      "1698 0.01692847\n",
      "1699 0.056091093\n",
      "1700 0.0019081171\n",
      "1701 4.3443856e-07\n",
      "1702 0.15932761\n",
      "1703 0.99999917\n",
      "1704 0.9999999\n",
      "1705 0.99990785\n",
      "1706 0.99984777\n",
      "1707 0.97015125\n",
      "1708 0.0072866282\n",
      "1709 0.99966943\n",
      "1710 0.330089\n",
      "1711 0.9972446\n",
      "1712 0.9749732\n",
      "1713 0.0010605822\n",
      "1714 0.001529833\n",
      "1715 0.00664673\n",
      "1716 9.618823e-05\n",
      "1717 0.99916124\n",
      "1718 5.8753067e-06\n",
      "1719 0.01150503\n",
      "1720 0.999995\n",
      "1721 0.1781725\n",
      "1722 1.0\n",
      "1723 1.3955508e-07\n",
      "1724 0.9999994\n",
      "1725 1.6633914e-05\n",
      "1726 0.99999917\n",
      "1727 3.4656223e-05\n",
      "1728 0.99971884\n",
      "1729 1.0\n",
      "1730 0.99984205\n",
      "1731 0.9781066\n",
      "1732 1.0\n",
      "1733 6.906089e-05\n",
      "1734 8.603658e-11\n",
      "1735 0.024396831\n",
      "1736 0.39615524\n",
      "1737 0.99806327\n",
      "1738 0.9999988\n",
      "1739 0.98253167\n",
      "1740 1.0\n",
      "1741 1.337007e-08\n",
      "1742 0.99999917\n",
      "1743 2.6356795e-06\n",
      "1744 0.9995484\n",
      "1745 0.57074153\n",
      "1746 0.99980956\n",
      "1747 0.9030071\n",
      "1748 0.8893923\n",
      "1749 1.1571875e-05\n",
      "1750 1.0313339e-08\n",
      "1751 0.9999715\n",
      "1752 0.9839722\n",
      "1753 3.127645e-05\n",
      "1754 0.9100753\n",
      "1755 0.8216618\n",
      "1756 0.9999993\n",
      "1757 2.8070068e-05\n",
      "1758 0.03260485\n",
      "1759 9.422299e-06\n",
      "1760 1.06223015e-05\n",
      "1761 0.002428808\n",
      "1762 0.96813565\n",
      "1763 1.6759546e-05\n",
      "1764 0.7557784\n",
      "1765 2.197093e-07\n",
      "1766 0.9999987\n",
      "1767 0.9970523\n",
      "1768 0.014612333\n",
      "1769 4.0564395e-05\n",
      "1770 0.07418289\n",
      "1771 0.0027511965\n",
      "1772 1.820424e-06\n",
      "1773 0.99950886\n",
      "1774 1.1790607e-06\n",
      "1775 0.000121612255\n",
      "1776 0.99699664\n",
      "1777 2.7791838e-12\n",
      "1778 0.97712076\n",
      "1779 7.207437e-07\n",
      "1780 0.98792624\n",
      "1781 0.00024218202\n",
      "1782 3.1016462e-08\n",
      "1783 7.1066717e-09\n",
      "1784 0.028181978\n",
      "1785 3.792005e-05\n",
      "1786 0.96989214\n",
      "1787 0.9998661\n",
      "1788 0.15517677\n",
      "1789 0.98981994\n",
      "1790 0.9999896\n",
      "1791 0.99996865\n",
      "1792 0.23019587\n",
      "1793 0.9999994\n",
      "1794 6.6223693e-06\n",
      "1795 0.99999344\n",
      "1796 0.9996238\n",
      "1797 0.054499615\n",
      "1798 0.09184526\n",
      "1799 2.6401904e-06\n",
      "1800 6.357818e-05\n",
      "1801 0.011234238\n",
      "1802 0.9803166\n",
      "1803 0.99980396\n",
      "1804 0.0004369508\n",
      "1805 0.9996221\n",
      "1806 0.9894448\n",
      "1807 2.1842961e-08\n",
      "1808 3.5372082e-08\n",
      "1809 0.90351427\n",
      "1810 0.08706313\n",
      "1811 8.768327e-06\n",
      "1812 5.167332e-12\n",
      "1813 0.86473477\n",
      "1814 6.1023705e-08\n",
      "1815 0.002099642\n",
      "1816 0.9374041\n",
      "1817 0.9995153\n",
      "1818 1.1000238e-06\n",
      "1819 0.0002824875\n",
      "1820 0.7945388\n",
      "1821 1.0027559e-05\n",
      "1822 0.99999976\n",
      "1823 0.3243575\n",
      "1824 0.0005538851\n",
      "1825 0.016061587\n",
      "1826 4.570513e-07\n",
      "1827 0.99999857\n",
      "1828 0.9999876\n",
      "1829 0.92481416\n",
      "1830 0.09934891\n",
      "1831 0.9997365\n",
      "1832 0.97897136\n",
      "1833 1.0\n",
      "1834 0.0006613595\n",
      "1835 0.8453347\n",
      "1836 1.0\n",
      "1837 0.5810019\n",
      "1838 0.9996296\n",
      "1839 1.0\n",
      "1840 0.99999535\n",
      "1841 5.5128485e-10\n",
      "1842 0.9974136\n",
      "1843 0.041590326\n",
      "1844 0.27779204\n",
      "1845 0.18301994\n",
      "1846 0.99742067\n",
      "1847 3.3054048e-06\n",
      "1848 2.453648e-05\n",
      "1849 1.1328061e-07\n",
      "1850 1.1006398e-06\n",
      "1851 0.99629223\n",
      "1852 0.99245876\n",
      "1853 0.99998677\n",
      "1854 0.46104708\n",
      "1855 0.9999374\n",
      "1856 0.000557056\n",
      "1857 0.75449175\n",
      "1858 0.2011901\n",
      "1859 4.2140702e-05\n",
      "1860 0.99849343\n",
      "1861 0.9958792\n",
      "1862 0.18677475\n",
      "1863 3.1140967e-06\n",
      "1864 1.0656886e-06\n",
      "1865 5.83675e-07\n",
      "1866 0.00014871747\n",
      "1867 0.9951054\n",
      "1868 0.9946272\n",
      "1869 4.671768e-05\n",
      "1870 0.018135501\n",
      "1871 0.9994404\n",
      "1872 3.3837338e-07\n",
      "1873 0.05246043\n",
      "1874 0.0004430974\n",
      "1875 2.8120955e-11\n",
      "1876 0.98625815\n",
      "1877 0.99999976\n",
      "1878 0.00050392916\n",
      "1879 1.335629e-06\n",
      "1880 0.99999976\n",
      "1881 0.9999696\n",
      "1882 0.9999939\n",
      "1883 6.5931003e-09\n",
      "1884 0.83381265\n",
      "1885 0.9997738\n",
      "1886 4.7796394e-08\n",
      "1887 1.0\n",
      "1888 8.646213e-06\n",
      "1889 0.9968822\n",
      "1890 0.99109393\n",
      "1891 4.0263644e-06\n",
      "1892 0.96597266\n",
      "1893 6.737294e-06\n",
      "1894 0.99995303\n",
      "1895 0.99501896\n",
      "1896 7.1381474e-09\n",
      "1897 0.99979573\n",
      "1898 0.0004577706\n",
      "1899 0.9997285\n",
      "1900 0.99999976\n",
      "1901 2.81959e-07\n",
      "1902 0.9999989\n",
      "1903 3.650199e-05\n",
      "1904 0.99888223\n",
      "1905 0.999997\n",
      "1906 1.0\n",
      "1907 0.9880283\n",
      "1908 0.99518764\n",
      "1909 3.0574355e-07\n",
      "1910 0.9979255\n",
      "1911 0.0008952257\n",
      "1912 3.9927173e-11\n",
      "1913 0.17013046\n",
      "1914 0.018494507\n",
      "1915 0.99993014\n",
      "1916 8.1102263e-07\n",
      "1917 0.015946105\n",
      "1918 0.9997003\n",
      "1919 6.302833e-07\n",
      "1920 0.0009350027\n",
      "1921 0.7601608\n",
      "1922 0.7165375\n",
      "1923 0.99976104\n",
      "1924 0.991542\n",
      "1925 3.1992568e-06\n",
      "1926 0.0011235271\n",
      "1927 0.00024412875\n",
      "1928 0.9984541\n",
      "1929 0.0019240745\n",
      "1930 0.99999905\n",
      "1931 0.09502636\n",
      "1932 0.99968135\n",
      "1933 0.0071124863\n",
      "1934 0.9978155\n",
      "1935 0.9911539\n",
      "1936 0.9999993\n",
      "1937 0.94757503\n",
      "1938 0.0047488245\n",
      "1939 0.9906068\n",
      "1940 0.8705952\n",
      "1941 0.8783744\n",
      "1942 0.00036883095\n",
      "1943 4.5878246e-06\n",
      "1944 0.99741423\n",
      "1945 0.9971437\n",
      "1946 0.99999964\n",
      "1947 0.9999051\n",
      "1948 1.9171277e-10\n",
      "1949 0.21750961\n",
      "1950 0.99999356\n",
      "1951 0.99986196\n",
      "1952 0.9997018\n",
      "1953 0.99954563\n",
      "1954 4.5187946e-08\n",
      "1955 0.010769851\n",
      "1956 0.0012009873\n",
      "1957 0.99873596\n",
      "1958 0.74875075\n",
      "1959 0.9976145\n",
      "1960 1.9199984e-08\n",
      "1961 0.9999999\n",
      "1962 1.2756044e-06\n",
      "1963 0.9912286\n",
      "1964 0.99959654\n",
      "1965 0.9797896\n",
      "1966 0.93572617\n",
      "1967 0.17667314\n",
      "1968 0.9999771\n",
      "1969 0.9267455\n",
      "1970 8.000701e-06\n",
      "1971 0.86277956\n",
      "1972 0.99999976\n",
      "1973 1.0\n",
      "1974 0.99660766\n",
      "1975 1.4211677e-06\n",
      "1976 0.35378838\n",
      "1977 0.99870026\n",
      "1978 0.6298462\n",
      "1979 0.9999939\n",
      "1980 0.99962246\n",
      "1981 0.99998975\n",
      "1982 0.110023014\n",
      "1983 0.00766491\n",
      "1984 0.009789689\n",
      "1985 0.9707597\n",
      "1986 0.9991042\n",
      "1987 1.0\n",
      "1988 1.3666765e-07\n",
      "1989 9.723188e-05\n",
      "1990 0.99996555\n",
      "1991 0.99993527\n",
      "1992 1.0\n",
      "1993 0.9999243\n",
      "1994 0.0020816815\n",
      "1995 4.9813652e-06\n",
      "1996 0.77767456\n",
      "1997 0.0021750221\n",
      "1998 0.022117889\n",
      "1999 1.2821172e-06\n",
      "2000 0.9907913\n",
      "2001 0.9992489\n",
      "2002 8.2113536e-07\n",
      "2003 0.00012477895\n",
      "2004 3.1828342e-05\n",
      "2005 1.1062365e-07\n",
      "2006 0.919904\n",
      "2007 1.0\n",
      "2008 0.37920526\n",
      "2009 0.7122473\n",
      "2010 5.77486e-06\n",
      "2011 0.9988049\n",
      "2012 0.24338944\n",
      "2013 9.03523e-05\n",
      "2014 0.99999857\n",
      "2015 1.2595021e-08\n",
      "2016 0.9993765\n",
      "2017 0.74946505\n",
      "2018 0.9999987\n",
      "2019 0.9999974\n",
      "2020 0.00022660477\n",
      "2021 0.999495\n",
      "2022 0.72820127\n",
      "2023 2.3923184e-07\n",
      "2024 0.8777307\n",
      "2025 0.00333642\n",
      "2026 0.9992711\n",
      "2027 0.9998956\n",
      "2028 0.0010894835\n",
      "2029 0.8355898\n",
      "2030 0.99237424\n",
      "2031 1.0\n",
      "2032 0.9999889\n",
      "2033 1.746831e-09\n",
      "2034 6.4342685e-06\n",
      "2035 3.9582344e-05\n",
      "2036 0.9999939\n",
      "2037 0.65498215\n",
      "2038 0.005839579\n",
      "2039 0.99999964\n",
      "2040 0.00062360254\n",
      "2041 1.3704147e-06\n",
      "2042 0.00017829867\n",
      "2043 0.5914499\n",
      "2044 0.9999993\n",
      "2045 6.9845814e-06\n",
      "2046 0.9999263\n",
      "2047 0.97287536\n",
      "2048 4.2513078e-09\n",
      "2049 0.0019585916\n",
      "2050 0.00039045647\n",
      "2051 0.00081220217\n",
      "2052 0.57856506\n",
      "2053 0.9999988\n",
      "2054 0.99968326\n",
      "2055 0.8272465\n",
      "2056 0.99814\n",
      "2057 1.7832724e-06\n",
      "2058 0.98069406\n",
      "2059 0.9996617\n",
      "2060 0.99999774\n",
      "2061 0.9999945\n",
      "2062 0.9999982\n",
      "2063 0.24214332\n",
      "2064 0.0008403014\n",
      "2065 0.0016604363\n",
      "2066 1.9311607e-07\n",
      "2067 0.9999999\n",
      "2068 0.0003627318\n",
      "2069 0.46901378\n",
      "2070 0.020798977\n",
      "2071 0.0032713977\n",
      "2072 0.18842441\n",
      "2073 1.0\n",
      "2074 0.00046630704\n",
      "2075 0.08277655\n",
      "2076 0.9918166\n",
      "2077 0.93851936\n",
      "2078 1.0\n",
      "2079 0.99903655\n",
      "2080 0.04759617\n",
      "2081 0.00047277738\n",
      "2082 0.9999647\n",
      "2083 0.99998283\n",
      "2084 0.00040172416\n",
      "2085 1.2544873e-06\n",
      "2086 0.9998011\n",
      "2087 0.0004620996\n",
      "2088 1.0743338e-06\n",
      "2089 1.0\n",
      "2090 0.8803556\n",
      "2091 0.99999964\n",
      "2092 0.011091139\n",
      "2093 6.5320074e-07\n",
      "2094 0.23614082\n",
      "2095 1.5548518e-10\n",
      "2096 9.665175e-07\n",
      "2097 0.9923496\n",
      "2098 0.9997955\n",
      "2099 0.99841595\n",
      "2100 0.056624755\n",
      "2101 0.99957436\n",
      "2102 0.008719933\n",
      "2103 0.09617434\n",
      "2104 1.1821102e-05\n",
      "2105 0.99499255\n",
      "2106 0.99999976\n",
      "2107 0.0162438\n",
      "2108 7.163756e-06\n",
      "2109 2.2236181e-06\n",
      "2110 0.8983149\n",
      "2111 0.71190536\n",
      "2112 0.5975748\n",
      "2113 0.9704056\n",
      "2114 1.431853e-10\n",
      "2115 2.4583076e-07\n",
      "2116 3.3018463e-07\n",
      "2117 0.26559782\n",
      "2118 0.1986793\n",
      "2119 0.5374491\n",
      "2120 4.578035e-06\n",
      "2121 0.9882302\n",
      "2122 0.9180347\n",
      "2123 0.9524542\n",
      "2124 0.9994586\n",
      "2125 0.010785901\n",
      "2126 0.70833266\n",
      "2127 0.9999968\n",
      "2128 0.00071443367\n",
      "2129 0.9980939\n",
      "2130 0.9999256\n",
      "2131 0.008995158\n",
      "2132 0.98531425\n",
      "2133 1.0\n",
      "2134 0.09703939\n",
      "2135 1.0\n",
      "2136 7.765406e-05\n",
      "2137 1.7394682e-07\n",
      "2138 1.4920878e-06\n",
      "2139 1.5206638e-05\n",
      "2140 0.99778384\n",
      "2141 0.034797374\n",
      "2142 1.0\n",
      "2143 0.9999999\n",
      "2144 0.9999882\n",
      "2145 0.08618942\n",
      "2146 0.98980576\n",
      "2147 0.8275237\n",
      "2148 0.99985135\n",
      "2149 0.0011018446\n",
      "2150 0.9999913\n",
      "2151 0.9999994\n",
      "2152 0.6489914\n",
      "2153 0.99999833\n",
      "2154 0.003640555\n",
      "2155 0.99999726\n",
      "2156 6.188676e-08\n",
      "2157 1.3768277e-05\n",
      "2158 0.8232\n",
      "2159 0.022459943\n",
      "2160 0.9751119\n",
      "2161 1.0\n",
      "2162 0.79109544\n",
      "2163 0.9999999\n",
      "2164 0.99997735\n",
      "2165 0.9997578\n",
      "2166 0.9723901\n",
      "2167 1.0\n",
      "2168 0.7082401\n",
      "2169 0.31723952\n",
      "2170 0.011693874\n",
      "2171 0.012245202\n",
      "2172 7.7513345e-05\n",
      "2173 1.1806206e-08\n",
      "2174 0.00035222113\n",
      "2175 0.005428815\n",
      "2176 5.948125e-10\n",
      "2177 0.7707966\n",
      "2178 0.99999917\n",
      "2179 0.9999987\n",
      "2180 0.9960387\n",
      "2181 0.044330727\n",
      "2182 0.009098991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2183 0.9977512\n",
      "2184 1.0\n",
      "2185 0.6400308\n",
      "2186 0.03464444\n",
      "2187 0.99995494\n",
      "2188 0.9984193\n",
      "2189 0.0010829726\n",
      "2190 0.0076204166\n",
      "2191 1.8478364e-06\n",
      "2192 8.326395e-05\n",
      "2193 0.9999856\n",
      "2194 1.7885267e-06\n",
      "2195 0.7579104\n",
      "2196 5.459243e-07\n",
      "2197 7.440502e-07\n",
      "2198 0.97179836\n",
      "2199 1.0\n",
      "2200 1.0794051e-08\n",
      "2201 0.9933581\n",
      "2202 0.9906715\n",
      "2203 1.4448326e-13\n",
      "2204 0.7564584\n",
      "2205 0.96211195\n",
      "2206 8.303139e-09\n",
      "2207 0.012179828\n",
      "2208 0.9998914\n",
      "2209 9.663989e-06\n",
      "2210 0.0074393963\n",
      "2211 0.99487597\n",
      "2212 0.9586168\n",
      "2213 0.3584936\n",
      "2214 0.99999833\n",
      "2215 4.2558277e-06\n",
      "2216 0.024959052\n",
      "2217 0.99379313\n",
      "2218 3.715625e-09\n",
      "2219 0.00038149624\n",
      "2220 1.0\n",
      "2221 0.9999571\n",
      "2222 0.98131275\n",
      "2223 0.9999999\n",
      "2224 3.012897e-06\n",
      "2225 8.937472e-06\n",
      "2226 2.4629551e-05\n",
      "2227 2.4838052e-08\n",
      "2228 0.0043256595\n",
      "2229 8.6477763e-07\n",
      "2230 0.99785656\n",
      "2231 1.0\n",
      "2232 0.9999994\n",
      "2233 0.99878186\n",
      "2234 1.0307306e-07\n",
      "2235 7.638394e-07\n",
      "2236 0.98944116\n",
      "2237 0.0011313991\n",
      "2238 0.009302808\n",
      "2239 1.0\n",
      "2240 0.9999999\n",
      "2241 0.0011658481\n",
      "2242 0.7990771\n",
      "2243 0.009104654\n",
      "2244 0.99999475\n",
      "2245 0.0006463443\n",
      "2246 0.9999988\n",
      "2247 0.9999999\n",
      "2248 0.9997353\n",
      "2249 0.00020278055\n",
      "2250 2.6029018e-05\n",
      "2251 0.005455444\n",
      "2252 1.5271014e-09\n",
      "2253 9.8881654e-05\n",
      "2254 0.9938339\n",
      "2255 1.0\n",
      "2256 0.99964666\n",
      "2257 0.034039915\n",
      "2258 0.9981217\n",
      "2259 1.2527861e-06\n",
      "2260 0.9999999\n",
      "2261 0.27179283\n",
      "2262 0.9996569\n",
      "2263 9.206356e-08\n",
      "2264 0.9999714\n",
      "2265 5.3101405e-07\n",
      "2266 9.244994e-06\n",
      "2267 0.9999981\n",
      "2268 0.999915\n",
      "2269 3.034012e-08\n",
      "2270 0.0036344447\n",
      "2271 0.0006004105\n",
      "2272 0.00030569933\n",
      "2273 0.0010006427\n",
      "2274 0.99664426\n",
      "2275 2.482328e-07\n",
      "2276 5.142766e-07\n",
      "2277 0.25549865\n",
      "2278 0.00188828\n",
      "2279 0.13779254\n",
      "2280 0.0070667523\n",
      "2281 0.9999677\n",
      "2282 0.93088305\n",
      "2283 6.6576345e-06\n",
      "2284 0.008769206\n",
      "2285 0.00022623023\n",
      "2286 0.37828973\n",
      "2287 0.7358684\n",
      "2288 0.9895084\n",
      "2289 0.95549244\n",
      "2290 0.99991\n",
      "2291 0.9999999\n",
      "2292 0.9978807\n",
      "2293 2.0759755e-05\n",
      "2294 0.9633823\n",
      "2295 0.9990941\n",
      "2296 0.0045865388\n",
      "2297 8.395264e-07\n",
      "2298 0.937413\n",
      "2299 1.0\n",
      "2300 1.0\n",
      "2301 0.9999999\n",
      "2302 0.9942246\n",
      "2303 0.999708\n",
      "2304 9.766258e-05\n",
      "2305 0.019783208\n",
      "2306 0.926128\n",
      "2307 0.011112372\n",
      "2308 2.3376792e-06\n",
      "2309 0.9996406\n",
      "2310 0.9662469\n",
      "2311 0.00016843466\n",
      "2312 0.99010205\n",
      "2313 2.0845557e-05\n",
      "2314 0.4911639\n",
      "2315 0.9999988\n",
      "2316 0.9843382\n",
      "2317 0.00011711429\n",
      "2318 5.1484863e-06\n",
      "2319 0.9999994\n",
      "2320 0.0004325519\n",
      "2321 0.9999982\n",
      "2322 0.011896706\n",
      "2323 0.9998274\n",
      "2324 0.98864424\n",
      "2325 0.9935788\n",
      "2326 0.9973501\n",
      "2327 2.0230335e-10\n",
      "2328 0.9063548\n",
      "2329 9.570476e-06\n",
      "2330 6.1598587e-07\n",
      "2331 0.79012966\n",
      "2332 0.0002762901\n",
      "2333 1.1837737e-06\n",
      "2334 1.6708244e-06\n",
      "2335 0.9999913\n",
      "2336 0.9992706\n",
      "2337 0.035642408\n",
      "2338 0.9999999\n",
      "2339 0.05687597\n",
      "2340 0.99999714\n",
      "2341 0.0016330207\n",
      "2342 0.99687046\n",
      "2343 7.765961e-05\n",
      "2344 0.021323917\n",
      "2345 0.004476754\n",
      "2346 0.9997726\n",
      "2347 0.9998752\n",
      "2348 0.99999976\n",
      "2349 0.00027846894\n",
      "2350 1.2661503e-11\n",
      "2351 0.9980234\n",
      "2352 0.24448766\n",
      "2353 5.5989933e-09\n",
      "2354 0.014282867\n",
      "2355 0.9999999\n",
      "2356 0.9999801\n",
      "2357 0.9999454\n",
      "2358 0.009796394\n",
      "2359 0.32717428\n",
      "2360 0.0606196\n",
      "2361 0.015335971\n",
      "2362 0.000480954\n",
      "2363 0.0072338735\n",
      "2364 0.99830073\n",
      "2365 0.006749748\n",
      "2366 0.5395425\n",
      "2367 0.93679994\n",
      "2368 0.9999901\n",
      "2369 0.9999609\n",
      "2370 0.0053653773\n",
      "2371 1.1013674e-06\n",
      "2372 0.9988386\n",
      "2373 0.9545955\n",
      "2374 0.27648878\n",
      "2375 0.9998246\n",
      "2376 0.9999989\n",
      "2377 0.007172948\n",
      "2378 0.9998111\n",
      "2379 0.031619556\n",
      "2380 9.060398e-06\n",
      "2381 0.99938536\n",
      "2382 0.040054977\n",
      "2383 0.9999994\n",
      "2384 0.9994547\n",
      "2385 0.99996674\n",
      "2386 0.00046400778\n",
      "2387 0.0068680504\n",
      "2388 0.005549017\n",
      "2389 1.0\n",
      "2390 0.007552261\n",
      "2391 0.99903643\n",
      "2392 0.030191857\n",
      "2393 4.8933834e-05\n",
      "2394 0.9177756\n",
      "2395 0.999972\n",
      "2396 0.99605006\n",
      "2397 0.00036654394\n",
      "2398 0.0021176755\n",
      "2399 0.99545234\n",
      "2400 0.021965215\n",
      "2401 0.99999905\n",
      "2402 1.096053e-10\n",
      "2403 2.6505226e-05\n",
      "2404 0.25914776\n",
      "2405 0.9999988\n",
      "2406 0.31498325\n",
      "2407 1.9937418e-09\n",
      "2408 6.4085244e-09\n",
      "2409 1.0\n",
      "2410 0.754131\n",
      "2411 0.95391387\n",
      "2412 9.893985e-08\n",
      "2413 1.6641471e-07\n",
      "2414 0.79773086\n",
      "2415 4.726118e-07\n",
      "2416 7.991238e-07\n",
      "2417 5.6582513e-07\n",
      "2418 0.7850283\n",
      "2419 4.482198e-06\n",
      "2420 1.1608295e-09\n",
      "2421 0.019384393\n",
      "2422 0.9999999\n",
      "2423 0.9999757\n",
      "2424 0.97948563\n",
      "2425 0.9999995\n",
      "2426 0.06633619\n",
      "2427 5.0686435e-08\n",
      "2428 0.9999993\n",
      "2429 0.99768424\n",
      "2430 1.722032e-05\n",
      "2431 0.818384\n",
      "2432 0.9687609\n",
      "2433 5.4883672e-05\n",
      "2434 3.5648296e-05\n",
      "2435 4.7130648e-08\n",
      "2436 0.2622029\n",
      "2437 0.00014917635\n",
      "2438 0.0788393\n",
      "2439 1.1520162e-08\n",
      "2440 0.0005057575\n",
      "2441 0.9995778\n",
      "2442 0.9999999\n",
      "2443 3.4858078e-10\n",
      "2444 9.689183e-06\n",
      "2445 0.0034865208\n",
      "2446 0.0044307355\n",
      "2447 2.9366747e-06\n",
      "2448 7.049662e-08\n",
      "2449 0.92063975\n",
      "2450 1.4090734e-05\n",
      "2451 0.015406835\n",
      "2452 0.018742746\n",
      "2453 4.820785e-07\n",
      "2454 0.7973195\n",
      "2455 0.67251605\n",
      "2456 0.38977623\n",
      "2457 0.9997012\n",
      "2458 9.259897e-05\n",
      "2459 0.0037288691\n",
      "2460 0.1898265\n",
      "2461 0.04052815\n",
      "2462 0.99999964\n",
      "2463 0.9902726\n",
      "2464 6.5500707e-09\n",
      "2465 0.9999989\n",
      "2466 0.99999905\n",
      "2467 0.00057609286\n",
      "2468 0.0006027671\n",
      "2469 0.33106163\n",
      "2470 0.00027388928\n",
      "2471 1.8170456e-07\n",
      "2472 0.7367331\n",
      "2473 0.99042904\n",
      "2474 0.8388254\n",
      "2475 0.006731796\n",
      "2476 0.9999987\n",
      "2477 0.0014409723\n",
      "2478 0.40195477\n",
      "2479 0.10098786\n",
      "2480 4.173765e-07\n",
      "2481 0.90854216\n",
      "2482 0.040331006\n",
      "2483 1.6784867e-05\n",
      "2484 0.00017559649\n",
      "2485 0.99948007\n",
      "2486 0.9991755\n",
      "2487 0.40356007\n",
      "2488 0.9974044\n",
      "2489 0.9951397\n",
      "2490 0.9999863\n",
      "2491 0.9999789\n",
      "2492 8.3989105e-10\n",
      "2493 0.9145167\n",
      "2494 0.99875593\n",
      "2495 0.9999379\n",
      "2496 0.97908837\n",
      "2497 0.10224991\n",
      "2498 0.993393\n",
      "2499 1.9293235e-07\n"
     ]
    }
   ],
   "source": [
    "# 실제 예측을 진행하기 위한 값 추출\n",
    "\n",
    "INPUT_TEST_DATA_FILE_NAME = 'test_input.npy'\n",
    "\n",
    "test_input_data = np.load(open(FILE_DIR_PATH + INPUT_TEST_DATA_FILE_NAME, 'rb'))\n",
    "\n",
    "def mapping_fn(X):\n",
    "    input = {'test': X}\n",
    "    \n",
    "    return input\n",
    "\n",
    "def test_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(test_input_data)\n",
    "    dataset = dataset.map(parser)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "prediction = est.predict(test_input_fn)\n",
    "\n",
    "num_score = []\n",
    "\n",
    "for i, p in enumerate(prediction):\n",
    "    num_score.append(p['prob'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d7a5f6b31644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#전처리 lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tensorflow.python.keras.datasets import imdb\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "from tensorboard import summary as summary_lib\n",
    "\n",
    "#전처리 lib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input function\n",
    "\n",
    "#각 문장의 길이를 계산한다, max 길이는 200\n",
    "\n",
    "x_len_train = np.array([min(len(x), sentence_size) for x in x_train_variable])\n",
    "x_len_test = np.array([min(len(x), sentence_size) for x in x_test_variable])\n",
    "\n",
    "def parser(x, length, y):\n",
    "    features = {\"x\": x, \"len\": length}\n",
    "    return features, y\n",
    "\n",
    "#len을 활용하여 기존 전처리 이후의 길이를 보존\n",
    "#from_tensor_slices를 활용하면 numpy 데이터 구조에서 쉽게 변환\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, x_len_train, y_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(x_train_variable))\n",
    "    dataset = dataset.batch(100)\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_test, x_len_test, y_test))\n",
    "    dataset = dataset.batch(100)\n",
    "    dataset = dataset.map(parser)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classification\n",
    "\n",
    "CNN을 활용하여 text를 분류해보자, n-gram의 효과로 활용\n",
    "\n",
    "https://www.semanticscholar.org/paper/Learning-to-Rank-Short-Text-Pairs-with-Deep-Neural-Severyn-Moschitti/452f7411af7d471dd3ba84c2b06b2aaffc38cdb9\n",
    "\n",
    "Embedding Layer -> Dropout -> Conv1D -> GlobalMax1D -> Hidden Dense Layer -> Dropout -> Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers = {}\n",
    "\n",
    "def train_and_evaluate(classifier):\n",
    "    # 예측 테스트를 위해 모델을 학습시키고 저장한다.\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=train_input_fn, steps=1)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n",
    "    \n",
    "    # name scopes의 재사용을 위해 graph를 reset한다.\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool),\n",
    "                             num_thresholds=21)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n",
    "        writer.add_summary(sess.run(pr), global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/user/git/DeepNLP/Kaggle/BagOfWordsMeetsBagsOfPopcorn/checkpoint/cnn_model/cnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11d325748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#head: pre-made estimator로 평가를 할 때, 일정한 함수를 사용하게 세팅\n",
    "head = tf.contrib.estimator.binary_classification_head()\n",
    "\n",
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    #embedding layer를 선언한다.\n",
    "    input_layer = tf.contrib.layers.embed_sequence(\n",
    "                    features['x'],\n",
    "                    vocab_size,\n",
    "                    embedding_size,\n",
    "                    initializer=params['embedding_initializer']\n",
    "                    )\n",
    "\n",
    "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer,\n",
    "                                   rate=0.2,\n",
    "                                   training=training)\n",
    "\n",
    "    conv = tf.layers.conv1d(\n",
    "            inputs=dropout_emb,\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
    "    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)  \n",
    "    dropout_hidden = tf.layers.dropout(inputs=hidden, rate=0.2, training=training)\n",
    "    logits = tf.layers.dense(inputs=dropout_hidden, units=1)\n",
    "    \n",
    "    #prediction 진행 시, None\n",
    "    if labels is not None:\n",
    "        labels = tf.reshape(labels, [-1, 1])\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer() #여러가지 Optimizer 활용가능\n",
    "    \n",
    "    def _train_op_fn(loss):\n",
    "#         tf.summary('loss', loss)\n",
    "        return optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "\n",
    "    \n",
    "    return head.create_estimator_spec(\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "        mode=mode,\n",
    "        logits=logits,\n",
    "        train_op_fn=_train_op_fn)\n",
    "\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                                        model_dir=os.path.join(model_dir, 'cnn'),\n",
    "                                        params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101002\n",
      "INFO:tensorflow:Saving checkpoints for 101003 into ./checkpoint/cnn_classifier/cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.933278e-09, step = 101003\n",
      "INFO:tensorflow:Loss for final step: 6.933278e-09.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-13-11:33:43\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-13-11:33:44\n",
      "INFO:tensorflow:Saving dict for global step 101003: accuracy = 0.8706, accuracy_baseline = 0.5024, auc = 0.89279175, auc_precision_recall = 0.91575927, average_loss = 2.343806, global_step = 101003, label/mean = 0.5024, loss = 234.3806, prediction/mean = 0.49696568\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n"
     ]
    }
   ],
   "source": [
    "#학습 후, 결과치를 tensorboard로 확인\n",
    "# tensorboard --logdir=./checkpoint/cnn_classifier/\n",
    "train_and_evaluate(cnn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 prediction으로 테스트 해 본다\n",
    "\n",
    "def text_to_index(sentence):\n",
    "    # Remove punctuation characters except for the apostrophe\n",
    "    translator = str.maketrans('', '', string.punctuation.replace(\"'\", ''))\n",
    "    tokens = sentence.translate(translator).lower().split()\n",
    "    return np.array([1] + [word_index[t] if t in word_index else oov_id for t in tokens])\n",
    "\n",
    "def print_predictions(sentences):\n",
    "    indexes = [text_to_index(sentence) for sentence in sentences]\n",
    "    x = sequence.pad_sequences(indexes, \n",
    "                               maxlen=sentence_size, \n",
    "                               truncating='post',\n",
    "                               padding='post',\n",
    "                               value=pad_id)\n",
    "    length = np.array([min(len(x), sentence_size) for x in indexes])\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": x, \"len\": length}, shuffle=False)\n",
    "    predictions = {}\n",
    "    for path, classifier in all_classifiers.items():\n",
    "        predictions[path] = [p['logistic'][0] for p in classifier.predict(input_fn=predict_input_fn)]\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        print(sentence)\n",
    "        for path in all_classifiers:\n",
    "            print(\"\\t{} {}\".format(path, predictions[path][idx]))\n",
    "#             predictions[path][idx]\n",
    "    \n",
    "    return predictions[path][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101002\n",
      "I do not like this movie\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999970197677612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999997"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_predictions([\n",
    "    'I do not like this movie'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101002\n",
      "fuck you\n",
      "\t./checkpoint/cnn_classifier/cnn 0.1322726458311081\n",
      "this movie sucks\n",
      "\t./checkpoint/cnn_classifier/cnn 2.31997950535464e-19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3199795e-19"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_predictions(['fuck you', 'this movie sucks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 했던 것을 모두 활용하여 제출용 데이터를 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                             review\n",
      "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
      "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
      "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
      "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
      "4   \"12128_7\"  \"A very accurate depiction of small time mob l...\n",
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#테스트 데이터를 읽어봅시다.\n",
    "test = pd.read_csv(default_path+\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "#테스트 파일은 이렇게 생겼다고 합니다.\n",
    "print (test.head())\n",
    "\n",
    "#이 파일은 \"sentiment\" 행이 없습니다.\n",
    "print (test.shape)\n",
    "\n",
    "#불용어 제거도하고 태그들도 지우고 난후 데이터를 저장할 장소를 만들어둡니다.\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = []\n",
    "\n",
    "print (\"Cleaning and parsing the test set movie reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "naturally film main themes mortality nostalgia loss innocence perhaps surprising rated highly older viewers younger ones however craftsmanship completeness film anyone enjoy pace steady constant characters full engaging relationships interactions natural showing need floods tears show emotion screams show fear shouting show dispute violence show anger naturally joyce short story lends film ready made structure perfect polished diamond small changes huston makes inclusion poem fit neatly truly masterpiece tact subtlety overwhelming beauty\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "movie disaster within disaster film full great action scenes meaningful throw away sense reality let see word wise lava burns steam burns stand next lava diverting minor lava flow difficult let alone significant one scares think might actually believe saw movie even worse significant amount talent went making film mean acting actually good effects average hard believe somebody read scripts allowed talent wasted guess suggestion would movie start tv look away like train wreck awful know coming watch look away spend time meaningful content\n",
      "\t./checkpoint/cnn_classifier/cnn 8.024853669818446e-28\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "movie kids saw tonight child loved one point kid excitement great sitting impossible however great fan milne books subtle hide wry intelligence behind childlike quality leading characters film subtle seems shame disney cannot see benefit making movies stories contained pages although perhaps permission use found wishing theater replaying winnie pooh tigger instead characters voices good really bothered kanga music however twice loud parts dialog incongruous film story bit preachy militant tone overall disappointed would go see excitement child face liked lumpy laugh\n",
      "\t./checkpoint/cnn_classifier/cnn 0.0011724684154614806\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "afraid dark left impression several different screenplays written short feature length film spliced together clumsily frankenstein monster best protagonist lucas creepy hard draw bead secondary characters far sympathetic afraid dark could achieved mediocrity taken one approach seen made lucas simply psychotic confused instead ghoulish putting wanted see packed asylum rest characters could normal life\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999042749404907\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "accurate depiction small time mob life filmed new jersey story characters script believable acting drops ball still worth watching especially strong images still even though first viewed years ago young hood steps starts bigger things tries things keep going wrong leading local boss suspect end skimmed good place enjoy health life film introduced joe pesce martin scorsese also present perennial screen wise guy frank vincent strong characterizations visuals sound muddled much acting amateurish great story\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "valuable king tut tomb ok maybe valuable worth hunting notice one commented movie years hope fresh post spark new comments film remembered snippets childhood saw recently tired waiting fox honour past hunted korean dvd english unremovable korean subtitles go another long plot description suffice say seeing first time proper widescreen format left agape vistas scope film matte paintings still hold palace sets truly breathtaking smaller scale details lend film depth richness offering glimpse lifestyles egypt poor well elite bazaars hovels docks embalming houses taverns fascinating pharaoh throne room errors abound large scale notably dynastic succession details meticulously researched vast majority hollywood films visually without flaws interiors often overly lit colourful blend seamlessly exteriors nevertheless movie credited audacious small large tedious parts absolutely overacted underacted yes though understated might apt description long absolutely wished spent time sinuhe experiences house death among hittites less romance nefer though historically inaccurate yes shakespeare nobody chastises appreciate historical accuracy much next guy ultimately remembered cinema theater history lesson\n",
      "\t./checkpoint/cnn_classifier/cnn 0.13919110596179962\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "one biggest misfires ever script nice could ended lot better actors played better maybe would given movie slightly better grade maybe hollywood remake movie little better actors better director sorry guys disappointment movie bad watch would like torture want spoil everyone opinion mine advice watch movie first see u like vote vote watch way fun watching peek watch till end\n",
      "\t./checkpoint/cnn_classifier/cnn 2.773841472811754e-15\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "one movies watched wondered watch find interesting truck driver find realistic never used lot lizard ever seen heard one traveling around country brand new seventy thousand dollar rv either thing pimp never sampled lady question end movie well still really getting bucks cut prostitute gets well cut yeah still laugh lot lizard comment ivey made lot lizards screw anything bucks men dressed woman something equally weird meaning better may still prostitutes get paid better story young woman wanted something life dead end job living home remember embarrassed mother basically thing dead end job least roof head job turned five tricks road wonder made worth guess\n",
      "\t./checkpoint/cnn_classifier/cnn 2.1189442277083463e-14\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "worst movie seen years seen lot movies acting terrible plot whatsoever point whatsoever felt robbed rented movie recommended mind disgrace terrible movies stay away terrible piece c p save money\n",
      "\t./checkpoint/cnn_classifier/cnn 0.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "five medical students kevin bacon david labraccio william baldwin dr joe hurley oliver platt randy steckle julia roberts dr rachel mannus kiefer sutherland nelson experiment clandestine near death afterlife experiences searching medical personal enlightenment one one medical student heart stopped revived temporary death spells experiences bizarre visions including forgotten childhood memories flashbacks like children nightmares revived students disturbed remembering regretful acts committed done experience afterlife bring real life experiences back present continue experiment remembrances dramatically intensify much physically overcome thus probe transcend deeper death afterlife experiences attempting find cure even though dvd released motion picture released therefore kevin bacon william baldwin julia roberts kiefer sutherland early stages adult acting careers besides plot extremely intriguing suspense building dramatic climax script tight convincing young actors make flatliners star cult semi sci fi suspense knew years ago film careers young group actors would skyrocket suspect director joel schumacher\n",
      "\t./checkpoint/cnn_classifier/cnn 0.00012794339272659272\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "mill floss one lesser novels mary ann evans wrote male pseudonym george eliot tried read dull turgid novel years ago unable finish review film version solely merits know faithfully follows original novel film opening credits printed old english typeface suggests mediaeval period poor choice film th century setting hand halfway film see close shot handbill advertising estate auction handbill set authentic victorian type fonts looks convincing film extremely convincing depiction architecture clothing early th century england precise location film story never disclosed judging actors accents place somewhere cotswolds perhaps warwickshire plot involves mill changes hands couple times couple decades two rival families one wealthy one working class disagree another imdb reviewer claims james mason small role film mason largest central role drama scion wealthier family spoilt petulant tom tulliver mason darkly brooding impetuous performance belongs better film made want see wuthering heights recast mason heathcliff multi generational saga something george eliot much better middlemarch several main roles film split among two actors apiece child actors prologue adults main narrative prologue film features well written scene establishing tom tulliver wilful bully ragging early age young philip wakeham decent thoughtful hard labour philip earned halfpenny tom tries bully away unwilling take coin brute force wants philip give child actors movie male female talented attractive unfortunately children speak dialogue posh plummy voiced accents utterly unlike accents actors actresses play roles adults discrepancy calls attention staginess material regrettably none later scenes good prologue climax features crowd labourers rainstorm much better paced photographed earlier scenes modern viewers britain least longer take sort material seriously practically every british comedian done trouble mill squire comedy routine parodying precisely subject matter difficulty watching movie straight face character actress martita hunt good small role opening credits old english typeface misspell forename marita rate dull movie points one point apiece james mason performance early scene children authentic victorian typesetting auctioneer handbill\n",
      "\t./checkpoint/cnn_classifier/cnn 9.76536739472067e-07\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saw film phoenix film festival today loved synopsis listed program old shakespearean actor invites three children suicide party sure going see read liked idea suicide party sounded interesting old shakespearean actor worried film would kind dry boring decided give try glad dry boring least dialogue great funny clever way pretentious difficult understand peter falk terrific role stole show also pleasantly surprised laura san giacomo performance usually bugs enjoyed watching film much think judge reinhold part could done better another actor times seemed kind cheesy looked like acting like watching character movie good able forgive one actor awkwardness would recommend film anyone already told people see soon available general public knew suicide could hilarious\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "love letter one movies could really clever wasted focusing letter wreaking havoc small town movie star cast nothing tom selleck alice drummond recently co starred super hilarious also upset small town great look though getting drug place tell people behind camera trying anything sure accomplish anything tragic potential laugh riot got sorrowfully wasted\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999397993087769\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "another fantastic offering monkey island team though long time coming survive departure ron gilbert another worthy installment gripe little short seeming comparison previous two though might glorious lack disk swapping roll mi\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "included disk shorts volume rather dull collection short films shorts among favorite style films somehow people assembling second collection hard time finding quality content nearly good first volume shorts collections short film feels like woefully incomplete story much unanswered viewer like feels bit left unfulfilled film begins woman boyfriend westie dog way going lonely beach lady speaks accent times bit difficult follow given hard hearing sure would loved closed captioned anyway boyfriend goes swim naps awakens dog gone panics makes guy follow looking dog spend time arguing disagreeable blue stop sex later find dog end story far characters go seemed rather dysfunctional unlikable fussy demanding lady seemed contempt wondered together little sex break showed bond kept together might like characterizations kept finding people irritating unreal like caricatures people might meet know also payoff worth wait unless want see guy naked\n",
      "\t./checkpoint/cnn_classifier/cnn 0.5541055202484131\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "really much abbott costello fan although enjoy first honest much movie would inspire watch work really bad mildly amusing scenes actually convincing giant played buddy baer somehow given fame duo esteem generally held say expecting story goes pair stumble babysitting job reading jack beanstalk bedtime story kid reading costello costello jack falls asleep dreams story wizard oz kind feel story characters dream equivalents real life acquaintances jack movie opens black white shifts colour dream sequence fight scenes jack giant dance scene jack polly dorothy ford among amusing parts movie polly course also leads one questions movie happened jack gang apparently left behind giant castle know dream cares still wondered also couple cute song dance routines year old giggled bit able appreciate humour found acceptable timewaster certainly anything would convince abbott costello comic geniuses\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9992899894714355\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "movie dreadful biblically inaccurate moses years old led people egypt movie forty moses forty fled egypt gone forty years wandering forty years moses years old died denied privilege crossing promised land realize movies use lot poetic license biblical account long making biblical movie still need reflect facts known keep general flavor main biblical character movie fails aspect many others even though version problems well theatrically much better\n",
      "\t./checkpoint/cnn_classifier/cnn 2.6139719607306735e-26\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "think ever gave something rating one easily gets denomination find hard sit one jokes jokes bad combine fact carson daily zero charisma set finish punchline got late night comedy recipe really turn stomach watched show never entirety many times still creeps conan usually watch minute two see carson daily still worst talk show host ever actually ever see interviewing guest interview feel sorry every time guest confused smiles try mask body language screaming get hell away freak recommend watching show laugh ponder got air still watch much think find complete awkwardness interesting\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0141736434381333e-19\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "excellent story telling cinematography poignant biting social commentary superb effects well filmed acted however parallel action present travel adventures though well done times drags little much hrs interrupts flow story first read book child enjoyed parts giants tiny people book lost got floating island land yahoos well although adventure plot may sound like children story fact adult story full symbolism moral decay england time jonathan swift author novel film based upon\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "completely forgot seen within couple days pretty revealing umpteenth version gaston phantom opera leroux locked door country house mystery heard engaging witty update appeared likable title sequence neat touches opening scene film quickly ground halt became vaguely tedious wholly unsatisfying mystery major problem fundamentally unsolvable audience like worst agatha christies depends character appearing final act wealth background information privy film comedy thriller crucial problem characterisation almost non existent exception killer everyone face value version typical suspects typical country house murder story reporter endangered heiress suspicious fianc scatterbrained scientist father surprisingly poor michel lonsdale etc depth little interest frequently ripe misjudged performances help frankly care anyone jeopardy suspense claude rich last reel pierre arditi get anything work last reel film get close sense resonance fleeting really effective rest get endless exposition couple ineffective would comic set pieces promising one photographer trapped inside grandfather clock poorly thought pay dennis podalydes reduced irving explainer last third picture fond country house movies agatha christie style whodunits might cit lot slack found poor show rich says mystery revealed rather something disappointment\n",
      "\t./checkpoint/cnn_classifier/cnn 2.6987486034307714e-34\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "like action movies softspot b flicks bad dialogue wooden acting wracking brain come one guilty pleasures worse blockbuster hard pressed put together bigger piece cr p bruce willis vehicle armageddon story use term loosely team super drillers flying destroy asteroid destroys earth realistic really cares action flick blasting premise minor spoilers movie begins couple scenes designed introduce threat characters bruce willis tough nails leader team spends first bit screen time chasing around ben affleck gun unforgiveable act sleeping daughter reason make laugh forced like everything movie team called people whole wide world drill asteroid okay prepared accept premise gets us action supposed meat movie attempts humor character going crazy nutty thing blast lame finally take movie really pi ed arrive rock set work would believe nothing works right everything suspenseful countdown whoah ten nine eight one oh surprise surprise saved day even get started jerky camerawork saw theater thought going sick assume trying cover gargantuan holes left insipid performances cutting away different shot every seconds someone raised mtv mr short attention span thought get worse wait manufactured tearjerker ending tacked made rest film virtual citizen kane summary witticisms witty plot well said let one go acting bad really bad even billy bob rise script worse camerawork bad even mention dumbest love scene history motion pictures think animal crackers rating giving half point steve buscemi makes smile another half point times able look lovely liv tyler attempt ignore acting performance far away worst movie gone see theater ever\n",
      "\t./checkpoint/cnn_classifier/cnn 3.860848273029571e-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "one worst sandra bullock movie since speed quite bad really lost blue special effect guys insomniac go girl see movie give three sleepies\n",
      "\t./checkpoint/cnn_classifier/cnn 7.357160721118613e-30\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "watched flick saturday afternoon cable man drag got metaphors symbolism stuff care one way another sexuality characters pacing story scripting almost put sleep ruth marshall got naked breast man homo phobic may want rent ruth lesbian sex scene pretty hot hetero sex scene notch higher standard movie fare jiggly cups made film worth watch mighty avatar\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0262750649303598e-08\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "went see tkia high expectations might influence opinion seen dogme films tkia far worst story intertwines themes shakespeare play king lear never succeeds capturing audience making care directing actors loose even dogme style movies results poor undefinable acting story lacks dynamics whatsoever lost interest shortly scenes film shock viewer think enhanced story mifunes sidste sang festen dogmefilms proved well directed good storylines shall look forward better dogmefilms future perhaps aake sandgren invisible man dogme prove lift quality like vinterberg k jacobsen skilled educated director\n",
      "\t./checkpoint/cnn_classifier/cnn 4.218123384836721e-26\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "credit writer director gilles mimouni fashioned winding twisting tale deceit betrayal keeping utmost control maintains audience arm length never allowing become completely aware goings even clever denouement guessing three central performances also top class vincent cassel romane bohringer monica bellucci utmost add mystery jean phillippe ecoffey supplements strength supporting role give away plot details character specifics would fair thierry arbogast uses camera effectively sweep us enigma cardine biggerstaff editing keeps story step ahead us theme peter chase sublime marriage ideal script many may say gilles mimouni trying confront several deeper issues love simply haunting elusive riddle weaves fascinating web french capable tantalisation hollywood would ruined happy ending monday march hoyts croydonno one thriller quite like french get right really get right vincent cassell intriguing deceptive max romane bohringer obsessive new lisa monica bellucci mysterious first lisa plot gilles mimouni whirlwind deliberate deception fatally crossed wires credit must go manipulation clever plot performances three leads lucien jean phillippe ecoffey strong emotional friday january video\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "writing teacher two ending never allow students use woke got run truck going add got bump head feel utterly unfair use tricks cover lack imagination whole issue transmigration could handled intelligence craft yet film either saying totally worthless predictable progress except stupid ending even gangsters go police get help guy done immediately forgettable borderline horror sci fi film nothing new offer\n",
      "\t./checkpoint/cnn_classifier/cnn 6.12813896849751e-11\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "know gotten decent reviews could weakest horror comedy ever seen englund cameo performance unnecessary lame attempts jokes scares direction terrible acting worse seems like every year producers trying make another evil dead weak unoriginal attempts stepping memory true horror classic whether filmmakers saying remake throwback unoriginal opinion hatchet people trying plug horror classics still misleading wont make lack scares horror comedy even decent movie matter avoid costs\n",
      "\t./checkpoint/cnn_classifier/cnn 8.682385592687624e-31\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "film released uk name blood rites banned outright never submitted release ghastly ones supposedly hit horror hungry denizens new york city famed nd street grindhouse circuit looking bloody horror find film unfortunately see developmentally disabled colin hal borske chomp live rabbit put shaky mm camera work makes ed wood look positively marvelous three sisters spend three days family homestead husbands old man money disbursed naturally situation people start dropping dead family secrets exposed lots blood spilled especially gruesome dismemberment maybe bunny bit brits objected know\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "uncle fred olen ray gives us little retromedia goodness form soft core cinemax non classic numb nut pair looking rocks come across swirling vortex black hole intelligent dolts put pretty soon attractive cave girl one million years ago happens time line beds way future pretty soon studly half makes way future well blazes path beds future ray delivers passable barely smut fest horrible acting decent skin yeah barely titillating heh worse comes worse cure insomnia reviews\n",
      "\t./checkpoint/cnn_classifier/cnn 3.1426879142271113e-19\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "ok watchable sick bed nothing else suspension disbelief required get movie significant though first today modern society believe college coeds get committed someone short period time even virtuous habitat volunteer likes autistic kids week romance blossoms letter exchange leads john conflict whether enlist right really asks every guy know gonna sitting sidelines towers came husband one love proud going john character flat nearly expressionless entire movie good looking spec ops seems unsure confident quiet instead hell raiser tattoos gets fight preppy boys nothing pushing match really walks around without cover head nearly whole movie military technical flaws everywhere epaulets upside war scenes dumb john another guy heading huh guy gets shot john drags feet starts giving buddy aid securing area back arrival even backs cover gunfight god sakes stop fighting heck wanted shoot john back back home truth revealed spills wine hated removing shirt presence wth break heart tease adultery head case trollop best part movie drives away least self respect honor overall unbelievable story generally care characters love dismal\n",
      "\t./checkpoint/cnn_classifier/cnn 3.6497600832171084e-17\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "allowed watch one program entire life would definitely pick chaser war everything satirical shows australian television found chaser funniest amazing boys afraid anything whether dress hitler get polish club push massive ball string around melbourne try tourism ad rock coke factory naked bath buy water chaser boys go agreement comments chaser war everything popular previous program cnnnn cnnnn funny unforgettable moments show clean cambodia classic anyway stop ranting strongly advise least give chaser chance likely find hilarious\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "truly terrific touching film female melodrama finest lot comedy great dialogue characters writing woman relate story classic love mr right interest guy seems completely wrong comes along fall head heels love course simplistic characters real performances perfect movie hilarious well every scene skewers society recommend film anyone loves well written screenplay humor melodrama relate every character plot moves unexpected directions great underrated movie\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "pepe le pew either really creep totally sweep feet either way help feeling little awe beholding classic wb character commentater personally believes pepe inspiration behind would animated casanovas today cartoon network johnny bravo disney lumiere beauty beast unique brand love making wondered today world antics would normally slapped sexual harassment warrant least distance victims particular cartoon world weary cat decides ultimate makeover earn respect change pretending skunk goes well pepe arrives promptly pursues unfortunate feline overwhelmingly enthusiastic love making groundwork pepe many trademarks laid cartoon adorable frenchified love calls aggravatingly calm hop chase cartoon goes show far world cartoon fantasy concerned ardent wooer go distance beloved pig eon leaving dust trails behind\n",
      "\t./checkpoint/cnn_classifier/cnn 0.018912719562649727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "alas another costner movie hour long credible performances script go hurry get first offered unrelated string events story script center randall wife randall fischer fischer thomas end real front story ever develops characters artificially propped monologues third parties singer explains randall randall explains fischer finally long care anymore learn something script meetings three endings doubt proffered one could make decision end result three used one another another hang past th yawn able pick despite transparent attempt gain points dedication coast guard one washed first day\n",
      "\t./checkpoint/cnn_classifier/cnn 0.011258931830525398\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "get shorty sight jackie brown even pick folks finally getting elmore leonard right making good movies work despite students warnings bad movie would resist renting thought bad oy mistake especially right heels reading book lame circularly self referential relative rest elmore leonard books still book better movie leonard trumps weak unskilled screen writers try take book dialogue written steven tyler painful watch lyrics character linda moon first song middle schoolers write depth sad sad sad even give star harvey keitel uma thurman still fun see screen andre make complete fool\n",
      "\t./checkpoint/cnn_classifier/cnn 1.5396114938504013e-11\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "still living parents aired dutch tv usually one watching movies caring somehow sat watched movie kinda movie used aired wednesday evening story woman die soon dies wants make sure many kids best possible foster parents watching dad emotional four us started cry followed almost immediately long sister mother teared totally moved simple heartbreaking story want good cry one\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "movie stunk much final fight looked like walker taking grandmother supernatural demon strength ten men found commercials interesting plot twists jokes could seen coming mile away redeeming quality film ended avoid costs unless enjoy bad chuck norris movies\n",
      "\t./checkpoint/cnn_classifier/cnn 0.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "spoiler alert boyfriend friends rented movie part marathon really bad movies sort knew getting lack plot direction special effects actually left us hoping great passable fight scene two main characters badly rendered swimming cobra super violent giant komodo ate people like scooping ice cream sort get end cut short due possibly budget time constraints one redeeming quality laughably bad many salient details pointed readers recommend movie cutting onions make cry\n",
      "\t./checkpoint/cnn_classifier/cnn 3.6811198821543257e-26\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "one worst movie seen far story hesitates silly thriller dumb comedy nothings happens void filled long boring dialogs make sense cast famous bring emotions except fast forward play happens plush seaside hotel looks really gloomy comparison one shining funfair nb lot users think located french riviera wrong south france nice cannes totally opposite cabourg normandy simple beaches day sea grey sky sun\n",
      "\t./checkpoint/cnn_classifier/cnn 3.0640420548853884e-24\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "love watching steven seagal movies action great plot holes makes laughoh makes laugh hard movie totally got point ridiculous compared movie pearl harbor rocks ben affleck need acting school give impression bad isfirst many goofs bad acting getting worse like steven try get jail chopper lands first security notice led land fly away sudden guard start shootingor killed guy car treach walk away see oil ground behind steven notice oil without even watching treach trows lighter car blows upand plenty goofs steven uses basic action someone pointing gun grabs shoot totally bullshit like gangster would let ever happen acting also worse fight scene jail outdoor place see steven clearly wait come action rewind couple time notice bad actingits makes laugh hope one day comes cinema holland go many friends possible laugh self death\n",
      "\t./checkpoint/cnn_classifier/cnn 2.924853777320393e-18\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "saw tonight fell asleep movie something done since never fallen asleep movies love original seen several times recommend everyone may problem think couple bright spots showed done right could made movie work bette used anne used miscast know english anyone matter let go condition billed sex city better chance liked sex city lot disappointed movie waste money movie go see anything\n",
      "\t./checkpoint/cnn_classifier/cnn 1.2894693851016244e-22\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "almost redeeming social value sequel original poseidon adventure heck people original including rescue crew michael caine undergoes humiliating performance date although later trumps jaws road slim pickens embarrassing stereotyped texas generally wonder bother irwin allen last stab cashing disaster craze guess\n",
      "\t./checkpoint/cnn_classifier/cnn 0.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "rossini described rival composer wagner work wonderful moments awful quarter hours inuyasha seems also described way many great episodes countless filler episodes entire series consists episodes say least filler sort subplot bother count surprised number fact higher though filler episodes actually quite enjoyable though many quite silly dull nonetheless constant digressions start wear thin first seasons plot ends progressing labored crawl series character development slows greatly later seasons cast become quite unchanging resulting increasingly stale jokes particularly concerning monk ironic traits start mildly humorous grow tiresome jokes associated appear repeatedly however say inuyasha bad series great series way neon genesis evangelion example generally considered something watch end hard day nice could never confused high art\n",
      "\t./checkpoint/cnn_classifier/cnn 6.825661702514196e-10\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "watched hallmark channel surprised john denver movie full clich expected made tv christmas movie come acting good made tv movie story said predictable clich still good looking campy christmas movie certainly scratch itch also pleased learned took place georgetown colorado real mountain town west denver cool home region never big john denver fan always found pretty foney decent actor good good old boy like played film get chance watch sure\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999996423721313\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "ronald coleman star screen several years talkies came boost career oxford english accent enthralling could listen recite farmer almanac bored coleman plays willie hale ish playboy wealthy family spends time womanizing gambling yet likable rogue likable standpoint audience family friends yet gone broke due constant gambling sells possessions foreign location settle debts provide passage back home england gets first met father insists kick willie layabout ways however five minutes alone room willie charm willie forgiven dad dad given one hundred pounds boot willie goes day recreation sister friend dorothy hope loretta young dorothy set engaged grand duke paul night mainly dad wants royalty family nobody else special life changes day willie soon scandal brewing dorothy refuses go marriage planned ronald coleman always delight watch early talking films sam goldwyn playing confident adventurer cad demeanor akin errol flynn unable display flynn physical agility due disabling wound received world war however lacks physical agility coleman always made agility soul loretta young picture made shows beginning trademark sweet girl erupt ball fire occasion calls myrna loy plays willie girl past mary crayle showgirl myrna still playing part similar exotic vamp parts got stuck often warner brothers contract player shortly movie made pretty much light breezy romantic comedy start finish mood kind escapist entertainment lightened hearts audiences great depression little film fits bill\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "footprints interesting movie somewhat difficult categorize psychological thriller appropriate description think female protagonist alice cespi discovers remember anything last three days clue torn photo hotel also haunted recurring vivid dream science fiction movie believes saw many years ago pursuit truth behind amnesia trust anyone little little becomes obvious visited town hotel located exciting flick whose main virtue virtually impossible predict events unfold particularly end unusual loneliness main character unreliability everyone else ensure good old paranoid feeling present throughout film whereas beautiful colors spectacularly filmed sequences make visually attractive movie well important part one nicoletta elmi everyone time favorite redheaded obnoxious child star italian horror extra bonus\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "love story american journalist eurasian lady doctor contain much conflict since largely westernized studied london fireworks since behaves rather restrained little interest story manages raise knocked wooden dialogs supposed two cosmopolitan intellectuals talk words put mouths hollywood hack much one movie also suffers amazing lack realism completely deserted beach crowded little hongkong overrun million chinese refugees presumably accomplished american journalist know hysterectomy hollywood ideas finally song hearing estimated twenty times throughout movie starting right credits tends loose emotional impact sorry say\n",
      "\t./checkpoint/cnn_classifier/cnn 0.16545721888542175\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "typical indian film great sense humanity characters pretty realistic great dynamism interpersonal relationships sense guilt grief passion passivity among many characters seeing one gets feel heavy burden years layers layers history social existence one oldest civilizations final scene elephant walking away rural area great footnote ancient civilization yet human relations still preserved nurtured saw dvd two interviews director main actress interesting surprised learn movie done well shown india maybe surprised artistic patrimony rural societies slowly lost inheritance picked younger generations older musicians movie longer living today great film\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "movie tries first acting horrible get past incredibly bad delivering lines terrible emoting plot quite interesting shipwreck occurs apparently made strings balsa wood couple guys find shore bad enough guy named count de sade living well lives fear pirates gone utterly insane anyway large slave young woman dogs another woman speak wife leper anyway things get bad men deal nut case arrogant likes pose deliver lines rest movie involves attempt escape ironic ending reveal kind rescues film bother\n",
      "\t./checkpoint/cnn_classifier/cnn 1.278294222483905e-20\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "bad dreams always come back like unwanted friends says marion fairlie half sister laura lives vast mid victorian country estate last night found limmeridge churchyard normally people dead stay dead normally criminals locked rather victims nothing normal happened us first class gothic story madness deception villainy based wilkie collins great novel victorian mystery good idea pay close attention plots within plots yet center cunning ruthless scheme involves else money lots money marion fairlie tara fitzgerald sister laura fairlie justine wadell devoted marion fierce protective laura softer much romantic marion money laura inherit riches comes age marion marriage prospects know laura pledged sometime ago sir percival glyde james wilby altogether charming aristocrat wards uncle fussy condescending immensely self centered hypochondriac ian richardson seems quite routine young artist walter hartright andrew lincoln engaged teach drawing artistic appreciation arrives night local train station carriage sets foot estate dark woods encounters strange woman dressed white wandering speaking things understand disappears uneasy yes sisters come realize strange woman looks much like laura later love emerge walter laura bud bloom misunderstanding sends walter away results laura marrying sir percival canker gnaw secrets slowly come light relationships among laura marian woman white learn deeply suspicious sir percival intentions come enjoy style manners sir percival close friend count fosco simon callow eventually realize foul depths depravity well power honor true love humanity capable visit victorian insane asylums see falls high towers dig open graves middle night watch retribution arrive amidst roaring flames locked church well course grand journey us bbc masterpiece theater program features fine acting outstanding production values fit collins plus page novel television show less minutes means good deal cut abridged changes made likely achieve greater impact little time available still taken terms production woman white opinion works well moody romantic dark television tale tara fitzgerald marion gives commanding performance woman determined protect save sister james wilby sir percival manages clever feat slowly letting us see depraved slime beneath skin still charm amidst villainy ian richardson young women uncle almost steals show gives bossy pungent performance almost unbalances story every time appears perhaps weakest main parts simon callow count fosco count simply monster yet supremely civilized charming one collins described immense girth callow fine mannered job lacks little monstrosity evil one point marian tells us sister fond gothic novels sometimes act little know store laura\n",
      "\t./checkpoint/cnn_classifier/cnn 0.017933126538991928\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "still wonder sat entire thing minutes actual entertainment rest total bore acting great action scenes soooo cheesy even funny kinda wish could say something good film think anything right probably somethings enjoy ending gotta dumbest idea ever type person would get little toy remote controlled helicopter burned machine gun assassinate president idea could never done first place let alone anyone dumb enough try guess writer must obsessed toy car scene dead pool actually tried make look serious\n",
      "\t./checkpoint/cnn_classifier/cnn 9.005855424509895e-32\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "serious marathoner seriously disappointed film target audience clearly never run marathon novice marathoners following stories first time marathoners one senior one injured runner two elites prepare chicago marathon film dedicates majority attention one female beginner whose story lack better word boring enjoy brief glimpses training sessions deena kastor brief history boston marathon marathoning general let emphasize brief watching joe runners prepare saturday run water bottles talking view marathon inspiring nonstop clich achievement feel good grinning runners make wish film hour shorter first time marathoner film may give feeling anyone else run away\n",
      "\t./checkpoint/cnn_classifier/cnn 2.9085907016224155e-08\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "generally love type movie however time found wanting kick screen since complain absolutely idiotic things happen dead kids cool alive people absolute idiots grown man pretty big defend well however would half stuff little girl movie also mother movie reckless children point neglect wish angry actions would otherwise enjoyed flick number take advise fast forward everything see end also anyone else getting sick watching movies filmed dark anymore one hardly see filmed audience impossibly involved actions screen hell night vision\n",
      "\t./checkpoint/cnn_classifier/cnn 7.096079723822868e-09\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wonderful family movie beautiful horse movie entertainment casey buddy kelly marsh interesting lovable characters horses real beauties horse racing backdrop showing luck sometimes nothing good commonsense shows kids stupid things stupid reasons shows adults stupid things selfish reasons realistically portrayed characters transform unrealistic theme film something everyone relate andrew rubin puts wonderful performance buddy sensible elder brother somewhat reminded aidan quinn eyes speech delivery facial appearance casey makes fall love character earnestness sarah blue also nicely portrayed alexis smith lloyd bourdelle father played walter matthau character though room improvement movie enjoyable feel good movie\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999998807907104\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "really film two halves first detailing lives friendship two boys one privileged pashtun trodden hazara late afghanistan invasion ussr works extremely well young actors turn convincing performances seeing afghanistan throws present situation stark relief real problem comes move later phase story join pashtun man living america ancient debts young friend lead return homeland really point things break central adult character clearly supposed sympathetic fact comes across wimpish wallowing self pity hard really care one cannot help feel really interesting story one get see boyhood friend returns afghanistan narrative becomes bogged series highly contrived coincidences remarkably manages come across childhood enemy years almost immediately even though looking despite chaos since consumed country enables confront past demons way simply convenient credible resolution narrative also run awful mawkish sentimentality undermines really serious points film may trying make although possible start seeing characters abuses lives symbols state torn apart world politics hard really see film engages wider political discussion instead narrative becomes reduced one character emotional journey self discovery healing unfortunately character dull wrapped hard really become engaged story opportunities make really interesting film afghanistan wasted\n",
      "\t./checkpoint/cnn_classifier/cnn 2.395911558039643e-08\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "often neglected harold lloyd actor unlike chaplin keaton lloyd vaudeville music hall background natural comedian came hollywood act discovered knack acting funny first shorts features made name lonesome luke chaplin knock glasses character made american boy rather grotesque lloyd found stride movies became best produced silent era developed reputation daredevil shorts retained best movies safety last heaven sake girl shy popular either chaplin keaton twenties became rich advent sound first sound movies often disasters get sound much dialog used many movies lloyd acting skills two decades geared silents bad voice high pitch suited glasses character sound films unqualified disasters legend yet silent movies raised high art especially lloyd stint budget extremely well crafted introduction talkies movies learn walk made missteps though tried move times embraced sound lloyd best bits early overly talky talkies still visual scene movie crazy appears riding swank car actually hitched ride bicycle trying recapture daredevil antics made famous feet first misstep safety last best movie one deservedly shoved lloyd box daredevil comic played determined young man climbing top safety last natural structure ascended character scaling side building obviously afraid fear added humor feet first arrived precarious building scaling position accident frantic cries help detracted humor character pathetic cringing aspiration save neck possibly accurate statement amusing harold lloyd mired past like wacky norma desmond embraced sound tried take movies different directions growing changing industry feet first failed left daredevil business made satire talking movie industry movie crazy flounder many movies lonesome luke carving place movie history glasses character tried several directions sound movies hitting stride sound catspaw catspaw plays missionary son reared china unwittingly gets elected mayor front corrupt political interests finds truth sets task cleaning town early forties lloyd could still act brash young man yet catspaw another box office failure lloyd made three movies including milky way chief competitors chaplin still silent movies keaton hopelessly mismanaged catspaw milky way suggest lloyd might mastered sound comedy little younger audiences given benefit doubt early sound fiascoes though movie unfairly maligned way lloyd character cleaned town suits days shorts lloyd wanted scare audience climax catspaw achieved yet surprising way trick revealed appears gruesome come laughs viewed product time catspaw charming funny well written sound comedy well acted lloyd directed sam taylor curious blend drama sly humor make look almost like frank capra preston sturges comedy\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "park avenue address mithi mithali konkona search movies beginning prof anu shabhana azmi mithi extremely caring loving half sister mithi mom earlier marriage movie revolves around characters looks life schizophrenic patient mithi director tries explain viewer imaginary world mithi continuous blabbering anu others konkona deserves one thousands awards sure getting rendition mithi movie see look patient written face drooping lips sleepy eyes first scene rahul bose done good job reduced one half movie spite importance life watch intense relationships shown characters movie mithi anu anu anu mom anu sanjiv kanwaljit singh shabhana azmi usual done riveting performance remembered sister sacrificed life mithi movie might usual hindi potboiler certainly make people look schizophrenic patients different light altogether usual aparna sen brings movie different ending rather clich ones might think hats great movie\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999998807907104\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "like madonna movie hilarious madonna fan see theater time release however time lost silliness pure fun sure bad lines cheesy acting whole film screwball comedy madonna actually carrying whole film great bombast cute funny comedic role movie career madonna usually plays roles watching nikki finn film really seems like somebody else course film directed james foley filmed dramatic haunting close range sean penn christopher walken co stars griffin dunn hours also brilliantly cast fun material story nothing genius expect climatic ending ever mood watch fun clean romp madonna fan must see soundtrack also notable contains madonna songs hit girl hit causing commotion beautiful one best ever ballads look love top hit uk stop left pop ditty true blue sessions year vhs soon available dvd\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "many film dvd producers forgotten tittles importance many moviegoers egyptian along el cid favorites era wide screen big budget epics merit many people generation learn lot history egypt medieval spain even incas first time heard cheap adventure movie charlton heston called treasure incas happened egypt rome seen many bad epics era many production values excellent use color de luxe color brigit sharp ordinary technicolor maybe cast wrong case film man ged give us idea life ancient egyptin way motor go buy novel mika waltari one best best historical novel ever published also oust anding superb score alfred newman bernard herrmann saw film many times boy big box office hit fox studios wanted afther robe enormous hit cinemascope stereo wonderful eye popping sp ectacle lasser disc version way see ito wdisescreen format soon hope appeared\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "taken story dear people edinburgh heart true story changed hollywood done many tale end result movie however well done know story yet totally different inaccurate original movie tale walt disney oversaw used right breed dog crucial tale make john grey anything special poor shepard died poverty inn like story watch disney original better heart warming story shame cast potential terrific remake classic tale read book accurate occurrence story really like visit real kirkyard edinburgh\n",
      "\t./checkpoint/cnn_classifier/cnn 3.456616435681785e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "tangier wealthy american woman two children kidnapped berbers murderous desert pirates scorn moroccan government kidnap american pestilence attracts attention u president theodore roosevelt fictitious historical epic less grand adventure peculiar somewhat exhaustive throwback desert sheik films bit king interjected besides portraying cloaked mustachioed bloodthirsty leader snippy haughty captive sean connery candice bergen could acting two entirely different movies neither one seems know far carry camp elements characters dialogue seem singularly without proper direction various anonymous slashings beheadings occur arbitrary know victims big action scenes become blurry noisy montages sand swept violence horseback pluses much lauded music score jerry goldsmith oscar nominated loser john williams jaws fine location shooting cinematography\n",
      "\t./checkpoint/cnn_classifier/cnn 4.626404552254826e-05\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "priscilla queen desert always trotted masterpiece australian cinema found quite disappointing lead actors great terence stamp aging beautifully guy pearce comedy instead dour roles chooses fan hugo weaving since saw play oberon eons ago cinematography great ever australian outback know air clear light brilliant could shot movie equivalent box brownie still would looked spectacular problem well three things first sympathetic female character whole film woman earn living shooting ping pong balls privates roadside pub deserves sympathy tick wife get much better treatment second scene sing survive group aboriginals offensive try draw sort parallel struggles drag queens trannies almost total destruction aboriginal culture assume scene supposed shows level historical understanding worthy paris hilton last greatest defect film funny enough stephan elliott actually talk drag queens writing film anyone knows drag queen three four knows rapier like wits afraid use understand lot drag queen banter probably would got film refused classification elliott able gather enough fit kiddies material complete film waste good idea great cast\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "short movie intends focus one issue sociologically known cultured shock film presents condition average romanian democratic romania finds life problems different communist period want something must bribe around get main character fired long around needs get similar job job available one inferior forced take lack money opinion live romania movie real tragic seems\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "ever wonder worst movie ever made stop wondering telling michael heartwarming entertaining travolta best sucks kids would let watch deep throat michael sold john travolta washed balding william hurt die time jean stapleton highlight turd film wait get hear andie mcdowell sing yeah hollywood really us one\n",
      "\t./checkpoint/cnn_classifier/cnn 9.01973120317336e-20\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "story sweeney todd evokes memories work classic writers like charles dickens contemporary writers like edward gory musical naturally becomes like musical les miserables deal grim effects poverty industrial revolution breakdown organized society musical different les mis one important aspect stephen sondheim songwriter adapt style sure successes failures one thing shows always count something unique would thought someone would write musical barber slits people throats makes meat pies sondheim marvelously entire show set factory suggest ever present catastrophic effects misery bottom society serves needs show perfectly catwalks railings moved throughout suggest streets walkways bridges techniques borrowed kabuki noh visual stagehands set changes top cast great angela lansbury gruesomely practical humorous mrs lovett george hearn operatic baritone voice murderous todd got stellar musical vehicle rest cast moves smoothly clich love story perfectly except johanna pirelli sound bit forced johanna pirelli broadway show could would perfect hearn acts sings len cariou obc album accents sound forced sondheim score never fails underline dark seriousness story said adapt style follies imitates style showtunes pacific overtures captures subtle art asian music woods knocks bar disney style songs assassins covers history american music however wonders making score distinctly english parlour songs operatic duets soliloquies society waltzes gilbert sullivan style patter yet still show remains deadly serious even though provokes laughs musical comedy still grim warning evils taking revenge movie makes mistake cutting judge solo flagellates guilt crimes without judge conventional villain movie point straight villains todd judge learn late horrors accept responsibility actions todd loses everything obsession well brought chilling reprise grim yet rollicking ballad sweeney todd ending show todd lovett rising grave tell us end world full sweeneys vengeance begets vengeance attend tale sweeney todd served dark vengeful god seek revenge may lead hell everyone seldom well sweeney sweeney todd demon barber fleet street\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "honest thought movie would japanese drama dead wrong movie based popular japanese anime novel name tells story town cursed uzumaki spiral english little little towns residents start slowly become dangerously violently obsessed anything spirals residents start actually turn living things actually sort spiral within snail movie one giant random acid trip twisted romance drama sort like twisted drama makes movie disturbing ways people obsessed spiral example one dads garage full house hold objects spirals incorporated one girl took extremely long hair teased insanely huge spiral like style one kid slowly transformed human snail one man could twist body spiral shape one woman attempted cut ear open obtain cochlea inside one teen ran could twisted around car tire one kid stuffed washer could become spiral another disturbing aspect well syndicated atmospheric tone style movie shot camera angles add psychotic twisted story words good cinematography overall coloring picture makes somewhat demented story coloring blend lime green yellow little orange special effects spirals outstanding however like many japanese films one undertone forbidden love romance girl boy however spirals strange happening going town hard keep relationship two teens way irrelevant like second hand story nothing actual story spiral obsessed town overall would recommend film anybody likes vastly different bizarre foreign films enough wackiness insanity touched\n",
      "\t./checkpoint/cnn_classifier/cnn 3.8516296626767144e-05\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "film remake bbc serial called friend charles gallops thru material relatively short time found fast moving enjoyable unpretentious anyone else notice scenes towards end john mills gassed producers obviously decided omit scenes maybe censorship notice sat window flat deep breathing closely followed similar scenes car window open francis durbridge serials seemed inhabit universe unexplained happenings people seem villain someone close hero victim predictable universe ways one rules regulations\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999998807907104\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "saw league gentlemen apocalypse special screening manchester mark gatiss reece shearsmith league attendance back peter kay brief cameo film affectionately heckling back q session film film complicated good way funny follows geoff tipps hilary briss herr lipp try save fictional rosyton vasey disinterest creators league play wide range characters character based ably supported cream british character comedy actors bernard hill victoria wood david warner warner particular stand reminding smooth cutting turn time bandits film swims various realities allows denizen rosyton vasey space grow beyond usual limits comedy shtick steve pemberton herr lipp great bretchian moment near end movie make decision purpose meaning life brings lump throat unexpected moment surprises tender affection characters echoes something mark reece said q afterwards plot league tired famous characters spurious whole film really love letter format started radio character based sketch show guys really evolved idea far sustain movie takes journey fiction reality comedy tragedy pleasing journey two less obvious characters carry long form story odd existing creations fans show love pays dedication attention detail spades uninitiated may little lost joy log always ability almost instantly tune acutely observed characters take stylistic leap farce expressionistic movie homage homages plenty one including shining la belle et la bete name two spotted ably demonstrate love cinema history segment england makes perfect sense engaged movie say marvelled boggled emoted snickered throughout definitely pulled many failed successful british tv comedy cinema translation watched enjoyed league gentlemen past go see enjoy rent buy dvd go see well done guys thanks charming humorous q\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "review contains spoilers expectations movie pulled video store rack movie white noise first credits stupid movie run minutes pacing start finish slooooow main heroines like wear bra director appears enjoy jiggle effect anna paquin descends stairs like movies boobies one low level buzz factor second nice movie rips elements lovecraft horror genre mechanisms better movies least rational consistently irrational behavior stinker tries establish sense modernity reality situations one calls police even though uncovered treasure trove potentially incriminating forensic evidence otherworldly rituals nicely spelled comprehensive book otherworldly rituals like buffy waiting miles show give consultation slay certain demon type premise possible open age darkness creatures crawl ceiling cut throat turn meat grinder effect ho hum need sacrificial circle seven kids must throat cuts people love opens world age darkness least says complete detail book ancient occult rituals raises annoying question uh well ones wrote book know happens would really leave information book take library much less get library world covered already darkness age brought lunatics could performed like much earlier using occult practices bring world darkness dummies nd edition turns father story th child one ran away ritual years ago released father doctor grandfather movie wanted try ritual presumably stupid parents wanted see dumb sh like opening world darkness actually works grandpa let father go really love aduh stupid stupid movie written moronic director appears think kind eurofilm auteur also scene movie kid appears big welts face mother grabs total lack reaction whole movie like people seeing really weird sh going reacting sort normal way must bad plot direction anna paquin best play character realistically without cracking smirk look smashing halter top several critical moments story character bother call back know walk likely demonic evil situation without knowledge defense help others carrying flashlights firepower even though sense impending doom even dumber may seem even bring age darkness creatures make bloody attack light source appear people know tell turn light source reminds video game alone dark maybe movie rip game concept best actors film young kid anna die end entire family dies darkness creatures lead death really stupidity characters family main cause death adults could interchangeable actors red shoes diaries series fine cinema wrap worst things movie stupidity characters bumping around blindly obviously abnormal situation really crap plot old architect story designs house sacrificial altar hidden architect suspected beginning would occult sacrifices house tell anyone well real reason find kids bother tell authorities hidden rooms designed house like hang around house year period worries going inside derrrrh duuuuh hackneyed use scare mechanisms children standing around dark showing photographs blood wallpaper egotism director see dvd features describing crap work new original rendition makes understand real horror movie lies entertaining x speed dvd player subtitles turned entertaining reach end realize movie crap otherwise draaaaaaaags cinematic equivalent fatty shake empty calories horrid movie gives feeling director must seen ring wanted attempt create something similar mood respect film fails miserably also respect jaume balaguer opinion suck\n",
      "\t./checkpoint/cnn_classifier/cnn 1.1818117595652211e-09\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "saw film first time impressed concerning kind atmosphere director creates also interesting see imagine near future year see film see lot sets customs called freaky modern today topic film deals old question real illusion see matrix find lot similarities two films comparable welt draht art matrix entertainment prefer first one unfortunately lost video copy\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999998807907104\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "went see movie theater paid money thinking would least mildly entertaining thing enjoyed robin williams crashes car bottom hill end seems get killed glenn close obnoxious obviously seem old enough garp mother mother like garp would kids taken away department children families robin williams glazed donut look benign goodness sweet smarmy two roles play funny person sad tragic good hearted victim see fisher king good morning vietnam called dramatic roles always performance put together one long mini series glenn close always cold fish remember fatal attraction would affair even worst day single feel sparks michael douglas ever seen glenn close warm screen john lithgow interesting role back day used play serial killers bad guys seeing transsexual least funny garp made people love see movies sick abnormal dysfunctional people claim beautiful profound\n",
      "\t./checkpoint/cnn_classifier/cnn 1.984757543490028e-16\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "thrive cinema limit name enough make movie beginning movie puts us mood expect unseen yet remain hungry angry till end things getting confused admit understand end end nonesense opportunity make outstanding movie target totally missed next\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999785423278809\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "exactly sure accuracy movie tell thoroughly entertained movie character gust played perfectly phillip seymour hoffman one unique yet entertaining characters recent memory movie informed yet managed avoid preaching audience made laugh made sad made feel alive glad spending time watch movie takes time understand going takes roller coaster ride genuine human emotion thought knew history apparently know give move recommend adults young adults young heart young soon allowed see r rated movies make priority\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "low budget memorable would shocker instead emerges theater bizarre vulnerable naive nurse charlotte beale comes secluded mental hospital completely unaware sane people murdered despite red flags constantly raised around lack decent budget really gives filmmakers little go sense style well cast wacky characters pleasures film come film shocks fairly tame weird atmosphere first delusional woman thinks baby doll real also axe murdering judge shell shocked war veteran old mrs callahan like everybody daffy elderly grandmother gone amok young patient named allyson gives term nymphomaniac new meaning big guy named sam little slow botched lobotomy jennifer vaults suddenly catatonia violent outbursts sentient person place seems dr masters secret look basement great example low budget exploitation films much plot going cheapness works movie several cast members turn memorable performances particularly betty chandler annabelle weenick way director adds little weird details movie really stick scene allyson telephone man classic time especially delicious facial expressions dr masters begins go edge near finale movie brownrigg also makes great use cheap soundtrack several musical cues really evoking characters accompany favorite cue crazy cue sitar twangs whenever one patients something pathological also wonderful way charlotte plunges hysteria climax patients revealing dr masters simply another inmate suggesting charlotte also patient allowed act delusions certainly tenuous grip reality else would question ominous lack phone service outside contact scene charlotte manages finish barely alive dr stephens toy boat one greatest moments low budget horror yes look basement could well american beauty grade z trash\n",
      "\t./checkpoint/cnn_classifier/cnn 0.00031043021590448916\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "take someone love want love go see film touches right places reviewers said perhaps cynical impressed seem like stuff leaves depressed days film ga run teed stay life gratified director usc trained validates premise much mediocrity conformity film days usc lockstep mentality inbreeding hooray jeff hare richard marcus cast crew well done\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "surprised much enjoyed sure bit slow moving parts else would one expect rollin also plenty nudity nothing wrong particularly includes lots gorgeous brigitte lahaie also spectacularly eroticised female dead bit dodgey perhaps effective also sci fi like storyline brief explanation end bother much interesting exploration memory effect memory loss extent one still alive without memory dvd sleeve mentions david cronenberg whilst perhaps quite good best films similarity particularly great use seemingly menacing architecture effective creepy use inside space tried indicate means rip roaring thriller captivating nightmare like movie makes locations including stunning railway setting end\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999995231628418\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "picture scene bored student empty day ahead video shop special offer video week rentals ex student usually grabbed pile videos dubious quality arbitrary reasons turning anybody occasionally odd undiscovered gem make vcr case film everything film good much parts mesh provide something rare cracking good film never got uk cinema release beyond especially consider crap wade multiplex week week whilst happily accept oscar material neither sodding titanic schmaltzy cgi tinged bollocks extremely enjoyable film trying think way describe best film appreciated accepted perfect film watch bonding dad coming home holidays large sunday lunch\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "milo complete rip slasher flick mikey actually check films tagline want watch incredibly funny film absolutely plot whatsoever well film acting terrible flashback scenes overwhelmingly confusing story behind atrocity simple milo jeeder kid serious family problems father abortion doctor keeps unborn feoutus jar nice desperate child figured way bring one aborted children life named milo aside bad acting terrible directing annoying sound milo voice ear piercing sound bell bike take away badness still bad funny attempt film give bank busting\n",
      "\t./checkpoint/cnn_classifier/cnn 2.7440097277122374e-34\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "come bangladesh c c costigan goddess awesome sex kidding aside friend awake middle night watching movies encore action channel came across series sci fi esquire flicks robocop bad bad judge dredd stalone almost ruins career movie called lethal target one would think title lethal target could awarded really cool really cheesy rambo knock nay delivered would like call semi softcore semi pseudo action semi sci fi film actually think say even film main character sheer hotness friend would turned movie opening credits rolled questions people even dare say professionals made film one future using weaponry used oh wait get could get hands right well main character wearing looks like normal everyday linen shirt vest kinda like people wore late nineties oh get space must fashion statement well oh main character pull floppy disk one point film upload bullshit wtf progressed far space travel still progressed past megabytes space guess asking much question two let say yes softcore porn one real sex scene last minutes mean taking reason people staying middle night see crap dare say movie anymore whittling minutes hell taken sex scene sold another porn movie would still made money crap c c cortigan hot offense actress acts well mentally retarded one testicle c c cortigan e mail lunch would write run space\n",
      "\t./checkpoint/cnn_classifier/cnn 4.6041543109521035e-14\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "bought movie market stall three years ago gotta hand sat watched thought ok gonna another big action b movie obviously wrong watching film began realise movie taking another planet full cr p began get really bored fed film although wanted see gonna happen end really felt like really getting nerves people behind film may brought well known name actors project thinking even actors save film end film felt like waste money buying low life sucker film small amount money months later sent tape charity want see sorry thinking watching movie nodding sleep highly recommend rather go pro plus watch something decent disappointing\n",
      "\t./checkpoint/cnn_classifier/cnn 1.3487665608132807e-15\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "destroy planets winds settling destroy tokyo film end space monster resembling giant squid falls reptilian furnace known gamera actually gamera saving earth right get go knocking varian space ship even first set film credits roll scene switches japanese scout camp meet pair meddlesome young heroes jim masao take part gamera exploits kidnapped aliens beamed aboard ship electrified bubble shield pretty startling see boys convince scientist let operate newly invented submarine might defective previously boy genius masao wired unit run reverse direction controls dr dobie think checking possibility least prepared boys interfering alien space ship controls playing switcheroo bunch triangular blocks boss alien viras says activate videotron hang seats rehashed footage earlier gamera movies battles barugon gyaos take quite bit screen time match fast forward button want get longest time viras addressed invisible crew finally appeared orientals could fly imagine seeing movies made juvenile audience surprising see gruesome scenes gamera drawing blood comes mind pair space crew members decapitated squid tentacles started emerging headless bodies made connection alien films individual units merge form giant viras neat device guess appeal young kids might reside identifying two young heroes make friends giant monster move around pretty freely alien space ship get whatever want help alien telepathy technology seeing movie presumably made adults could simple case wish fulfillment\n",
      "\t./checkpoint/cnn_classifier/cnn 3.974991614086321e-06\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "another endless amount cookie cutter kickboxers fight death amusement wealthy scumbags films many know ones created taking words death blood steel words ring fight match cage putting random generator saying though death match pretty good entry used genre thanks exciting fight scenes surprisingly good acting kickboxer cast story concerns two buddies ex kickboxing world champion john larson played pug faced middleweight kickboxing champ ian jacklin probably previously best known awful performance main villain ring fire nick wallace nick hill likable guy probably best known role street fighter sergio bloodsport work l docks loading crates onto ships one discovery boxful guns brief fight later two heroes jobless propping l bar sensible john larson decides head north look job headstrong nick wallace heard guy paying good money fighters fight private kickboxing matches things change says john need predictably enough long nick gone missing good friend fighting deadly ring death trying find lead missing buddy sure enough prizes originality like said films strength lies action cast real life fighters fairly good performances manages wring ian jacklin particular surprised previously seen bad guy ring fire bit parts tripe like steel ring always quite amused bad actor good fighter though death match pretty good given decent script haircut proves quite charismatic leading man friendship nick well portrayed jacklin hill nice chemistry really believe two characters care enough one lose job travel halfway across country risk death save wish friend like also nice see matthias hues villainous henchman little depth used seeing many villainous henchman roles however fooled thinking star video cover seems head stuck body michael bernardo cover shootfighter good screen much negative side film pretty slow fighting going lots unnecessary scenes whats gangster jimmie fiorello pointless story grandfather end fight disappointingly short whole enjoyed plenty fights good martial arts really need course eye candy lovely form pretty renee ammann pretty entertaining kickboxing movie\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9881884455680847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "film started got feeling going something special acting camera work undoubtedly good also liked characters could grown empathise film good atmosphere hint fantasy however film went plot never appeared takeoff rolled scene scene unable understand connection stories could see characters occasionally bumping references ships bottles without connection left unremarkable short stories surprised well cannes\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999971389770508\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "consider huge horror movie fan one night wanted rent newer horror movies make fun rented milo surprised movie scared hell outta something say often usually halloween scares two friends watched left disturbed feeling good feeling ask watching horror movie unaffected point movie original follow normal guidelines horror movie movies like valentine bombed course many left unanswered questions horror movies worth rent though\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9292302131652832\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "seen installments one far best nt much expectation got dvd rd drag delight one fast paced slick punch lines miss one\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999879598617554\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "compare two films sacha cohen borat ali g ali g immeasurably better ts master piece film least borat complete garbage understand rated better ali g cannot put finger something wrong ali g script half jokes written years old adult scriptwriter number jokes including mr cohen lower body quite tasteless film actually comes together comedy valid jokes funny ali g becomes member government something scandalous stupid public sadly true today western society people get careers stupid things public also ali advice immigrant policy others ali g overall remains sympathetic character even though kind mentally underdeveloped age ok watch quite funny never ever watch borat awful makes every intelligent movielover sick\n",
      "\t./checkpoint/cnn_classifier/cnn 3.6470826184814873e-20\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "one enduring classics mgm came closing years world war ii film made young elizabeth taylor star done films child actress national velvet came place movies assured ironically enough biologically growing fast enough national velvet next struggle actress get substantial adult roles casting directors saw innocent little velvet brown loved jumping horse sure would work steeplechase horses confirmed bloodlines pi subject dealt national velvet know reckless untrainable horse hands reginald owen breaks free causes considerable damage owen gets rid nominal price local butcher donald crisp time things happening mickey rooney comes wandering lives brown family consists crisp wife anne revere daughters angela lansbury juanita quigley elizabeth taylor little brother butch jenkins rooney former jockey open road heading brown family father horse trainer anne revere family sees potential pi short pirate steeplechase jumper elizabeth convinces crisp pass chance elizabeth taylor sweet innocent national velvet good book says faith like child spare infuses rooney faith heart ability pi leave little anne revere best supporting actress award national velvet wise mother hidden depths audience suspect turns back youth taste fame glory swimming english channel prize money saved years gives daughter scene probably oscar national velvet also one academy award film editing years made debut national velvet family classic lost thing depiction life world wars great britain still standout national velvet launched movie legend much better high regard\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999514818191528\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "funny film like lot cary elwes plays robin hood tee course usual good vs evil robin evil sheriff nottingham humor sort face stuff part still works well comedy night want think much well worth rent\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "really like show part greek life say things exaggerated overall still pretty damn funny rusty likable lead character roommate hilarious entire cast entertaining rights like focuses individual situations well interpersonal relations organizations show covers without cursing anything else bad else could abc family favorites cappie course rusty roommate pretty much kappa tau show great launch pad excited see doors opens please renew show next summer abc family like said love love love\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "oh f cking hell start first show another stupid american non funny called comedy pathetic acting poor humor american way laughing track business makes whole thing even worse come hear laughter yet nothing funny happening pretty stupid eh show american people ever heard far funnier better wittier comedies great brittain also america simpsons example simply understand good reba lasted long television nothing new offer underestimates possible viewers many ways simply funny could lived fact bad shows reba hell run finland see seconds horrible show rest day ruined take word believe show sucks ass even kind american comedies usually simply horrible favor ever watch peace sh well leave commenting language better thanks possible interest\n",
      "\t./checkpoint/cnn_classifier/cnn 1.4376281804624366e-31\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "boring movie humorous parts plain boring lengthy minute movie believe cause lack action rented movie expected see white blood cells combat evil viruses luck virus thwarted defeated movie promise since made little kiddies mind meet potential opinion\n",
      "\t./checkpoint/cnn_classifier/cnn 2.369391060485622e-22\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "part bbc filming shakespeare classic plays version hamlet nothing dispel particular impression one shakespeare rated plays hamlet particularly moving tragic character feel sympathy watching even great actors like great derek jacobi role dane patrick stewart claudius jonathan hyde rosencrantz cannot disguise lack passion storyline good actor like jacobi injects passion renders entire role incomprehensible could connect physicalisation character saying killed said get speech right actions dagger make clear character suicidal intentions point play supporting roles better written consequently better played enjoyable notably lalla ward loopy ophelia stewart well detailed interpretation claudius four half hours long best watched bite sized chunks check interested prepared long watch\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "corned beef cabbage little romantic comedy clips along scene scene exotic twists imaginary scenes costume party centered around wife husband looking break doldrums played gloria swanson twenty leading men natural air convincing course swanson perfect kinds moods frivolous worried hopeful behind games apparent lightheartedness old serious problem staying love straying love little corniness director demille top keeping snappy believable many films period subtitles tell saying thinking often give kind philosophical insight justify tragedy raciness higher purpose probably better without instructional text part narrative style kind quaint looking visual formal amazement find story well acted filmed precision economy really great example events might come total surprise modern love story set almost hundred years ago gas saw swanson perfect\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "favourite movie time flawed piece work coppola seeing documentary heart darkness made even compelling coppola point king hollywood making godfather godfatherii developed ego necessary even dare try make movie like apocalypse sheer arrogance went phillipines partial script thought would know would got captain willard thought would know got col kurtz compound like willard know going got masterpiece american cinema beautifully photographed river perfect metaphor backdrop story like apocalypse offers answers conclusions consequently open endedness infuriates viewers like movies much obvious movie defies categorization call war movie really personal study man best pic vietnam platoon opinion viewer seeking retelling vietnam war go first answers coppola commended take bureaucracy war conveys quite effectively meeting gen corman lucas harrison ford playmate review sheer audacity kilgore makes unforgettable character dawn attack always hollywood classic almost psychedelic cruise surreal ending makes movie accessible everyone challenging watch rewarding well could offer explanations scene would totally pointless movie intended interpretation contemplation opposed immediate gratification little footnote definitely first time viewer apocalypse watch original version first redux version think intended hardcore fan curiosity new improved version movie\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "aside fact women film stunningly beautiful camp prisoners fat film rings true chaos post war beautiful photography powerful national expression polish national character slow points entire pacing different american western european films quite refreshing lead actors good job dvd version see interviews principal actors crew lead actress stanislawa celinska gained lbs lost beauty stunner\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "cant put simpler terrible film worked industry made several short films okay standard pretty high seriously absolutely hate film made comment imdb hated film much literally come warn others piece sh writer director idiot idea make write good film writing skills adolescent teenager characters unrealistic lead woman think taking policeman pistol yet resourceful enough improvise molotov cocktail please even likable hell hated cheered died understand director trying demon redneck idea looked like sloppy writing convenient bullsh real thought behind officially worst movie seen year congratulations shiban rank greats micheal bay prestigious shouldnt allowed waste millions dollars making film club hope read really idiots rated film bwahhahahahah oh god hope redneck demon appears conveniently behind tortures\n",
      "\t./checkpoint/cnn_classifier/cnn 1.9176245257856994e-33\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "great tv movie told murder martha moxley greenwich connecticut nephew ethel kennedy use ghost martha provide details effective added lot heart story christopher meloni seemed capture personality mark fuhrman well furhman got much underserved bad publicity j simpson trial certainly vindicated contribution bringing killer justice years\n",
      "\t./checkpoint/cnn_classifier/cnn 0.7636933922767639\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "surprised liked movie reminded version first friday th number cheesy elements yet time many cool ones story line good predictable seen one two horror movies full one liners make worthwhile memorable scenes worth watching issues plot continuity characters instance opening scene scarecrows humans stakes whose blood drained grow crops looked real later film looked like fake scarecrows wearing blue colored masks several gaps plot acting mediocre least sounded like real people talk unlike hollywood movies dialogue really fake sounding think culmination last scene main character says baker connell lops head scarecrow satisfying friends part killed creatures point\n",
      "\t./checkpoint/cnn_classifier/cnn 1.059550017168398e-11\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "believe actually spent almost three hours life watching must one unbelievable predictable cheesy television movies seen long time hoping good special effects action instead spent entire time rolling eyes yelling oh come screen dialog shallow obvious acting strained times story moves along funny everything happens time mention obvious nauseating ending seen share disaster movies big fan actually think often pull completely unrealistic stuff long done fun way definitely insult intelligent viewers everywhere thinking made movie\n",
      "\t./checkpoint/cnn_classifier/cnn 7.655714847872377e-14\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "young theater actress reluctantly accepts first major part staged play lady macbeth thanks mishap production diva falling front moving car success winning accolades betty christina marsillach finds instead horror one responsible getting point terrorizes cruel ways first stage manager boyfriend stefano william mcnamara viciously stabbed knife watch rope tied pillar uncle vast mansion keeping eyes closing thanks needles scotch taped eyes pricking result blinks allowing escape betty finds unfortunate position specific gold chain found lady macbeth wardrobe torn shreds madman killing series crows escaped cage equipment room clothing designer first knocked floor iron subsequently stabbed heinously pair scissors cap nasty scene chain falls throat killer cut open throat find specifically elaborating act dario uses ripping sound scissors optimum effect camera often retreating back victim dead face nowhere turn inspector alan santini urbano barberini playing cold bland dario request promises catch psycho betty relies remaining friends comfort theater director marco ian charleson ghandi chariots fire would later die aids sad footnote dario revealed interview charleson informed end shoot hiv positive attempting stage successful horror movie career despite rejected critics pal mira daria nicolodi dario former squeeze agent confident serial killer quite driven showdown course occur theater marco added interesting change production using crows disposal think dario savage nihilistic although certainly made later gruesome films masters horror entries sleepless would suggest film really ups ante pure violence towards victims psychopath method forcing betty watch admittedly gag dario regarding type audience like look away horrific parts horror movies found rubbing eyes every time blink brilliantly dario shoots pricking point view achieving tormenting effect perspective ones scotch taped needles holding eyes open like dario show widened eyes betty horrified forced watching little blood tears needles choice blink photographic work ronnie taylor impeccable crow point view shot theater end searches killer camera travels rooms theater following killer wishes see muse box seat dream sequence taken betty memory event regarding mother death certain killer donning mask gloves one causing trauma present highlight opinion peephole bullet fire sequence masterly staged involved camera follows bullet shoots eye victim exploding back head going telephone betty planned use call help even get crow pecking eyeball killer add vicious scene crow shown eyeball rolling around beak aspect care often pointed naysayers film final ending personally felt bit unnecessary guess dario wanted point betty indeed like mother woman sadomasochistic tendencies twist relate killer torments heroine rock music used violent scenes bother felt moments wicked graphic attacks needed jarring thud heavy metal often provide\n",
      "\t./checkpoint/cnn_classifier/cnn 1.0091488191962816e-12\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "one true thing quiet film opened fall glowing reviews mild box office tells crippled story ellen renee zellweger workaholic forced move back home take care terminally ill mother meryl streep aloof father william hurt run academic department terms general strength one true thing lies way actors elevate characters hollywood clich territory streep kate perfect homemaker whose ability light room charm evident opening scenes costume party celebrating hurt birthday ellen never close mother since graduated harvard university certain destain ellen almost thinks mother simplistic air head hand admires father shares special passion writing ellen writes aggressive new york firm almost heartbroken latest piece torn hurt seems lonely figure get point kate gets sicker ellen perspectives change grows closer mother distant father hurt keeps making excuses family needs ellen assumes affair meanwhile given desk work spend time craft activities mother cult group minnies also learning mother weak first assumed without giving much away one true thing masterpiece character study streep turns beautiful performance time working subtle level starts slow ends brilliant speech vows marriage streep earned eleventh oscar nomination performance hurt also convincing father carries secret revealed closing moments renee zellweger steals movie forget chicago cold mountain bridget jones diary whatever else seen rent movie remarkable working within character bitter resentment understanding parents zellweger manages realistic portrayal young woman fighting keep lip screaming inside\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9999905824661255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "usually difficult time watching tv movie extra long commercial breaks break concentration give find good book one however made put adds stay end realize movie based true story brought took long find denny name would presume social security number move around lot would seem would found soon number entered job etc actors seemed bit old part buried metal object dug rust technical glitches take file lifetime movie better\n",
      "\t./checkpoint/cnn_classifier/cnn 0.9979889392852783\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/cnn_classifier/cnn/model.ckpt-101003\n",
      "movie painful probably best way describe minutes life never able get back well actually like minutes way anyone would want sit credits stinking pile dog feces immediately tell movie producer mortal kombat due thumping annoying techno soundtrack drains laughably enjoyable moments movie give rest drained completely uninteresting annoying characters freddie prinze jr school acting acting abilities involved including miscast christopher lambert non existant directing leave anything course let forget suicide inducing script unitentionally funny dialogue oh yes let us also talk shamed original poem sad useless futuristic medieval translation costumes weapons giant pizza cutters kept seeing plain stupid best way describe last culprit night always awful cgi filmmakers learn cgi sucks see wonderful effects used probably never films like star wars episode phantom menace make us wish would bring back closing avoid movie like newest freddie prinze jr movie like freddie prinze jr movies deserve sit horrid excuse filmmaking\n",
      "\t./checkpoint/cnn_classifier/cnn 1.3913024229586322e-26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bfb5a7d289e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Current Progress %d \\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msentimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_test_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-aa33724cb1ac>\u001b[0m in \u001b[0;36mprint_predictions\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_classifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-aa33724cb1ac>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_classifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[1;32m    416\u001b[0m               \u001b[0mscaffold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m               config=self._session_config),\n\u001b[0;32m--> 418\u001b[0;31m           hooks=hooks) as mon_sess:\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m           \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    671\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    672\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    491\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \"\"\"\n\u001b[1;32m    850\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     return self._get_session_manager().prepare_session(\n\u001b[1;32m    421\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_get_saver_or_default\u001b[0;34m()\u001b[0m\n\u001b[1;32m    805\u001b[0m           format(collection_key))\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msavers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m   \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_eager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1261\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[1;32m   1264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mper_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GroupByDevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m           \u001b[0msave_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddShardedSaveOps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m           restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_AddShardedSaveOps\u001b[0;34m(self, filename_tensor, per_device)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \"\"\"\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msaver_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaverDef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddShardedSaveOpsForV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mnum_shards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_AddShardedSaveOpsForV2\u001b[0;34m(self, checkpoint_prefix, per_device)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# attempts to delete the temporary directory, \"<user-fed prefix>_temp\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         merge_step = gen_io_ops.merge_v2_checkpoints(\n\u001b[0;32m--> 363\u001b[0;31m             sharded_prefixes, checkpoint_prefix, delete_old_dirs=True)\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerge_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0;31m# Returns the prefix \"<user-fed prefix>\" only.  DOES NOT include the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints\u001b[0;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;34m\"MergeV2Checkpoints\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_prefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mdestination_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         delete_old_dirs=delete_old_dirs, name=name)\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    968\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m    931\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m    932\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_pack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   2870\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 2872\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   2873\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2954\u001b[0m         \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m         \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2956\u001b[0;31m         op_def=op_def)\n\u001b[0m\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf14_py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_types_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     self._outputs = [\n\u001b[0;32m-> 1439\u001b[0;31m         \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 예측된 모델을 불러 체크포인트로 결과치를 불러온다.\n",
    "\n",
    "sentimental = []\n",
    "\n",
    "for i in range(len(clean_test_reviews)):\n",
    "    if ( (i+1) % 1000 == 0):\n",
    "        print (\"Current Progress %d \\n\" % (i+1))\n",
    "    sentimental.append(print_predictions([clean_test_reviews[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#알아보기 쉽게 데이터랑 붙여두는 편이 좋을 거 같습니다.\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":sentimental} )\n",
    "\n",
    "#지금까지 처리한 결과를 파일로 저장합니다.\n",
    "output.to_csv( \"Bag_of_Words_model_test.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.5 기준으로 값들을 변환\n",
    "\n",
    "def correct_val(x):\n",
    "    if x >= 0.5:\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 0\n",
    "    \n",
    "    return x\n",
    "\n",
    "final_result = output['sentiment'].apply(correct_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#알아보기 쉽게 데이터랑 붙여두는 편이 좋을 거 같습니다.\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":final_result} )\n",
    "\n",
    "#지금까지 처리한 결과를 파일로 저장합니다.\n",
    "output.to_csv( \"final_bof.csv\", index=False, quoting=3 )\n",
    "\n",
    "#최종 점수는 0.8344가 나왔습니다. 단순한 cnn 1 layer 모델 기준. 향후 파인 튜닝 하면 더 증가 할 가능성이 있ㄴ에ㅛ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
