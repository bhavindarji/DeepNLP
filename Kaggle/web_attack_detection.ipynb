{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "FWAF - Machine Learning driven Web Application Firewall\n",
    "Author: Faizan Ahmad\n",
    "Performance improvements: Timo Mechsner\n",
    "Website: http://fsecurify.com\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import urllib.parse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadFile(name):\n",
    "    directory = str(os.getcwd())\n",
    "    filepath = os.path.join(directory, name)\n",
    "    with open(filepath,'r') as f:\n",
    "        data = f.readlines()\n",
    "    data = list(set(data))\n",
    "    result = []\n",
    "    for d in data:\n",
    "        d = str(urllib.parse.unquote(d))   #converting url encoded data to simple string\n",
    "        result.append(d)\n",
    "    return result\n",
    "\n",
    "badQueries = loadFile('badqueries.txt')\n",
    "validQueries = loadFile('goodqueries.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "badQueries = list(set(badQueries))\n",
    "validQueries = list(set(validQueries))\n",
    "allQueries = badQueries + validQueries\n",
    "yBad = [1 for i in range(0, len(badQueries))]  #labels, 1 for malicious and 0 for clean\n",
    "yGood = [0 for i in range(0, len(validQueries))]\n",
    "y = yBad + yGood\n",
    "queries = allQueries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTF-IDF(Term Frequency - Inverse Document Frequency)는 정보 검색과 텍스트 마이닝에서 이용하는 가중치로, \\n여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치이다. 문서의 핵심어를 추출하거나, \\n검색 엔진에서 검색 결과의 순위를 결정하거나, 문서들 사이의 비슷한 정도를 구하는 등의 용도로 사용할 수 있다.\\n\\nTF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값으로, \\n이 값이 높을수록 문서에서 중요하다고 생각할 수 있다. 하지만 단어 자체가 문서군 내에서 자주 사용되는 경우, \\n이것은 그 단어가 흔하게 등장한다는 것을 의미한다. \\n\\n이것을 DF(문서 빈도, document frequency)라고 하며, \\n이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다. TF-IDF는 TF와 IDF를 곱한 값이다.\\nIDF 값은 문서군의 성격에 따라 결정된다. 예를 들어 '원자'라는 낱말은 일반적인 문서들 사이에서는 잘 나오지 않기 때문에 \\nIDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 \\n각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "TF-IDF(Term Frequency - Inverse Document Frequency)는 정보 검색과 텍스트 마이닝에서 이용하는 가중치로, \n",
    "여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치이다. 문서의 핵심어를 추출하거나, \n",
    "검색 엔진에서 검색 결과의 순위를 결정하거나, 문서들 사이의 비슷한 정도를 구하는 등의 용도로 사용할 수 있다.\n",
    "\"\"\"\n",
    "#TF = (용어 t가 문서에 나타나는 횟수) / (문서의 용어 수)\n",
    "#IDF = log (N / n), 여기서 N은 문서의 수이고, n은 용어 t가 나타난 문서의 수\n",
    "\n",
    "# TF-IDF는 TF와 IDF를 곱한 값으로 점수가 높은 단어일수록 다른 문서에는 많지 않고 해당 문서에서 자주 등장하는 단어를 의미한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  정확도(Precision) \n",
    "#  재현율(Recall)\n",
    "\n",
    "# 모델의 성능 평가 F - score\n",
    "# 정확도와 재현율을 하나의 지표로 통합해서 정확성을 측정하는 방법\n",
    "# 정확하면서 계속 반복시도했을때 동일한 결과가 나와야 .... \n",
    "\n",
    "# Precision과 Recall의 트레이드오프를 잘 통합하여 정확성을 한번에 나타내는 지표라 할 수 있다. \n",
    "# 보통 가중치를 가진 조화 평균(weighted harmonic mean)이라고도 한다. \n",
    "# * 조화 평균(Harmonic Mean)은 주어진 수들의 역수의 산술 평균을 구한 값의 역수\n",
    "\n",
    "# F 1 score = (1 + β제곱) * (Precision * Recall) / (β제곱 * Precision + Recall)\n",
    "\n",
    "#  β가 1인 경우 (즉 F1)를 F1 Score라고 하고, 모델의 성능 평가 지표로 많이 사용한다.\n",
    "# \n",
    "#vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"word\", sublinear_tf=True, ngram_range=(1,3)) #converting data to vectors\n",
    "#Bad samples: 44532\n",
    "#Good samples: 1265974\n",
    "#Baseline Constant negative: 0.966019\n",
    "#------------\n",
    "#Accuracy: 0.996070\n",
    "#Precision: 0.924847\n",
    "#Recall: 0.960847\n",
    "#F1-Score: 0.942503\n",
    "#AUC: 0.987436\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3)) #converting data to vectors\n",
    "X = vectorizer.fit_transform(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data > train, test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# training our model \n",
    "# class_weight가 작동하는 방식 : \n",
    "# 클래스 가중치가 높다는 것은 그 클래스에 중점을 두는 것을 의미합니다. \n",
    "# 클래스 0이 클래스 1보다 더 자주 보인다면\n",
    "# 클래스 0에 비해 클래스 1의 class_weight를 증가시켜야합니다. \n",
    "# 예를 들어 {0 : .1, 1 : .9}. \n",
    "\n",
    "# 기본값은 class_weight='balanced'\n",
    "# \"balanced\"모드는 y 값을 사용하여 입력 데이터의 클래스 빈도에 반비례하는 가중치를 \n",
    "#                        n_samples / (n_classes * np.bincount (y))\n",
    "# 로 자동 조정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "badCount = len(badQueries)\n",
    "validCount = len(validQueries)\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced') # class_weight='balanced')\n",
    "lgs.fit(X_train, y_train) #training our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############\n",
    "# Evaluation #\n",
    "##############\n",
    "\n",
    "predicted = lgs.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "auc = metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad samples: 44532\n",
      "Good samples: 1265974\n",
      "Baseline Constant negative: 0.966019\n",
      "------------\n",
      "Accuracy: 0.999252\n",
      "Precision: 0.980748\n",
      "Recall: 0.997268\n",
      "F1-Score: 0.988939\n",
      "AUC: 0.999980\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Bad samples: %d\" % badCount)\n",
    "print(\"Good samples: %d\" % validCount)\n",
    "print(\"Baseline Constant negative: %.6f\" % (validCount / (validCount + badCount)))\n",
    "print(\"------------\")\n",
    "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))  #checking the accuracy\n",
    "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
    "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
    "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
    "print(\"AUC: %f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
