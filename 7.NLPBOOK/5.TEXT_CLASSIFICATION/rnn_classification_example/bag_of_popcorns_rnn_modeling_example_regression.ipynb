{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR_PATH = './data/'\n",
    "INPUT_TRAIN_DATA_FILE_NAME = 'input.npy'\n",
    "LABEL_TRAIN_DATA_FILE_NAME = 'label.npy'\n",
    "DATA_CONFIGS_FILE_NAME = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vocab', 'vocab_size'])\n"
     ]
    }
   ],
   "source": [
    "input_data = np.load(open(FILE_DIR_PATH + INPUT_TRAIN_DATA_FILE_NAME, 'rb'))\n",
    "label_data = np.load(open(FILE_DIR_PATH + LABEL_TRAIN_DATA_FILE_NAME, 'rb'))\n",
    "prepro_configs = None\n",
    "\n",
    "with open(FILE_DIR_PATH + DATA_CONFIGS_FILE_NAME, 'r') as f:\n",
    "    prepro_configs = json.load(f)\n",
    "    print(prepro_configs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "\n",
    "input_train, input_test, label_train, label_test = train_test_split(input_data, label_data, \n",
    "                                                                    test_size=TEST_SPLIT, random_state=RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "def mapping_fn(X, Y):\n",
    "    input, label = {'text': X}, Y\n",
    "    return input, label\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_test, label_test))\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/rnn_classifier'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "embedding_size = 100\n",
    "hidden_state_dim = 150\n",
    "hidden_layer_dim = 150\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    input_layer = tf.contrib.layers.embed_sequence(\n",
    "                    features['text'],\n",
    "                    vocab_size,\n",
    "                    embedding_size)\n",
    "\n",
    "    training = False\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "    \n",
    "    input_layer = tf.layers.dropout(inputs=input_layer,\n",
    "                                   rate=0.2,\n",
    "                                   training=training)\n",
    "    \n",
    "    rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [hidden_state_dim, hidden_state_dim]]\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                       inputs=input_layer,\n",
    "                                       dtype=tf.float32)\n",
    "    \n",
    "    hidden = tf.layers.dense(inputs=outputs[:,-1,:], units=hidden_layer_dim, activation=tf.nn.tanh)\n",
    "\n",
    "    hidden = tf.layers.dropout(inputs=hidden, rate=0.2, training=training)\n",
    "    logits = tf.layers.dense(inputs=hidden, units=1)\n",
    "    \n",
    "    logits = tf.squeeze(logits)\n",
    "    predicts = tf.nn.sigmoid(logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # TFServing을 하기 위한 준비를 위해서는 output에 대한 export 정의를 해줄 필요가 있다.\n",
    "        # 여기선 영화 평점 예측점수와 그 해당 영화 리뷰 텍스트에 대한 시멘틱 정보를 출력하고자 한다.\n",
    "        \n",
    "        predictions = {'sentiment': predicts}\n",
    "        \n",
    "        # TFServing을 활용하여 예측값을 얻고자 한다면 예측 output에 대해서 프로토콜을 맞춰 export할 \n",
    "        # 준비를 해야 한다. 이를 estimator.export.PredictOutput을 통해 해결 할 수 있다.\n",
    "        export_outputs = {\n",
    "          'prediction': tf.estimator.export.PredictOutput(predictions),\n",
    "        }\n",
    "        \n",
    "        # TFServing 파일로 만들기 위해서는 export_outputs 파라메터를 반드시 지정해주어야 한다.\n",
    "        # 이 파라메터가 없이 serving 모델에 대한 저장을 하려하면 이 파라메터에 대한 부재가 있음을\n",
    "        # 에러를 통해 알게 될 것이다.\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  predictions=predictions,\n",
    "                  export_outputs=export_outputs)\n",
    "    \n",
    "#     one_hot_labels = tf.one_hot(labels, 2)\n",
    "#     loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)\n",
    "    loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(predicts))\n",
    "        eval_metric_ops = {'acc': accuracy}\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          loss=loss, \n",
    "                                          eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "    global_step = tf.train.get_global_step()\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "              mode=mode,\n",
    "              train_op=train_op,\n",
    "              loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'checkpoint/train_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2bf1d03898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f2bf6c0c950>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "est = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                             model_dir='checkpoint/train_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into checkpoint/train_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6930158, step = 0\n",
      "INFO:tensorflow:global_step/sec: 17.5229\n",
      "INFO:tensorflow:loss = 0.6325678, step = 100 (5.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4629\n",
      "INFO:tensorflow:loss = 0.32543308, step = 200 (5.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.488\n",
      "INFO:tensorflow:loss = 0.5885191, step = 300 (5.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4763\n",
      "INFO:tensorflow:loss = 0.5572064, step = 400 (5.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5513\n",
      "INFO:tensorflow:loss = 0.6487688, step = 500 (5.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4676\n",
      "INFO:tensorflow:loss = 0.4880464, step = 600 (5.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.538\n",
      "INFO:tensorflow:loss = 0.6299506, step = 700 (5.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5405\n",
      "INFO:tensorflow:loss = 0.67146635, step = 800 (5.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5782\n",
      "INFO:tensorflow:loss = 0.42932725, step = 900 (5.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5217\n",
      "INFO:tensorflow:loss = 0.51503956, step = 1000 (5.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5193\n",
      "INFO:tensorflow:loss = 0.24190812, step = 1100 (5.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4901\n",
      "INFO:tensorflow:loss = 0.39396185, step = 1200 (5.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5532\n",
      "INFO:tensorflow:loss = 0.3363809, step = 1300 (5.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5551\n",
      "INFO:tensorflow:loss = 0.59078455, step = 1400 (5.389 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1407 into checkpoint/train_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.62298405.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f2bf1d034a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-25-12:04:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/train_model/model.ckpt-1407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-25-12:05:02\n",
      "INFO:tensorflow:Saving dict for global step 1407: acc = 0.6696, global_step = 1407, loss = 0.59245867\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1407: checkpoint/train_model/model.ckpt-1407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6696, 'loss': 0.59245867, 'global_step': 1407}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글 평가 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR_PATH = './data/'\n",
    "INPUT_TEST_DATA_FILE_NAME = 'test_input.npy'\n",
    "\n",
    "test_input_data = np.load(open(FILE_DIR_PATH + INPUT_TEST_DATA_FILE_NAME, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"text\":test_input_data}, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/train_model/model.ckpt-1407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array([p['sentiment'] for p in est.predict(input_fn=\n",
    "predict_input_fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6720835 , 0.11022212, 0.55367845, ..., 0.14113991, 0.6324039 ,\n",
       "       0.5942693 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(predictions, range=[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PATH='~/.kaggle/competitions/word2vec-nlp-tutorial/'\n",
    "\n",
    "test = pd.read_csv(DEFAULT_PATH+\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"2913_8\"</td>\n",
       "      <td>\"...as valuable as King Tut's tomb! (OK, maybe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"4396_1\"</td>\n",
       "      <td>\"This has to be one of the biggest misfires ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"395_2\"</td>\n",
       "      <td>\"This is one of those movies I watched, and wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"10616_1\"</td>\n",
       "      <td>\"The worst movie i've seen in years (and i've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"9074_9\"</td>\n",
       "      <td>\"Five medical students (Kevin Bacon, David Lab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l...\n",
       "5    \"2913_8\"  \"...as valuable as King Tut's tomb! (OK, maybe...\n",
       "6    \"4396_1\"  \"This has to be one of the biggest misfires ev...\n",
       "7     \"395_2\"  \"This is one of those movies I watched, and wo...\n",
       "8   \"10616_1\"  \"The worst movie i've seen in years (and i've ...\n",
       "9    \"9074_9\"  \"Five medical students (Kevin Bacon, David Lab..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":list(predictions)} )\n",
    "output.to_csv( \"rnn_predict13.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFServing 파일로 저장하여 서비스 활용하기 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_SEQ_LEN = 100\n",
    "\n",
    "# Serving을 제공하기 위한 입력 리시버 함수를 선언해주어야 한다.\n",
    "def serving_input_receiver_fn():\n",
    "    # estimator에 입력하고자 하는 데이터를 dict 객체로 정의한다.\n",
    "    receiver_tensor = {\n",
    "        # 외부로부터 입력을 받는 프로토콜은 스트링이다. ServingInputReceiver 메뉴얼에도 언급되었다시피\n",
    "        # 이 방식은 TFRecord 파일 형태로 시리얼화한 데이터 형태로 전송을 받는다. (이를 tf.example 방식이라고도 하는 것 같다)\n",
    "        'text': tf.placeholder(dtype=tf.string, shape=[None])\n",
    "    }\n",
    "    \n",
    "    # 다음은 TFRecord 방식으로 받은 데이터를 모델에 넣을 수 있게 처리를 하는 dict 객체라 보면 된다.\n",
    "    # 쉽게 말하면 앞서 estimator를 진행하기 위해 data_fn의 과정을 작성해두는데 이 과정을 여기서 거친다 보면 된다.\n",
    "    features = {\n",
    "        key: tensor\n",
    "        for key, tensor in receiver_tensor.items()\n",
    "    }\n",
    "    # TFRecord로 시리얼화 된 데이터를 integer tensor로 변환하기 위해서는 string to int로 decode를 해줘야 한다.\n",
    "    fn = lambda query: tf.decode_raw(query, tf.int64)\n",
    "    features['text'] = tf.map_fn(fn, features['text'], dtype=tf.int64)\n",
    "    # 받은 데이터에 대해 모델입력에 맞는 shape로 구성을 해주기 위해 reshape을 해준다.\n",
    "    features['text'] = tf.reshape(features['text'], [-1, LIMIT_SEQ_LEN])\n",
    "\n",
    "    # 위에 정의한 받을 데이터에 대한 프로토콜과 모델에 입력할 데이터 전처리를 다음 함수 파라메터에 입력해준다.\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/train_model/model.ckpt-1407\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./served_model/new_staging/temp-b'1537877107'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "export_dir_base = './served_model/new_staging'\n",
    "\n",
    "# 서빙에 대한 입력 리시버함수와 저장 위치를 파라메터로 지정한다면, 서빙 pb파일로 저장하여 간단하게 모델을 활용할 수 있게 된다.\n",
    "# 실행을 하게 되면 저장된 파일의 위치를 텍스트 출력을 통해 얻게된다.\n",
    "path = est.export_savedmodel(export_dir_base, serving_input_receiver_fn) #,\n",
    "#                       strip_default_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./served_model/new_staging/1537877107/variables/variables\n"
     ]
    }
   ],
   "source": [
    "# 모델이 저장된 경로 위치를 파라메터로 지정하여 함수를 부르면 간단하게 예측 모델을 활용할 수 있다.\n",
    "# 이 모델 예측을 간단하게 함수로 받게된다.\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "    export_dir = path,\n",
    "    # 옵션이지만 실행되는 모델에 대한 이름을 명시하고자 한다면 다음의 파라메터를 활용한다.\n",
    "    signature_def_key=\"serving_default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 array:  [   89    77    45    23    92   772   242     7   125   347     2   199\n",
      "   122     3  7572   729     2  3581  8961    12 37400  2004     8    10\n",
      "    17     6     3   236   465  1579     6   364    29     4     1    89\n",
      "   999    77   123     5  1625    10  1132    18     6    24  2473    71\n",
      "    16    30     1   676     9   137   509    10   849  7066    71     9\n",
      "    88    20   121    85    77    50    28   270   485  4535  3530     9\n",
      "   121    10    15     3   189    24     6   341    34   563   323    18\n",
      "   371   224    41    29     4     1    89 18838 18839     9   438    24\n",
      "     6    23     1  1493]\n",
      "\n",
      "모델에 입력하기 위한 array:  b'Y\\x00\\x00\\x00\\x00\\x00\\x00\\x00M\\x00\\x00\\x00\\x00\\x00\\x00\\x00-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\\\\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\xf2\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x00\\x00\\x00\\x00\\x00\\x00\\x00[\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc7\\x00\\x00\\x00\\x00\\x00\\x00\\x00z\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x1d\\x00\\x00\\x00\\x00\\x00\\x00\\xd9\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xfd\\r\\x00\\x00\\x00\\x00\\x00\\x00\\x01#\\x00\\x00\\x00\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x92\\x00\\x00\\x00\\x00\\x00\\x00\\xd4\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xec\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd1\\x01\\x00\\x00\\x00\\x00\\x00\\x00+\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00l\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x1d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00Y\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xe7\\x03\\x00\\x00\\x00\\x00\\x00\\x00M\\x00\\x00\\x00\\x00\\x00\\x00\\x00{\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00Y\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00l\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa9\\t\\x00\\x00\\x00\\x00\\x00\\x00G\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa4\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x89\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xfd\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00Q\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x9a\\x1b\\x00\\x00\\x00\\x00\\x00\\x00G\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00X\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00y\\x00\\x00\\x00\\x00\\x00\\x00\\x00U\\x00\\x00\\x00\\x00\\x00\\x00\\x00M\\x00\\x00\\x00\\x00\\x00\\x00\\x002\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\xe5\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\xb7\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\xca\\r\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00y\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xbd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00U\\x01\\x00\\x00\\x00\\x00\\x00\\x00\"\\x00\\x00\\x00\\x00\\x00\\x00\\x003\\x02\\x00\\x00\\x00\\x00\\x00\\x00C\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\xe0\\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00Y\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x96I\\x00\\x00\\x00\\x00\\x00\\x00\\x97I\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xb6\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd5\\x05\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터는 array 형태로 입력을 할 수가 있다. 이 때 주의할 점은 데이터 타입을 \n",
    "# 반드시 입력 리시버 함수에서 정의한 데이터 타입과 일치시켜야한다.\n",
    "# 보통 int32, int64 데이터에 대한 정의가 맞지않아 막상 데이터를 모델에 입력했을 때 \n",
    "# 바이너리 데이터 길이의 불일치 문제로 이어져 에러가 발생할 수 있다.\n",
    "\n",
    "d = np.array(input_data[0], dtype=np.int64)\n",
    "print('입력 데이터 array: ', d)\n",
    "\n",
    "d = d.tostring()\n",
    "print('\\n모델에 입력하기 위한 array: ', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단하게 입력 파라메터에 대한 프로토콜만 맞춰 입력한다면 예츨 모델을 함수를 통해 얻을 수 있다.\n",
    "output = predictor_fn({'text': [d]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 0.6081097}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 간단한 서비스 테스트를 위한 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2vec(s, vocab, limit_len=100, PAD='pad', UNK='unk'):\n",
    "    s_tok = s.split()\n",
    "    pad_count = limit_len - len(s_tok)\n",
    "    indecied_list = [vocab[t] if t in vocab else 0 for t in s_tok]\n",
    "    if pad_count > 0:\n",
    "        indecied_list = indecied_list + ([0] * pad_count)\n",
    "    elif pad_count < 0:\n",
    "        indecied_list = indecied_list[:limit_len]\n",
    "    \n",
    "    np_index = np.array(indecied_list, dtype=np.int64)\n",
    "    np_index = np_index.tostring()\n",
    "    \n",
    "    return indecied_list, np_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 229, 10, 17, 6, 36, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentiment': 0.101114474}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = prepro_configs['vocab']\n",
    "\n",
    "test_sent = 'i feel this movie is so good'\n",
    "arr, input_arr = str2vec(test_sent, vocab)\n",
    "print(arr)\n",
    "predictor_fn({'text': [input_arr]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text : i hate this movie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentiment': 0.09129788}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = input('input text : ')\n",
    "arr, input_arr = str2vec(input_str, vocab)\n",
    "predictor_fn({'text': [input_arr]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
