{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 전처리 하기 위하여, 아래에서 사용할 라이브러리는 다음과 같다.\n",
    "\n",
    "import re # 정규표현식\n",
    "from bs4 import BeautifulSoup # \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 데이터를 Pandas 라이브러리로 불러온다.\n",
    "DEFAULT_PATH ='~/.kaggle/competitions/word2vec-nlp-tutorial/'\n",
    "train = pd.read_csv(DEFAULT_PATH+\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(DEFAULT_PATH+\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\\\\"The Classic War of the Worlds\\\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells\\' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\\\"critics\\\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\\\"critics\\\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells\\' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\\\"critics\\\\\" perceive to be its shortcomings.\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터의 구조는 \"id\", \"sentiment\", \"review\"로 구분되어 있으며, \"review\"를 보고 \"sentiment\"를 판단하는 문장\n",
    "train.head()\n",
    "#raw text는 다음과 같은 구조로 되어 있다. 내부에 html과 관련된 특수기호 및 문자 (html 태그) ]들이 들어가 있다.\n",
    "train.review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing( review, remove_stopwords = False ): \n",
    "    # 불용어 제거는 옵션으로 선택 가능하다.\n",
    "    \n",
    "    # 1. HTML 태그 제거\n",
    "    review_text = BeautifulSoup(review, \"html5lib\").get_text()\t\n",
    "\t\n",
    "    # 2. 영어가 아닌 특수문자들을 공백(\" \")으로 바꾸기\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "\n",
    "    # 3. 대문자들을 소문자로 바꾸고 공백단위로 텍스트들 나눠서 리스트로 만든다.\n",
    "    words = review_text.lower().split()\n",
    "\t\n",
    "    if remove_stopwords: \n",
    "        # 4. 불용어들을 제거\n",
    "    \n",
    "        #영어에 관련된 불용어 불러오기\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        # 불용어가 아닌 단어들로 이루어진 새로운 리스트 생성\n",
    "        words = [w for w in words if not w in stops]\n",
    "        # 5. 단어 리스트를 공백을 넣어서 하나의 글로 합친다.\t\n",
    "        clean_review = ' '.join(words)\n",
    "    \t\n",
    "    else: # 불용어 제거하지 않을 때\n",
    "        clean_review = ' '.join(words)\n",
    "\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train데이터를 전처리\n",
    "clean_train_reviews = []\n",
    "for review in train['review']:\n",
    "    clean_train_reviews.append(preprocessing(review, remove_stopwords = True))\n",
    " \n",
    "#전처리한 데이터의 첫 번째 데이터 출력\n",
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naturally film main themes mortality nostalgia loss innocence perhaps surprising rated highly older viewers younger ones however craftsmanship completeness film anyone enjoy pace steady constant characters full engaging relationships interactions natural showing need floods tears show emotion screams show fear shouting show dispute violence show anger naturally joyce short story lends film ready made structure perfect polished diamond small changes huston makes inclusion poem fit neatly truly masterpiece tact subtlety overwhelming beauty'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test데이터를 전처리\n",
    "clean_test_reviews = []\n",
    "for review in test['review']:\n",
    "    clean_test_reviews.append(preprocessing(review, remove_stopwords = True))\n",
    " \n",
    "#전처리한 데이터의 첫 번째 데이터 출력\n",
    "clean_test_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 갯수:  25000\n"
     ]
    }
   ],
   "source": [
    "reviews = list(train['review'])\n",
    "sentiments = list(train['sentiment'])\n",
    "\n",
    "num_reviews = train[\"review\"].size\n",
    "print('전체 리뷰 갯수: ', num_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어 갯수:  101246\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_reviews+clean_test_reviews)\n",
    "\n",
    "#train\n",
    "train_text_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n",
    "#test\n",
    "test_text_sequences = tokenizer.texts_to_sequences(clean_test_reviews)\n",
    "\n",
    "word_vocab = tokenizer.word_index\n",
    "print(\"전체 단어 갯수: \", len(word_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input train data tensor: (25000, 50)\n",
      "Shape of label train tensor: (25000,)\n",
      "Shape of input test data tensor: (25000, 50)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "\n",
    "train_inputs = pad_sequences(train_text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "train_labels = np.array(train['sentiment'])\n",
    "\n",
    "test_inputs = pad_sequences(test_text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "print('Shape of input train data tensor:', train_inputs.shape)\n",
    "print('Shape of label train tensor:', train_labels.shape)\n",
    "print('Shape of input test data tensor:', test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR_PATH = './data/'\n",
    "INPUT_TRAIN_DATA_FILE_NAME = 'train_input.npy'\n",
    "LABEL_TRAIN_DATA_FILE_NAME = 'train_label.npy'\n",
    "INPUT_TEST_DATA_FILE_NAME = 'test_input.npy'\n",
    "\n",
    "DATA_CONFIGS_FILE_NAME = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(FILE_DIR_PATH):\n",
    "    os.makedirs(FILE_DIR_PATH)\n",
    "\n",
    "np.save(open(FILE_DIR_PATH + INPUT_TRAIN_DATA_FILE_NAME, 'wb'), train_inputs)\n",
    "np.save(open(FILE_DIR_PATH + LABEL_TRAIN_DATA_FILE_NAME, 'wb'), train_labels)\n",
    "np.save(open(FILE_DIR_PATH + INPUT_TEST_DATA_FILE_NAME, 'wb'), test_inputs)\n",
    "\n",
    "data_configs = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab) # vocab size 추가\n",
    "\n",
    "import json\n",
    "\n",
    "with open(FILE_DIR_PATH + DATA_CONFIGS_FILE_NAME, 'w') as f:\n",
    "    json.dump(data_configs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
